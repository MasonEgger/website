{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Mason Egger","text":"<p>On my business card, I am a Sr. Technical Curriculum Developer. In my mind, I am an engineer. But in my heart, I am a teacher.</p> <p>I'm Mason Egger, a technical educator, software developer, and community organizer.  I'm currently on the Developer Education team at Temporal, an organizer and president of the PyTexas Foundation, and the Deputy Province Governor for Province 9 of the Phi Mu Alpha Sinfonia fraternity.</p>"},{"location":"#recent-content","title":"Recent Content","text":"<p>The most recent content I've published.</p> <ul> <li>You Don't Get Better Without Deliberate Practice</li> <li>2023 Is Dead! Long Live 2024!</li> <li>Oh Shit, I Haven't Blogged in a While</li> </ul>"},{"location":"#featured-content","title":"Featured Content","text":"<p>These are the pieces that do well or people tell me they have enjoyed.</p> <ul> <li>How To Build a 7 Days To Die Server on Ubuntu</li> <li>How I Write Conference Talk Proposals</li> <li>Tech Industry Interviews are Bullshit. Let's Make Them Better</li> </ul> <ul> <li> <p> Come to PyTexas</p> <p>Join me April 11 - 13, 2025 in Austin Texas for the 18<sup>th</sup> annual PyTexas Conference</p> <p> PyTexas Website</p> </li> <li> <p> Take My Temporal Courses</p> <p>I am the author of many Temporal based courses in Java and Python</p> <p> Get Started</p> </li> <li> <p> Book a Meeting</p> <p>Want to chat? Book some time on my calendar. All I ask is you give me 24 hours to prepare</p> <p> Book a Meeting</p> </li> </ul> <p>Mastodon</p>"},{"location":"bio/","title":"Professional Biography / <code>tl;dr</code>","text":"<p>I'm terrible at having to write bios for talks that I want to present, so I'm putting it here just to keep everything together. If you need a bio for me,  please take this one.</p> <p>Mason is currently a Senior Developer Advocate at Temporal Technologies who specializes in building community, developer-focused educational content, distributed systems, and Python.  Prior to his work at Temporal he worked in Developer Relations at DigitalOcean and as a backend engineer at various companies.  He\u2019s an avid programmer, speaker, educator, and writer/blogger.  He is President of the PyTexas Foundation, Conference Chair of the PyTexas Conference, and a founding organizer of the PyTexas Meetup.</p> <p>\"On my business card, I am a Developer Advocate. In my mind, I am a programmer. But in my heart, I am a teacher.\" - paraphrased, original quote from Satoru Iwata</p>"},{"location":"bio/#my-resume","title":"My Resume","text":""},{"location":"blog/","title":"Blog","text":"<p>Here are my thoughts on topics that I find relevant to me, or just want to go on a nice rant.</p> <p>You're chosing to dive into the ramblings of my mind, don't be surprised to find a mad man or a genius (maybe a little of both?). </p>"},{"location":"blog/new-website/","title":"New Website!","text":"<p>Every few years I grow tired of my website and build a new one. More often than not, it is actually me trying to simplify something that I made more complicated than it needed to be. After listening to friends and  co-workers, I'm finally making the jump to static sites.</p>","tags":["Website","Hugo"]},{"location":"blog/new-website/#my-previous-sites","title":"My Previous Sites","text":"<p>I've had probably half a dozen websites since my first one in 2012 (I think?).  My first website was HTML made in Dreamweaver for part of my undergraduate  Music Technology class. In this class we covered a short section on what was  called \"web development\", then more music related technologies such as Finale  and ProTools. I purchased my domain  masonegger.com and deployed the site. Shortly after that I decided to pursue Computer Science in college (that story is long and I'll probably write a blog post on that later). After a few years and rough iterations of my basic HTML site I decided to learn Django. I worked for the Computer Science department and we had decided to rewrite our site using Django, so I took it as an opportunity to learn on my own and make my own website. I created three separate sites <code>www</code>, <code>resume</code>, and <code>labs</code> (I was a lab instructor at the time and wanted to host my materials). This was all fine and good but the overhead required for each of these sites was a database. Now I was just using <code>sqlite</code>, but the process of building an entire database driven site around what was mostly static content, seemed unnecessary. I liked the idea of trying to use the Django admin panel as sort of a Content Mangement System (for anything other than a small website, this is a bad idea) but, as it turns out, I rarely go back and edit my site (And by the time I do I've forgotten the password so I have to login and run <code>django admin</code> to reset the bloody password). The other issue is that my version of Django has become hopelessly obsolete. Like, refactor the whole site to move to 2.0 obsolete. So I was faced with the choice of a) redo the site in Django again with the same frontend (I'm actually not really a fan of it anymore) or b) explore new options. I chose that it's time to explore new options.</p>","tags":["Website","Hugo"]},{"location":"blog/new-website/#static-sites","title":"Static Sites","text":"<p>When I first started looking into build a website, my first boss had tried to point me to static sites. He said something along the lines of \"You don't need a dynamic site, and the security of it will eventually cause you problems.\" Luckily, I haven't had security issues with my website (You have to have something of value to be an actual target ), am running it on FreeBSD which, more often than not, boggles the minds of pen testers, and finally, am  not an easy to hit wordpress site. I started looking around into static site generators and immediately could see the benefits. Once the templates are setup I can simply write Markdown for posts. I enjoy this way more than logging into a WYSIWYG editor. There is no denying the speedup implications regarding a  dynamicy python site vs. static html files. I am also learning Golang for my current job, so that naturally brought me to Hugo (which I had previously received many glowing recommendations for). After looking around at the pre-built templates I finally settled on one that I liked (what you're seeing now).</p>","tags":["Website","Hugo"]},{"location":"blog/new-website/#the-desire-for-a-blog-and-the-move-away-from-medium","title":"The Desire for a Blog and the Move Away from Medium","text":"<p>I've always dabbled with the idea of writing a blog. I had a WordPress blog site once and acually liked it (until I accidentally nuked the cloud instance from orbit and had no backups). I tried building a blog in my old Django site, but absolutely loathed the interface, even after vamping it up with TinyMCE. I started a Medium blog and even published a post through my employeer HomeAway. However, I recently learned that Medium is starting a membership program  where you will have to pay to get full access to the site. As someone who  founded UnlockedEdu(1) and doesn't believe that knowledge should be hidden behind a pay wall, this just didn't sit right with me. I had been putting off updating my website and moving forward, but I do believe the Medium situation was the straw that broke the camel's back. I will still have to publish there due to work (when I write public blogs) but I will write a post with a link to the blog. I don't think I can republish it under this site since it is technically the property of my company (No animosity in this statement at all, I love my job and my company. It's just how it is).</p> <ol> <li>A now defunct project where I aimed to make open education resources. I still believe in this, but this project never really took off.</li> </ol>","tags":["Website","Hugo"]},{"location":"blog/new-website/#the-new-site","title":"The New Site","text":"<p>Low and behold, a new site was born. It's the site you're reading this blog on. After the initial \"what the hell is this?\" phase with Hugo I've come to enjoy it. The template that I chose was a good starting point, and I have spent more time modifying the template than actually writing the initial content of this site, but I'm happy with the result. Once I get the deployment of this site up and have automated the release process, be on the look out for another blog post detailing this process.</p>","tags":["Website","Hugo"]},{"location":"blog/new-website/#welcome-to-my-new-site-its-good-to-have-you-here","title":"Welcome to my new site, it's good to have you here.","text":"","tags":["Website","Hugo"]},{"location":"blog/year-of-the-linux-desktop/","title":"Year of the Linux Desktop","text":"<p>After decades of trying to ignore or straight up bashing Linux,  Microsoft has finally embraced the loveable penguin. So much so that it ships a Linux kernel on your Windows OS by default! What does this mean for the sake of development? Is it finally the year of the Linux desktop?</p> <p>My first job was as a lab instructor/developer for the Computer Science department at Texas State University, starting in the summer of 2012. My boss was what I would call The *nix Dude. You know who I'm talking about. Socks with sandals, utility clothing (pockets in pockets for pockets), and of course, a glorious beard that would make Albus Dumbledore proud. He pretty much personified the *nix Guy from the classic Dilbert comic. Between him and a few select others I was constantly told about how this year would finally be the year Linux became popular on the desktop and how it would signal the end of Microsoft's dominance on the PC. I then decided to try Ubuntu on my personal machine, and after about three months decided this was all wishful thinking and promptly reinstalled Windows. But every time I went to a Linux meetup or conference the phrase \"year of the Linux desktop\" was always being uttered. Personally, like many, I thought it was never going to happen. However, I think I can proudly say that 2019 is in fact, the year of the Linux desktop.... just not how anyone envisioned it.</p>","tags":["Windows","Linux","VSCode","WSL","Programming"]},{"location":"blog/year-of-the-linux-desktop/#year-of-the-linux-desktopexe","title":"Year-of-the-Linux-Desktop.exe","text":"<p>If a decade ago you had told any *nix evangelist that, in 2019, Microsoft Windows would ship a version of their operating system with a Linux kernel built in you would have probably gotten one of two responses:</p> <ol> <li>\"We won! Microsoft has crumbled to Linux!\"</li> <li>\"Linux sold out! expletive M$ will ruin Linux!\"</li> </ol> <p>With Microsoft's long track record of bashing Linux (pun intended) it seemed impossible that the two would ever be able to co-exist. But when Steve Balmer left Microsoft and Satya Nadella took over as CEO it appears that Microsoft entered a sort of Renaissance period. This is a whole topic that could be covered in a separate blog post, but in summary Microsoft started adopting technologies and patterns that it never had before. So when Microsoft announced the Windows Subsystem for Linux (or WSL for short) it took many people by surprise. Microsoft seemed to be embracing Linux and responding to the need for useful development tools on its platform. While a majority of the world uses either Windows or OS X as their primary operating system for day to day life, the vast majority of software is deployed in Linux. I personally have run a dual boot system for years so when I wanted to do regular activities such as streaming video or playing games I would boot into my Windows drive, but when I wanted to write code or tinker I would reboot into my Linux drive. But now I no longer have to do that. For my work computer I used a MacBook Pro like many developers I know. This was a great experience back in early 2015. But ever since then it seems every iteration of the MacBook Pro just gets worse and worse. For the sake of keeping this short we'll only focus on one issue, the keyboard. I don't think I need to say anymore, but if Apple doesn't come to the realization that these terrible hareware decisions are driving developers away from their hardware then I doubt I'll ever own another Mac product again. It used to be that Macs were the only decent viable option for professional developer laptops (not that Linux distros aren't great, but IT management software for them is scarce). The WSL has completely turned this assumption on its head. The WSL allows me to run a fully functioning Linux distro within Windows. Now, when I open my terminal, instead of getting <code>cmd</code> or <code>PowerShell</code> I get a bash terminal with everything I ever needed from my Linux partition. Then, on top of that, I can remote connect to the WSL with VSCode and execute everything I write in there. I open an application on Windows and it just executes my code in a Linux environment flawlessly. It has been three months and I haven't needed to reboot into Linux desktop once. Here's how you can have this experience yourself.</p> <p>So let's get this setup for you so you can experience it for yourself.</p>","tags":["Windows","Linux","VSCode","WSL","Programming"]},{"location":"blog/year-of-the-linux-desktop/#installing-the-wsl","title":"Installing the WSL","text":"<p>Installing the WSL has been made extremely simple though the Microsoft Store.</p> <ol> <li> <p>Go to the Microsoft Store app on your Windows machine and search for Linux.</p> <p></p> </li> <li> <p>As you can see, there are many options to choose from. For the sake of this article we are going to install <code>Ubuntu 1804 LTS</code>. Click on the associated icon and you should see something similar to this.</p> <p></p> </li> <li> <p>Click on the <code>Get</code> button. This will add the app to your account. Then in the  top right hand corner you will see an <code>Install</code> button. Click this to actually install it on your local Windows workstation.</p> <p>After this installation process has finished we can now search for <code>Ubuntu</code> in our applications and it appears! </p> <p></p> </li> <li> <p>Look at that! Let's open it.</p> <p></p> <p>Oh no! Error?!?</p> <p>When you first open Ubuntu you may be presented with this error message:</p> <pre><code>Installing, this may take a few minutes...\nWSLRegisterDistribution failed with error: 0x8007019e\nThe Windows Subsystem for Linux optional component is not enabled. Please enable it and try again.\nSee https://aka.ms/wslinstall for details.\nPress any key to continue\n</code></pre> </li> <li> <p>Don't fret, this simply means you haven't enabled the WSL feature yet. To do this navigate to the control panel path <code>Control Panel -&gt; Programs</code> and select the <code>Turn Windows features on or off</code>. Windows comes pre-configured with the most commonly used features enabled, but the WSL is considered a specialty feature. Simply enable it and reboot your machine. After this reboot the WSL should be enabled.</p> <p></p> </li> <li> <p>Now that you have rebooted your machine search for <code>Ubuntu</code> again and open it. It may take a few minutes for the initial setup to complete. Once it is done you will be prompted for a username and password for your Linux installation. These don't have to be your Windows credentials, it can be whatever you want. Once you have entered them configuration will finish and you will be presented with a <code>bash</code> terminal. On Windows. Welcome to 2019.     </p> </li> </ol>","tags":["Windows","Linux","VSCode","WSL","Programming"]},{"location":"blog/year-of-the-linux-desktop/#installing-and-configuring-the-new-windows-terminal","title":"Installing and Configuring the new Windows Terminal","text":"<p>Now that we have a Linux distro installed on our machine we need an awesome terminal to go with it. The Ubuntu application launches a terminal for you, so if you want to use that go right ahead. It appears that Microsoft, realizing  developers desire for good tooling, has redesigned the Windows Terminal as well as open sourced it. While currently in beta, I haven't had any issues with it and found it easy to install.</p> <ol> <li> <p>Search for Terminal in the Microsoft Store. The Windows Terminal will be the first thing that appears. It may say <code>Windows Terminal (Preview)</code> which is fine.</p> <p></p> </li> <li> <p>Now click on the icon and click <code>Get</code> and <code>Install</code></p> <p></p> </li> <li> <p>Once it's installed you can see it in your recently added section or scroll through your applications to find it. For some reason when I search for it I don't find it.</p> <p></p> </li> <li> <p>Once you open it you'll see it defaults to PowerShell. If you click on the <code>+</code> sign next to the PowerShell tab you will see the options available. You can choose between PowerShell, a traditional Windows <code>cmd</code>, an Azure Cloud Shell, or since we installed Ubuntu, an Ubuntu shell. You also have the ability to modify some settings which we'll get to later.</p> <p></p> </li> <li> <p>If I click on an Ubuntu shell voila you now have a shell into your Ubuntu environment.</p> <p></p> </li> <li> <p>If you want to change your terminal to default open your Ubuntu shell you'll need to click on the <code>+</code> sign and click on <code>Settings</code>. This will open the <code>profile.json</code> in your default text editor and allow you to modify configurations such as font, color, default, and default mount position.</p> <p></p> <pre><code>{\n    \"acrylicOpacity\" : 0.5,\n    \"closeOnExit\" : true,\n    \"colorScheme\" : \"Campbell\",\n    \"commandline\" : \"wsl.exe -d Ubuntu\",\n    \"cursorColor\" : \"#FFFFFF\",\n    \"cursorShape\" : \"bar\",\n    \"fontFace\" : \"Consolas\",\n    \"fontSize\" : 16,\n    \"guid\" : \"{2c4de342-38b7-51cf-b940-2309a097f518}\",\n    \"historySize\" : 9001,\n    \"icon\" : \"ms-appx:///ProfileIcons/{9acb9455-ca41-5af7-950f-6bca1bc9722f}.png\",\n    \"name\" : \"Ubuntu-18.04\",\n    \"padding\" : \"0, 0, 0, 0\",\n    \"snapOnInput\" : true,\n    \"startingDirectory\" : \"%USERPROFILE%\\\\Linux\",\n    \"useAcrylic\" : false\n}\n</code></pre> </li> <li> <p>To change the default terminal find the shell you want to open within the <code>profiles.json</code> and copy it's <code>guid</code>. Then, at the top of <code>profiles.json</code>  there is a <code>globals</code> section with a <code>defaultProfile</code> key. Copy the <code>guid</code> from the profile you want as the <code>defaultProfile</code> and now your shell will default to that option.</p> <pre><code>{\n    \"globals\" : \n    {\n        \"alwaysShowTabs\" : true,\n        \"defaultProfile\" : \"{2c4de342-38b7-51cf-b940-2309a097f518}\",\n    ...\n}\n</code></pre> </li> </ol>","tags":["Windows","Linux","VSCode","WSL","Programming"]},{"location":"blog/year-of-the-linux-desktop/#vscode-and-remote-execution","title":"VSCode and Remote Execution","text":"<p>On top of all this Linuxy greatness Microsoft added Remote Execution plugins for their popular IDE VSCode. These Remote Execution modules seamlessly sync your workspace with an environment to enable you to run and test your code as if it were running on Linux. Currently the Remote Execution plugins support Docker containers, SSH to servers, and WSL. So now, instead of simply editing our code in a text editor in the Windows Terminal (which is how I do a lot of my programming) I can now open VSCode and it thinks it's running in a Linux environment with minimal configuration.</p> <p>So let's set this up and complete the puzzle.</p> <ol> <li> <p>Download and install VSCode from the VSCode Website.</p> <p></p> </li> <li> <p>Install VSCode by clicking on the download and following the installation      wizard instructions.</p> <p></p> </li> <li> <p>Launch VSCode and click on the plugin icon (4 squares on the bottom of the     taskbar on the left hand side) and search for <code>Remote</code>. You will see a      plugin named <code>Remote - WSL</code>. This plugin will allow your VSCode to connect     to your WSL Linux installation. VSCode will seamlessly sync your files and     allow you to execute your code as if it were running on a Linux machine.     Click <code>Install</code> to install this plugin.</p> <p></p> </li> <li> <p>Create a test file and folder for the purposes of this installation. I'm going     to create a simple Python Hello World in Python named <code>hw.py</code>.</p> <pre><code>print(\"Hello Python from WSL\")\n</code></pre> <p>Once you have done this save this file in a new directory. I saved mine in my Documents folder, but a folder called <code>Code</code> or something similar might be good to keep your projects separate from all the other files on your computer.</p> <p>Once done, close this file.</p> </li> <li> <p>VSCode can treat folders as workspaces, so now just go to <code>File -&gt; Open Folder</code>     to open the directory containing the file. This will open the document view     on the left with your file. Double click on it to open it.</p> <p></p> </li> <li> <p>Immediately after opening the file VSCode will start to warn you that nothing     is installed!. This is 100% fine. We haven't installed anything on the base     Windows system and don't intend to.</p> <p></p> </li> <li> <p>Now for the moment of truth. In the very bottom left hand corner their is a     small green box with <code>&gt;&lt;</code> symbol on it. When you hover over it it will say     <code>Open a remote window</code>. Click on this and a menu will pop down from the top     with the current options you have for remote connection (we've currently     only enabled WSL so that should be all you see, there are other remote     connections you can configure). Select the option <code>Remote-WSL: Reopen Folder in WSL</code>.     This will relaunch your VSCode but now it thinks it's running Linux.</p> <p>Note: You still may get warnings about missing plugins installed. This is ok. We'll cover that in a later step.</p> <p></p> </li> <li> <p>Now to test our code you can open a new terminal from the navigation bar     <code>Terminal -&gt; New Terminal</code> and now you have a bash terminal opened. Navigate     to the location of your python script and run <code>python3 hw.py</code> and you should     see the output of your program displayed to the terminal. Tada!</p> <p></p> </li> <li> <p>Executing our code in the terminal is nice and all, but if we just wanted that we     could have used <code>vim</code>. We want all of the features that come with VSCode. Well you can     install any plugin directly into the WSL the way you normally do. If you search for the     Python plugin for example, you'll see the button says <code>Install in WSL: Ubuntu 18.04</code>.     By doing this you will be able to run the debugger and other niceties you've come to     expect from VSCode like the debugger, linter, auto code formatter (note you will need     to install these plugins as well to get these tools).</p> <p></p> </li> <li> <p>And now that we have installed Python we can run it from VSCode directly and get our      output.</p> <p></p> </li> </ol>","tags":["Windows","Linux","VSCode","WSL","Programming"]},{"location":"blog/year-of-the-linux-desktop/#conclusion","title":"Conclusion","text":"<p>With this relatively simple setup I now have a fully functioning Linux environment that seamlessly integrates with my IDE for a development experience unlike any other. Now when I'm waiting for a build to finish, I can play a game of Overwatch or any game since I'm not having to hope for an Apple port or that the developers also wrote it to work in Linux through Steam.</p> <p>I have been using this workflow for the past three months and haven't needed to boot into my Linux partition since. One of the major downsides currently is WSL has pretty poor support for Docker, but the WSL2 has already corrected this and is winding its way through the Windows Insider Beta process. While not having docker has been somewhat of a challenge, when I need it I standup a DigitalOcean droplet with it installed and use the <code>Remote: SSH</code> plugin instead.</p> <p>I'm so impressed with this that when asked what type of laptop I want for my new job, which I start October 1, 2019, I requested a Windows laptop instead of a Mac. I have no doubt that going forward this will be a great experience for me.</p>","tags":["Windows","Linux","VSCode","WSL","Programming"]},{"location":"blog/my-personal-job-litmus-test/","title":"My Personal How Am I Feeling About My Job Litmus Test","text":"<p>Over the past five years working in tech I've developed a sort of litmus test that I perform every morning to gauge how I currently feel about my job and how my career is progressing. And I do it all with a morning playlist.</p> <p>So, I've discovered something curious that I've told others about but never really wrote down before. Over the past five years working in the tech industry, from cyber security to vacation rentals to now cloud providers, I've developed a sort of litmus test about how I'm currently feeling about my job. Funny enough I didn't set out to build this but rather it sort of just happened. It's a test I apply every morning and when the results come back negative for too many days in a row I know it's time to change something. </p>","tags":["Self Care","Work/Life Balance"]},{"location":"blog/my-personal-job-litmus-test/#my-morning-shower-playlist-litmus-test","title":"My Morning Shower Playlist Litmus Test","text":"<p>So, like some I enjoy listening to music while I shower in the morning. I used to listen to the news on my Google Home but I've learned that starting your day off with the latest news is a great way to ruin your day and put you in a sour mood. So, I started messing around with the idea of a playlist that I listen to every morning. Some people may opt to just have random music play every morning but that's not really my style. My morning shower playlist is more of a hype playlist and I enjoy the repetition. One of the things that annoys my friends and family is that I can watch the same TV show or listen to the same music over and over and over and never get tired of it. I'm embarrassed to say  how many times I've watched the entire King of the Hill series and when I was in college I bought the Book of Mormon CD (my Toyota Corolla didn't have Bluetooth) and I left it in the CD player for about 4 years. On rare occasions I would change it to Wicked but then right back. I am happy to report now that I own a vehicle with Bluetooth I now alternate my music a little more. Anyway, the point here is that while some people would be annoyed with the same music every single day I actually love it. So, I started adding and removing songs to the playlist until I settled on what I believe is the perfect shower playlist. I've noticed that when I spend long amounts of time in the shower it's usually because I'm avoiding  going to work. I can even pinpoint how I currently feel about the day ahead based on which song is playing when I finish and turn the shower off.</p>","tags":["Self Care","Work/Life Balance"]},{"location":"blog/my-personal-job-litmus-test/#the-playlist","title":"The Playlist","text":"<p>Here is my \"'How Do I Feel About Work' Shower Litmus Test\".</p> <ol> <li>High Hopes - Panic! At The Disco</li> <li>Shooting Stars - Bag Raiders</li> <li>Come On Eileen - Dexys Midnight Runners</li> <li>Don't Stop Me Now - Queen</li> <li>9 to 5 - Dolly Parton</li> <li>The Show Must Go On - Queen</li> </ol> <p>If you are unfamiliar with the songs, this playlist is essentially a hype playlist with songs like High Hopes, Shooting Stars, Come On Eileen, and Don't Stop Me Now that devolves rather quickly at the end. Dolly Parton's 9 to 5 is pretty much a working class anthem that criticizes the capitalistic system (and that's putting it lightly) which is then followed by The Show Must Go On, a lesser known Queen song that, to me, reminds me of a sad clown putting on a happy face to do his job<sup>1</sup>. Like I  said, this playlist is a rollercoaster that drops fast at the end. </p>","tags":["Self Care","Work/Life Balance"]},{"location":"blog/my-personal-job-litmus-test/#how-i-administer-this-litmus-test","title":"How I Administer This Litmus Test","text":"<p>Every morning I wake up, tell my Google Home Mini to play my playlist and take a shower. I listen to the music and enjoy the warm water and depending on what song is playing when I get out helps me determine how I feel about the day ahead.</p> <p>Here's what I'm feeling when each song is playing:</p>","tags":["Self Care","Work/Life Balance"]},{"location":"blog/my-personal-job-litmus-test/#high-hopes-panic-at-the-disco","title":"High Hopes - Panic! At the Disco","text":"<p>So, I am rarely done when this song is playing. If I am it usually means that I'm running late. It takes half the time of this song just for my water to warm up. So, on days where this song is the result it tells me I need to get up earlier.</p> <p>That being said, this is a great song to start your morning to. It is a fantastic hype song and usually wakes me up quickly. Some might say it is an intense song to start the morning off with, I think it is just intense enough.</p>","tags":["Self Care","Work/Life Balance"]},{"location":"blog/my-personal-job-litmus-test/#shooting-stars-bag-raiders","title":"Shooting Stars - Bag Raiders","text":"<p>It is also rare for me to be done when this song is playing. However, it does happen. When this song is the result of the test it tends to mean I'm either running slightly less late than if I had finished listening to High Hopes, that I've figured out the answer to an issue I've been having and want to rush out to fix it, or I'm  just generally excited for work. Often, it's that I'm still running late, but slightly less late.</p> <p>This song is more of a meditative song than a hype song in my mind. It is a great song to just stand with your head under warm water and think. Therefore, this song is not often the result of the litmus test. It is not meant to be.</p>","tags":["Self Care","Work/Life Balance"]},{"location":"blog/my-personal-job-litmus-test/#come-on-eileen-dexys-midnight-runners","title":"Come On Eileen - Dexys Midnight Runners","text":"<p>When I finish my shower on this song that usually means I got a good night sleep, am ready to go, and am excited about the day. This result should be interpreted as \"You are currently happy and excited about your job.\" I would say that maybe 35% of the time I finish here. And I suspect the reason this number is low is due to lack of sleep not excitement.</p> <p>This song is just fun to sing along with. The Too-ra-loo-ra Too-ra-loo-rye-ay  is just too much fun to not sing along with and play with harmonically. So have fun.</p>","tags":["Self Care","Work/Life Balance"]},{"location":"blog/my-personal-job-litmus-test/#dont-stop-me-now-queen","title":"Don't Stop Me Now - Queen","text":"<p>Ah. This song. The hype songs of all hype songs. If I finish with this song I may have been a little groggy waking up. I'm notorious for not getting a  decent night\u2019s sleep but this song definitely wakes me up. This result basically means everything's right in my work life. I'm happy, I'm fulfilled, I'm ready to tackle the day. This song is the result a vast majority of days. </p> <p>Who doesn't love this song? Like seriously. It just gets you pumped.</p>","tags":["Self Care","Work/Life Balance"]},{"location":"blog/my-personal-job-litmus-test/#9-to-5-dolly-parton","title":"9 to 5 - Dolly Parton","text":"<p>So, as I said earlier, this roller coaster takes a downward angle fast. 9 to 5 is not the song of happy workers. I would imagine there is a correlation between the amount of people listening to this song and unions starting to form. That being said, if this song is the result of my litmus test it is not necessarily  game over. This just means I'm tired with the bull shit I've been dealing with lately and will more probably be in a bad mood that day.</p> <p>Dolly Parton is a national treasure. Enough said.</p>","tags":["Self Care","Work/Life Balance"]},{"location":"blog/my-personal-job-litmus-test/#the-show-must-go-on-queen","title":"The Show Must Go On - Queen","text":"<p>This is the bottom of the roller coaster. If we are here, it is not good.  <pre><code>Inside my heart is breaking\nMy makeup may be flaking\nBut my smile, still, stays on\n</code></pre> When this song is the result of the test, I know that I need to take immediate action to make something better at work. Whether that be take a few days off, talk with my manager, or polish up the resume, this is not where I want to be.</p> <p>This song is hauntingly beautiful, and I highly recommend that if you haven't heard it before that you give it a listen. </p>","tags":["Self Care","Work/Life Balance"]},{"location":"blog/my-personal-job-litmus-test/#how-do-i-use-this-data","title":"How Do I Use This Data?","text":"<p>So, I bet you're wondering \"If he gets to the end of his playlist does he just quit?\". The answer here is no. No one day is enough to make me quit. It is a  great indicator about how I'm currently feeling, but that day could turn everything around. I use this data two different ways. The first is to get a  gauge of my mood for the day. The second is to gauge my long-term mood. If I wind up listening to the ghostly voice of Freddie Mercury singing The show must go on for a month straight that's when I start to think that serious action needs to be taken. And I've been there. I switched teams at a past job because I found myself in this dark place for a long time (this past job was actually how I developed this playlist). And even then, when nothing changed after switching teams I decided it was time to move on. </p> <p>And to be honest, that was the best decision I've ever made.</p>","tags":["Self Care","Work/Life Balance"]},{"location":"blog/my-personal-job-litmus-test/#conclusion","title":"Conclusion","text":"<p>Your mental health matters. Being unhappy in a job can drag you down into some very dark places. I stayed at a job for a year and a half hating my life wondering why none of my side projects were getting anywhere, why I didn't want to achieve the goals I had set for myself, and why my personal life was suffering. I know times are tough and getting a new job, especially in the current state of the world, can be scary or downright impossible. But life's too short to wake up every morning hating it. I didn't realize just how much a toxic work culture could drag you down until I left one. It's like having a weight lifted off your chest. I urge you all to find some way of being able to measure your happiness and satisfaction with your life. Because it's possible you'll wind up like me, confused and depressed, trying to figure out what's wrong when the answer was right in front of my face.</p> <ol> <li> <p>That being said, it's a beautiful song and if you haven't heard it, I highly recommend it. It chronicles Freddie Mercury's struggle to continue performing while losing his battle with AIDS.\u00a0\u21a9</p> </li> </ol>","tags":["Self Care","Work/Life Balance"]},{"location":"blog/exploring-new-waters-a-year-one-digitalocean-recap/","title":"Exploring New Waters: A Recap of My First Year at DigitalOcean","text":"<p>Another year come and gone, and what an adventure it was but I'm happy to say I have successfully completed my first year at DigitalOcean. Come, gather round and listen to the tale of a career change, being a Developer Advocate amidst a global pandemic, and everything else 2020 had to throw at me.</p> <p>So this blog post is a few months late. I wanted to post it on the anniversary of my first day at DigitalOcean, however between Hacktoberfest, deploy by DigitalOcean, and the launch of App Platform October and November were very busy for me. However, now that things have calmed down I can finally sit down and reflect on my first year at DigitalOcean as a Developer Advocate. </p>","tags":["DigitalOcean","Developer Relations","Developer Advocate","Community"]},{"location":"blog/exploring-new-waters-a-year-one-digitalocean-recap/#how-i-arrived-at-digitalocean","title":"How I Arrived at DigitalOcean","text":"<p>On October 1, 2019 I joined DigitalOcean as a Developer Advocate. This was my first step into an advocacy role after spending roughly four years professionally as a Software Engineer/Site Reliability Engineer<sup>1</sup>. This was going to be my  third role in under five years and I was feeling slightly down that I hadn't managed to stay at one place for longer than two and half years. I left my first role for reasons that honestly, looking back, I could have probably gotten over. But I was young and dumb(er) and the sudden shift in company focus, team changes, and the inability to decide on what we wanted to be triggered my fight or flight reflex and I left. My second job, the job I left to join DigitalOcean, was.... interesting to say the least. I learned so much about the Cloud, Availability, Scaling, and the list goes on. The Cloud platform I got to work on and maintain is still, to this day, one of the most impressive I've ever seen. However, the culture among my org was slightly less toxic than a nuclear waste dump. Without going into too much detail it sucked, I hated it, and became ever more depressed the longer I stayed there. So, I started looking for a new gig. While being miserable at my previous job I learned a neat little trick. If I got accepted to speak at a conference my boss would give me the time off to attend the  conference. He wouldn't pay for the conference, but honestly at that point anything I could do to get away was worth it. So, I started submitting talks and getting accepted to many different conferences across the continent. It was during this time that I became more aware of the Developer Advocate role and what it was. I applied for a handful of Developer Advocate roles, as well as some SE/SRE roles. While the idea of being an advocate was enticing, I wasn't quite sure if I wanted to take that step. And of course, fate would position me where I had to make that exact decision. I received offers for both a Developer Advocate role and a Site Reliability Engineer role at two different companies,  both of whom I was super excited to work at. I flip flopped at lot on which role I wanted to take but, in the end, I took the role at DigitalOcean as a  Developer Advocate. It was a hard decision, but I had become so disenfranchised with engineering in general I thought it would be a good choice to try something new. And, thankfully, I was correct.</p>","tags":["DigitalOcean","Developer Relations","Developer Advocate","Community"]},{"location":"blog/exploring-new-waters-a-year-one-digitalocean-recap/#how-this-year-went-october-1-2019-december-18-2020","title":"How This Year Went: October 1, 2019 - December 18, 2020","text":"<p>DigitalOcean prides itself on being a remote friendly company. When I started almost 70% of the company was fully remote and my role was going to be remote. That being said, most new sharks start their first week in the New York City office. I had never been to NYC so it was excited. Due to current events coming up in  the DigitalOcean company calendar my manager was able to allow me to start working the Monday after I stopped working at my previous job. This was due to the fact that DigitalOcean was going to be having its global company all hands  at Disney World in the middle of October and for me to go I needed to start within a window. I agreed and was able to convince my boss to let me  have the week off after my first week to kind of recuperate from my previous job. I fly out to NYC and get put up in one of the company's corporate apartments. Due to a majority of the company being remote these apartments were kept so  employees cannot have to worry with the hassle of a hotel when they come into  town. I get to the apartment and the first person I meet is Adam Harder, the new Video Marketing Manager. Later that evening my manager Eddie Zaneski arrived at the apartment since he was also spending the week in NYC. The next day we go  to the office and I go through the typical first day things. This is where things change. I am packing up my stuff when my manager Eddie comes by and says \"Are you ready to work an event?\". Turns out that night was the kickoff night for Hacktoberfest and I was going to help run the event. It was a lot of fun and I must say, that was the most interesting first day I've ever experienced.  Fast forward a few weeks and I'm off to Disney World for our company all hands. I got to meet so many people in the company, including all of my teammates, and just had the best time ever. My team was amazing. We got to take team pictures,  hang out, plan what we wanted to accomplish for the next year and just get to bond. The Developer Advocate team was finally fully staffed and ready to go. I leave  Disney beyond excited for what the future holds. We continue through the year as I settle in and meet more and more people in the company. We get started in 2020 and I was excited to get to work conferences. One of the main reasons I joined  was to get to travel and meet developers all over the world......and we see how  that all turned out. I am happy to say I did get to work one conference this  year. I attended Sunshine PHP in Miami, Florida in the first week of February  and I loved it.</p> <p></p> <p>Unfortunately, these happy times were short lived. Due to changes made within the company, the Marketing org, and people deciding to pursue options elsewhere  I was left the only remaining member of my original team. I'm not going to lie, it was kind of a blow. My previous team was amazing and to finally find a place that felt welcoming just to have it disappear was a huge downer. I contemplated if I should remain an advocate and even at the company. I decided to stay because I had just gotten started and hadn't even been able to actually do much Developer Relations work. I also wanted to see the new direction that my team was going to take. And on top of all of this, the world was grappling to deal with a global pandemic the likes of which hadn't been seen for a century. What was  Developer Relations and Community going to look like when I couldn't physically be with my Community? Luckily, I fortunate enough that my new manager was  someone I trusted within the company and had been a part of my previous  extended team. After that we picked up another Developer Advocate internally and then a contractor to help us with the logistical parts of the role and suddenly, I had a team again.And honestly, I'm so glad I stayed. While I miss my old team, my  current team is amazing. The direction, strategy, and charter of my team is amazing. We have measurable goals to work towards and I get to work with some of the best in Developer Relations. From product releases to Tech Talks (webinars) to  virtual conferences (both attending and hosting) to Hacktoberfest this year has been a new slate for Developer Relations at DigitalOcean. I feel that we  were able to navigate the pandemic situation and brought new life to virtual  events at a level that hadn't been seen before. I'm incredibly grateful for my team, my extended teams, the Marketing organization and DigitalOcean as a whole for making a challenging year much more enjoyable that it could have been. </p>","tags":["DigitalOcean","Developer Relations","Developer Advocate","Community"]},{"location":"blog/exploring-new-waters-a-year-one-digitalocean-recap/#2020-stats","title":"2020 Stats","text":"<p>So what all did I do this year? Here are the stats for my accomplishments of 2020:</p> <ul> <li>Code:<ul> <li>Added the DOCR resource and data source for the DigitalOcean Terraform Provider.</li> <li>Wrote multiple sample example applications for DigitalOcean's App Platform:<ul> <li>Django</li> <li>Flask</li> <li>Fortran</li> <li>COBOL</li> <li>Perl</li> </ul> </li> <li>Wrote multiple functional applications for DigitalOcean's App Platform<ul> <li>RSS Reader API</li> <li>App Platform Showcase API</li> <li>One Time Secret API</li> <li>URL Sortener API</li> </ul> </li> <li>Hacktoberfest Repo Label/Topic Manager</li> <li>Terraform Sample Architectures for DigitalOcean</li> <li>Education Tool for setting up a lab type environment using Droplets DigitalOcean Classroom</li> </ul> </li> <li>Content:<ul> <li>Wrote 6 Tutorials for DigitalOcean's Community Site<ul> <li>How To Use Visual Studio Code for Remote Development via the Remote-SSH Plugin</li> <li>How To Create A Minecraft Server On Ubuntu 18.04</li> <li>How To Create A Minecraft Server On Ubuntu 20.04</li> <li>How To Build a Slackbot in Python on Ubuntu 20.04</li> <li>How To Deploy a Django App on App Platform</li> <li>How To Deploy a Flask App Using Gunicorn to App Platform</li> </ul> </li> <li>Produced the following videos for DigitalOcean<ul> <li>Using Visual Studio Code for Remote Development</li> <li>Build a Django App on DigitalOcean</li> </ul> </li> </ul> </li> <li>Community:<ul> <li>Presented at the following conferences:<ul> <li>PyCon 2020 - Building Docs like Code: Continuous Integration for Documentation</li> <li>Open Source Summit - SLIs, SLAs, SLD\u2019OHs! Learning About Service Uptime from Homer Simpson</li> <li>PyOhio - There's a Snake in the Birdhouse! Building a Python Culture at Vrbo</li> <li>EuroPython - There's a Snake in the Birdhouse! Building a Python Culture at Vrbo</li> <li>PyBay - There's a Snake in the Birdhouse! Building a Python Culture at Vrbo</li> <li>PyTexas - There's a Snake in the Birdhouse! Building a Python Culture at Vrbo</li> <li>PyTexas - How to Build and Deploy Your First Python Slackbot on DigitalOcean's App Platform</li> </ul> </li> <li>Presented at the following meetups:<ul> <li>Chicago Python - SLIs, SLAs, SLD\u2019OHs! Learning About Service Uptime from Homer Simpson</li> <li>IndyPy - Infarstructure as Code using Terraform Workshop</li> <li>Evening of Python Coding - Mkdocs Intro</li> <li>One Valley - Strategies for Building Cloud Infrastructure</li> <li>Texas State University EXE Student Club - Building a Discord Bot</li> </ul> </li> <li>Presented the following Tech Talks for DigitalOcean:<ul> <li>Building a Minimal, Production-Ready Infrastructure on DigitalOcean</li> <li>Foundations of Computer Security</li> <li>Securing Your Droplet</li> <li>Top 10 Security Practices for Protectiong Your Infrastructure</li> <li>Command-line Your Way to PaaS Productivity With DigitalOcean App Platform</li> <li>Utilizing Security Features in SSH</li> </ul> </li> <li>Multiple livestreams on my Twitch channel Coding With Mason</li> </ul> </li> </ul>","tags":["DigitalOcean","Developer Relations","Developer Advocate","Community"]},{"location":"blog/exploring-new-waters-a-year-one-digitalocean-recap/#what-does-the-future-hold","title":"What Does The Future Hold?","text":"<p>My future holds many more enjoyable days at DigitalOcean. For the first time in my career I'm not looking to what's next or thinking about my next career jump. I am incredibly happy in my role and want to just enjoy that for a time.  Constantly thinking about the next step, the next jump, the next item on our  career checklist often causes us to miss the fun moments and doesn't allow us to just enjoy being in the moment. I finally found a company that feels like home, shares my values, and allows me to do the kind of work that I want to do.  They also support me by allowing me to further my career with courses and professional development. Next year I'm going to be participating in Stephanie Morillo's  DevRel CMS next year, I'm working on a book  proposal and experimenting with Zines. 2020 may have been challenging but for me, it was a good year to reset and introspect, preparing and motivating me to make 2021 a phenomenal year. </p> <p>Thank you to everyone who has and continues to support me and my work. I look forward to producing amazing content for y'all in 2021. Happy Holidays!</p> <ol> <li> <p>I had worked as a student at Texas State University managing labs and writing software while I was getting my degrees but our industry doesn't count this as \"real\" software engineering. I may write a blog about my opinion on this in the future but the tl;dr of that dismissive mindset is: \"That's bullshit.\"\u00a0\u21a9</p> </li> </ol>","tags":["DigitalOcean","Developer Relations","Developer Advocate","Community"]},{"location":"blog/django-or-flask-how-do-i-choose-which-to-use/","title":"Django or Flask: How Do I Choose Which To Use?","text":"<p>As a Python developer, I love both Flask and Django. But how do I choose which one to use?  Over the years I've developed a very simple test that helps me decide if I'm going to use Flask or Django for my projects.</p> <p>I love both Django and Flask. Due to the recent release of DigitalOcean's App Platform I have found myself writing more and more webservices using these two frameworks. I now find myself answering the same question very often, which is how do you choose which one to use? Well luckily I have a simple checklist of questions to ask myself that helps me determine which framework to use.</p>","tags":["Python","Django","Flask","Web Development"]},{"location":"blog/django-or-flask-how-do-i-choose-which-to-use/#the-questions","title":"The Questions","text":"<p>Currently I ask myself three questions to determine which framework I'm going to use. I will admit that currently I'm building mostly one-off applications and things for fun. If I was designing a large application for a company or open source project I would probably use these questions as a starting point, but I wouldn't use this as a finite decision maker.</p> <p>That being said, it's probable that you may not agree with my choices. This is fine. Each framework is 100% capable of solving every problem I throw at it. These are just my personal preferences after roughly 8 years of building Python microservices.</p>","tags":["Python","Django","Flask","Web Development"]},{"location":"blog/django-or-flask-how-do-i-choose-which-to-use/#database-access","title":"Database Access","text":"<ul> <li>Do you need to access a database like MySQL or Postgres?<ul> <li>Yes - Django</li> <li>No - Flask</li> </ul> </li> </ul> <p>I am a huge fan of the Django ORM. It was one of the first tools I learned when I started doing Python web development and it makes my life simple. So if I find myself needing a relational database I immediately find myself reaching for Django. There are other Python ORMS such as SQLAlchemy that are also good. Flask + SQLAlchemy is a perfectly fine choice as well. But I tend to go with the Django ORM. </p> <p>However, if I need a different data store, such as a Key Value store like Redis, I will find myself reaching for Flask. If I don't need the Django ORM I don't use it. It doesn't add to much value for me in this situation. It's all about the right tool for the job.</p>","tags":["Python","Django","Flask","Web Development"]},{"location":"blog/django-or-flask-how-do-i-choose-which-to-use/#user-authentication","title":"User Authentication","text":"<ul> <li>Do you want to have users be able to login to the system?<ul> <li>Yes - Django</li> <li>No - Flask</li> </ul> </li> </ul> <p>After the ORM my next favorite feature of Django is its authentication framework. This is another feature I've been using since I got started with Django and it has been fun watching it grow and gain features throughout the years. I enjoy this feature so much I have never implemented authentication in Flask. Maybe it's fantastic. I wouldn't know. I have always found Django's auth to be easy to use and extremely flexible. So, if I need user authentication, I always pick Django.</p>","tags":["Python","Django","Flask","Web Development"]},{"location":"blog/django-or-flask-how-do-i-choose-which-to-use/#container-size","title":"Container Size","text":"<ul> <li>If deploying a microservice, does size of container matter?<ul> <li>Yes - Consider Flask</li> <li>No - Consider Django</li> </ul> </li> </ul> <p>Sometimes when you're deploying microservices the size of your container makes a big difference. We would expect Flask, being a microframework, to have a smaller footprint than Django, which is exactly the case. Below is data regarding three docker containers that I've built. One is ubuntu with pip installed, one has flask installed and the other has Django installed. </p> <p><pre><code>ubuntu              ...     394MB\nflask               ...     398MB\ndjango              ...     428MB\n</code></pre> As we can see, there is a 30MB difference between the containers. This is just the base framework, not including other libraries and middleware. While this may not seem like a lot, it can make a difference in deployment environments. I rarely have to ask myself this question, but it is definitely something that needs to be considered.</p>","tags":["Python","Django","Flask","Web Development"]},{"location":"blog/django-or-flask-how-do-i-choose-which-to-use/#the-decision","title":"The Decision","text":"<p>Once I have run through my list I tally it up. If Django was an answer to the database or authentication questions that is usually enough for me to go with Django. However, if that isn't the case I almost always go with Flask. If I'm writing a small microservice, cron task, or even a small REST API Flask provides everything I need to write clear, concise code. It's not that Flask can't be used to build large applications. In fact, the first job I had out of college was building a huge REST API in Flask. I just enjoy writing smaller apps in Flask and larger apps in Django. </p>","tags":["Python","Django","Flask","Web Development"]},{"location":"blog/django-or-flask-how-do-i-choose-which-to-use/#conclusion","title":"Conclusion","text":"<p>So there you have it. That is how I determine if I'm writing my application in Django or Flask. The process may seem simple, but I have always been happy with the implementation of my apps. If I was working in a team or the code would need to be maintained by others I would use this framework to start a discussion instead of mandating a tech stack, but for my personal projects it's good enough for me. </p> <p>If you're curious about deploying Django or Flask to DigitalOcean's App Platform checkout this Django and Flask tutorial that I wrote. If you're new to DigitalOcean and want to try it out you can click here for a $100 free credit for 2 months with a new account.</p>","tags":["Python","Django","Flask","Web Development"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/","title":"Tech Industry Interviews are Bullshit. Let's Make Them Better","text":"<p>If you ask almost any programmer what their least favorite part of the industry is, they'll likely say interviewing. The Tech industry has transformed what should be a simple process into an unholy nightmare. When a majority of your industry says it loathes the interview process, perhaps we should examine it more and attempt to make it better.</p>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#lets-just-say-what-were-all-thinking","title":"Let's Just Say What We're All Thinking","text":"<p>Technical interviews suck. I don't think I've ever met someone who was like \"You know what my favorite part of our industry is? The interviews! I love being put on the spot and being harshly critiqued over my ability to think on the spot and recall random algorithms that no one ever actually uses in production.\" Yet, somehow, we continue to double down on a process that is not only extremely stressful but overwhelmingly biased.</p>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#lets-put-it-in-perspective","title":"Let's Put It in Perspective","text":"<p>Imagine you were interviewing for a job as a short order line cook at a restaurant chain. For this example, we'll call it French Toast House. You arrive at the restaurant for an interview and are greeted by the company's accountant. Now you'll never actually work with the accountant; you're a cook but the company wants people outside of the cooks to evaluate you. You have a nice conversation with the accountant, and you try to ask basic questions like, \"Do we work with gas or electric stoves?\". The accountant admits that they don't know; they have nothing to do with the preparation of food, but they do want you to solve this brain teaser about transporting a fox, chicken, and corn across a river. They get up to leave and ask if you have any questions about the job. You decide to not ask any because they are unaware of the cooking procedures within the kitchen and when you tell them you don't they frown and say \"That's a shame.\" </p> <p>You are then interviewed by one of the night shift cooks. They just finished cooking 100,000,000 pieces of French toast because last night was prom night and everyone decided to come to the restaurant at 3:00am in the morning. They look utterly exhausted and completely disinterested in being there. They ask you routine questions like what a stove is and how would you handle a grease fire, but then their pager goes off. They swear loudly because apparently more French toast is needed and it's their turn to be in the bi-monthly French toast hell. You ask if it is always like this and they laugh like a deranged person who just figured out they can put Red Bull in the coffee machine and never sleep again as they walk out of the room, leaving you alone for the next 10 minutes until it's time for the next interviewer. </p> <p>Your next interviewer is the Senior Short Order Line Cook. You spend the first five minutes getting to know each other but then the interviewer says it's time for \"a simple test, won't be too hard\". You are then asked to recreate Gordon Ramsey's famous Beef Wellington, but as an added challenge you aren't allowed to use any utensils. You are confused since you thought you were going to be making French toast, but the interviewer explains that they like to see how you do under pressure. You ask if you could go to the kitchen to attempt this experiment but are told to just diagram it on the white board. You muddle through the exercise as best you can with your limited knowledge of Beef Wellingtons but when it's over you can tell the interviewer is disappointed. They come up and show you how they would have solved it and tell you that it's a standard question from the Cracking the Short Order Line Cook Interview book. You're shown out of the building and told they'll get back to you with their decision soon. You make a mental note of how to cook Beef Wellingtons, just on the off chance it shows up at your interview at Burger Queen. </p> <p>If you were offered the job would you take it? Depends on your situation. You're pretty sure you'll be able to work with real utensils and not have to cook Beef Wellingtons but didn't see any evidence of this. Was this a fair interview process? No. Yet some version of this dynamic is currently being used to interview software engineers around the world, holding them to a much higher standard and rigging the situation against people who don't know the secret knock of admittance. </p>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#why-is-it-like-this","title":"Why Is It Like This?","text":"<p>To be honest, I have no earthly idea. I don't know where this form of interviewing came from. My assumption is that one of the larger companies decided to develop a hiring practice to ensure that they could \"attract and hire top talent\".(1) Then everyone else in the industry was like \"Hey look! Hooli does it like this, so should we!\". There's a very blatant issue with this approach. Your 30 person startup does not have the same hiring challenges as the wealthiest company on the planet. I don't know who needs to hear this, but you are not Hooli. You're not. \"Well if we continue growing our customer base...\" No. Stop. You do not move petabytes of data a day. You do not have 3 billion concurrent users. And let's be honest, these large companies don't need this kind of process either. The only reason they get away with it is because their reputation allows them to get away with it. If I were to give a conservative estimate I would say 95% of all software engineering jobs will not require the level of stringency that is tested in interviews. I think the following image explains it perfectly (big shout out to Dare Obasanjo for posting this on their twitter.   </p> <ol> <li>By the way, \"hire and attract top talent\" is just a fancy way of saying \"mask our discrimination by hiring people that look and think like us\".</li> </ol> <p>So, your small startup offering a store front for people to buy stuffed armadillos should not adopt these same interviewing methods. For one, they are extremely discouraging to participants. I personally know that I'm a competent engineer. These interviews make me feel like shit, hands down. I have to tell myself that \"Interview questions are not the real job. You can do the job, you just struggle jumping through their hoops.\" Secondly, adopting their practices means that you are validating these practices. And that's your choice; just know that some people, myself included, refuse to participate in interviews like this and you're potentially alienating your talent pool. If you really cared about \"top talent\", your interview practice would show it.</p> <p>If you want to attract the top talent, make your interview process match the level of expectation required for the job. </p>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#why-do-the-engineers-at-these-companies-participate-in-this-process","title":"Why Do the Engineers at These Companies Participate in This Process?","text":"<p>I honestly don't know. I know that I don't. I refuse. If I had to guess about other people, I'd say it's primarily a combination of lack of training mixed with a little bit of ego, revenge, and gatekeeping. </p>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#lets-talk-about-the-lack-of-training-first","title":"Let's Talk About the Lack of Training First.","text":"<p>I've worked in the software industry for about 9 years now, with my first three years being in academia. It wasn't until I joined DigitalOcean in October of 2019 that I ever received any form of interview training. Most engineers are thrust into the interview room with no further instructions than \"Interview this person.\" This actually surfaces a more pressing issue, and that is there is no formalized process around hiring. This is bad for both the candidate and the company. This means that there isn't any sort of standardized interviewing practices  not only across teams within the company but also within a single team that is interviewing multiple candidates  for the same role. This can lead to vastly different experiences for candidates and allow for bias to slip in. So when I think about it, it is kind of hard to be upset with engineers for reverting to the types of questions that they themselves were asked when they are given no training or guidance in interviewing. At that point, it is a failure of the company, not the individual interviewers.</p>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#do-you-really-think-some-people-care-about-where-you-went-to-school-or-imparting-their-struggles-onto-others","title":"Do You Really Think Some People Care About Where You Went to School or Imparting Their Struggles Onto Others?","text":"<p>Absolutely. I've witnessed it. I've been denied opportunities because of where I went to school and my inability to perform somersaults while saying the Greek alphabet backwards. If you ever want to be completely disheartened by this all you have to do is go read the Tech industry interview section on the Blind app.(1) The below bullet points are exact quotes from people I've heard in my career from interviewers and sadly enough, recruiters. </p> <ol> <li> <p>I don't recommend you do this. It'll just make you sad and upset.</p> </li> <li> <p>\"Well, I had to do XYZ when I was interviewing, so they should too!\"</p> </li> <li>\"I went to a Top 10 Computer Science School. Where did you go?\"</li> <li>\"I don't want to hire students from XYZ University, their program isn't good.\"</li> <li>\"We don't hire engineers from your University. (Said to me by a recruiter at a job fair on my university campus)</li> </ol> <p>This saddens me to no end. But it's a reality that we need to talk about. This came up as recently as two weeks ago when someone posted the interview criteria that ex-Googlers created while they were working at Twitter. A process, btw, that is disgustingly discriminatory. (Thanks to Leslie Miley for posting this)</p> <p></p> <p>I could go on but I'm literally getting upset writing this. So long story short: Yes these people exist. Yes it's completely unfair. Call it out when you see it, speak up in your company for fair interviewing practices (I'll go into this more later in the article) and don't repeat their mistakes. </p>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#does-everyone-do-this","title":"Does Everyone Do This?","text":"<p>Not at all. People tend to remember past bad experiences and that is exactly what happened in the paragraph above. For every asshole interviewer I've experienced I've dealt with three amazing ones. But it only takes one bad person in an interview panel to sour the entire experience. Oddly enough, I've found that it's usually the younger engineers who do this.(1) When I've interviewed with more senior engineers who haven't thought about how to balance a tree since their last interview(2) don't ask questions like this. They ask practical questions. I know one senior engineer who always asks the exact same interview questions regardless of level. He claims he can know everything about a candidate from three relatively simple programming questions, each of which should be solvable by a student who has finished a CS 101 course. I had another senior person set up a test where I had to debug an issue with a web server. None of this \"If you throw an egg down a hallway how many platypuses would it take to sing La Traviata\".(3) Questions that are actually relevant to the job that test proficiency, not familiarity with questions. </p> <ol> <li>If you're a younger engineer who doesn't do this, congrats! You're doing it right. Those who are doing this know who they are and probably will leave nasty comments or blast me on Twitter about this article.</li> <li>Or ever. Some of the best engineers I've ever worked with have 0 formal education in Computer Science.</li> <li>The answer is 17. 12 to sing the different parts and 5 extras in case any of them run after the egg. Usually the mean platypus attention span can be calculated by taking the sum of the number of platypuses divided by the average length of an egg. This can range from 53.12mm for a medium sized egg to 59.675mm for an extra large egg. For the sake of brevity I won't go into the math of converting platypuses to millimeters. </li> </ol>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#well-then-if-you-dont-like-it-whats-the-better-option","title":"\"Well Then, If You Don't Like It What's The Better Option?\"","text":"<p>I mentioned it above but I'll repeat Ask questions that are relevant to the job you're interviewing the candidate for. If you are interviewing someone for a job to work on the front page of your website, they probably don't need to know how to build a binary tree from scratch. And I'm sure if that odd case ever did actually come up they would do what every engineer(1) does, They'll Google It. It's as if everyone believes their workplace is this XKCD comic. </p> <ol> <li>Including you, snobby person currently interviewing the candidate.</li> </ol> <p></p> <p>Memorization of knowledge is an outdated measure of intelligence. We live in a world where I can ask literally any question I have ever wanted and get an answer instantly. Is having this knowledge in your mind advantageous? Absolutely. But is it an indicator of ability? Not in the slightest. In actuality it could become a hindrance. The amount of times I've learned something new about a topic I already felt very knowledgeable in because I chose to look something up to double check is non-trivial. The information in your head doesn't update unless you choose to update it. </p>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#how-i-interview-people","title":"How I Interview People","text":"<p>I enjoy interviewing people. It's always fun to add someone new to your team and the people you meet along the way are fascinating. I split my interviews into three parts:</p> <ol> <li>Let them talk about themselves</li> <li>Technical interview</li> <li>Discuss the job</li> </ol>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#part-1-let-the-candidate-tell-you-about-themselves","title":"Part 1 - Let the Candidate Tell You About Themselves","text":"<p>Candidates tend to want to tell you about themselves and their work. So let them. Questions like \"So tell me about yourself\" can be seen as vague but some candidates really enjoy that question. If they don't, try to make a more pointed question. \"Tell me about your last job.\" \"How did you get into programming?\" \"What is your favorite programming language and why?\" These are all really good ways to get a conversation going. My favorite question to ask is \"Tell me about a project that you're proud of.\" Most developers have had at least one project that they are super happy to talk about. The project might have taught them something new, been really fun to work on, or solved a complex issue. Whatever it is, you want to know about it because it will showcase the candidates ambition. I always hire enthusiastic, ambitious, and curious people ready to learn. That mindset is contagious and it elevates a team. </p>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#part-2-technical-interview","title":"Part 2 - Technical Interview","text":"<p>\"Wait Mason, didn't you just go on a long winded rant about how you hate technical interviews?\" To an extent. I hate technical interviews for the sake of cleverness. I do, however, acknowledge that we have to have some metric of determining ability. I have a three-pronged technical interview. The first question is for them to implement the classic \"Fizzbuzz\" program.(1) You may laugh, but you'd be surprised how many people are filtered out with this question. This is the bare minimum bar for me. If a candidate can't pass this then I believe they will benefit more from practice and study than a job that has demands. The second question I ask is for the candidate to implement the game of craps. I usually explain the game and have a printout for the candidate to reference. This assignment requires keeping state and iterating until an outcome is reached. Finally, I tend to ask a question about removing all duplicate characters from a string and getting a count of all the characters of the same type in a string. I love set theory so if you use a set for this question I smile on the inside. This is the question I'd like to see some form of data structures being used.</p> <ol> <li>Always give a detailed assumption of the program. Don't assume everyone knows what Fizzbuzz is.</li> </ol> <p>Note, none of the questions require advanced knowledge of data structures or algorithms. As someone who's worked in the DevOps space for a while, I rarely come across these concepts so I don't interview for them. I assume that the person who I hire will reach for these tools when necessary and if not that's what a code review and being a mentor is for.</p>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#part-3-discuss-the-job","title":"Part 3 - Discuss the Job","text":"<p>This might be the most controversial thing I say in this entire blog post. I show every candidate who does an onsite (or virtual onsite) our Jira backlog. I show them what the team is working on. I encourage them to ask questions about the backlog. It is just as much about them interviewing me as it is me interviewing them. I had an experience where I took a job and in our first sprint planning I looked at the backlog and saw not a single thing that I wanted to work on. I spent the next year and a half hating my job. I want to ensure that doesn't happen to anyone on my team. I also take this time to discuss architecture, the technologies we use, and ask questions about these technologies. If the role is for a Senior Kubernetes Engineer then I should definitely check their knowledge. If you have a good recruiting team supporting you though, this isn't as necessary because they should have already weeded out the people with little to know experience in the technologies you need. </p>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#after-the-interview","title":"After the Interview","text":"<p>Hopefully you're not the only person interviewing a candidate and there is a team of people relevant to the project. Trust your teammates. Tell them what you're going to be interviewing the candidate on so they can adjust accordingly. Everyone should interview every candidate with the same outline. Switching it up to how you feel that day just allows for bias. </p>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#how-can-this-be-made-better","title":"How Can This Be Made Better?","text":"<p>Talk with your manager. Talk with your teammates. Discuss how you can make the process better. Then take action. Here are some tips for an interview process that you can easily implement and improve your process:</p> <ul> <li>Discuss who will ask what. Make sure everyone doesn't ask FizzBuzz. Does everyone need to know the candidates life story or could that time be better used for other questions?</li> <li>Set your questions and ask the same questions for all candidates. This will help remove bias and ensure a fair process for the whole candidate pool.</li> <li>Hold your teammates accountable for their questions. If you see a question that you think is unnecessary ask your teammate what they are trying to learn from that question. Don't come off confrontational about this. People can get defensive over this topic really quick.</li> <li>Don't do group interviews. These are extremely intimidating and you will not get the results you desire from these.</li> <li>Debrief within 24 hours of the candidate exiting the building. Impressions are best fresh. </li> </ul> <p>A defined process will lead to a better experience for both the candidates and the interviewers.</p>","tags":["Interviews"]},{"location":"blog/tech-industry-interviews-are-bullshit-lets-make-them-better/#final-thoughts","title":"Final Thoughts","text":"<p>We can do better than this. I love the tech industry. The people who I've met here are amazing and the innovation is inspiring. Take action. Make an active attempt to make your process standardized. Make the interview process match the requirements. Developers talk. When we experience a good interview process we tell our friends and the same for a bad one. I've not applied at companies before because I've heard their process is awful. The changes you're trying to achieve won't happen overnight. It'll take time. The only thing I can tell you is that if no one tries to make things better that we all better get used to cracking open your copy of Cracking the Short Order Line Cook Interview and remember exactly how to make Gordon Ramsey's Beef Wellington. </p>","tags":["Interviews"]},{"location":"blog/random-musings-about-resumes/","title":"Random Musings About Resumes","text":"<p>Drafting a resume can be a nerve wracking experience. While there are many resources available for creating a resume, I still see the same mistakes year after year on resumes. In this post I'll discuss my philosophy regarding resumes and some tips on how to make yours better.</p> <ul> <li>My Resume for reference</li> </ul>"},{"location":"blog/random-musings-about-resumes/#my-resume-story","title":"My Resume Story","text":"<p>It's no surprise that drafting a resume can be a daunting task. You're essentially trying to make a first impression with a piece of paper that needs to be formatted in a specific way using specific language that can't be too long or too short. If you've ever been stressed out by your resume know that you're not alone. I feel the same way. I've read articles, visited resume building centers on university campuses, and even bought a few books on resume and technical writing. While I learned a lot of good information from these resources, I found myself pushing back on some of the recurring patterns I found. Like most university students, I found myself making my first resume in preparation for a job fair. After getting a first draft of my resume finished, I looked it over and was unhappy with it. It was bland, dull, and not a representation of who I was as a person. I took it to Career Services on campus to discuss it with them but was assured that my resume checked all of their boxes and was a successful resume. That didn't sit right with me and I thought to myself \"I'm going to make this the way I want to so that it represents me.\" So, I decided to break away from my colleagues at the time and not go with the default resume template in Google Docs and make my own using Latex.(1) Once I figured out what I was doing the result was something I was very proud of. I took my resume to the job fair and was complimented by every single recruiter I handed my resume to. Everyone loved the format and the fact that it had color, an element I was explicitly told to avoid. Since then, every single job that I've applied to has complimented me on the layout of my resume. When I started speaking at universities to students about their resumes I've tried to let them know that it's ok to deviate from the \"standard resume\". Below I'm going to go over the advice that I give students and working professionals regarding resumes.</p> <ol> <li>While some of you may be sitting here thinking \"Wow, that sounds like a terrible idea.\" let me assure you, it is way worse than you can possibly imagine. I currently have one laptop that I managed to install all of the packages correctly on that can compile my resume. I have tried to recreate it elsewhere and have failed. That laptop is forever more my \"Resume Generating\" laptop. One day it'll die and I'll have to change formats. But until then I just hold out against hope.</li> </ol>"},{"location":"blog/random-musings-about-resumes/#masons-resume-advice","title":"Mason's Resume Advice","text":"<p>I will be the first to say that I have very strong opinions about resumes. You may or may not agree with everything that I say here. All of these tips are based of my personal experience and what I've witnessed while being on hiring panels.(1)</p> <ol> <li>If you read this article and think to yourself \"He's completely wrong, I absolutely disagree with all of this\" that's fine. My feelings won't be hurt. Don't implement these tips then.  </li> </ol>"},{"location":"blog/random-musings-about-resumes/#tip-1-the-standard-template-is-boring-change-it-up","title":"Tip #1 - The Standard Template is Boring. Change It Up","text":"<p>Everyone uses the resume templates in Word or Google Docs. Everyone. And they're boring templates, devoid of color and any emotion. I dislike them and wish they would go away forever. Try to find a template with accent colors, maybe a two column template, maybe even a website theme that can be saved as a 1 page resume. Don't be afraid of color!(1)</p> <ol> <li>This is the biggest tip I get the most pushback on and I don't understand it. People always tell me \"Avoid color! All you need is headers and bulleted lists!\". While I can see how using colors may be difficult for someone who is visually impaired (hint: there are color schemes that address this), more often than not people who hold this bland ass opinion are trying to jam way too much into their resume and need every spare millimeter to put another irrelevant piece of information. </li> </ol>"},{"location":"blog/random-musings-about-resumes/#tip-2-objectives-are-pointless-use-that-space-for-something-else","title":"Tip #2 - Objectives Are Pointless. Use That Space For Something Else","text":"<p>Get rid of these. Period. Objectives are my biggest pet peeve on resumes. Unless you are legitimately trying to trade me 3 chickens for one of my goats I know you're trying to get a job! You sent me your resume! You didn't send it to me so I could frame it and walk by it every day. You sent it because you want a job! Space on a resume is valuable real estate. Anything that doesn't need to be there is only taking up space from something more important. I prefer to replace this with an About Me section. Tell me who you are. What do you like to work on? What are you passionate about? My About Me says I like backend work, specifically Python, along with teaching and open source. This section is at the top of the page. The goal is for a recruiter or hiring manager to read it and be able to immediately go \"This person is/isn't a good potential candidate for this role\" before they ever even get to my experience.(1) Tell people who you are up front and save everyone some time.</p> <p>1.It's also a great conversation starter for recruiters/hiring managers. They already know something about me that's true because I told them. They didn't have to extrapolate it.</p>"},{"location":"blog/random-musings-about-resumes/#tip-3-dont-just-list-your-responsibilities-focus-on-their-impact","title":"Tip #3 - Don't Just List Your Responsibilities. Focus On Their Impact","text":"<p>I always see resumes that list the job and then have a bulleted list of tasks that they completed at that job. While this does inform on what you worked on, it in no way focuses on why you were doing it or what it accomplished. </p> <p>Example: You worked for a small e-commerce startup and you were responsible for implementing the shopping cart feature. You put this on your resume:</p> <ul> <li>Wrote a web application using Flask, SQLite, and React for customers to use at checkout.</li> </ul> <p>This tells me nothing other than what technologies you used and the general vicinity of the purpose. Try rewriting it in this format:</p> <ul> <li>&lt;THING THAT WAS ACCOMPLISHED&gt;&lt;HOW YOU DID IT&gt;&lt;WHAT YOU USED TO DO IT&gt;</li> </ul> <p>So let's rewrite the example above</p> <ul> <li>Provided a seamless and enjoyable checkout experience for customers by implementing a shopping-cart web application using Flask, SQLite, and React.</li> </ul> <p>Immediately this tells me the impact you had, what you did and how you did it. It highlights your accomplishments and allows me to gauge the impact of your work because you told me the impact.</p>"},{"location":"blog/random-musings-about-resumes/#tip-4-brag-about-yourself-resumes-are-not-the-time-to-be-humble","title":"Tip #4 - Brag About Yourself. Resumes Are NOT The Time To Be Humble","text":"<p>Before we go any further, I know I have to address this. Do not put that you're a 10x engineer or the Superman of programming. When I say brag about yourself, I don't mean delve into the land of hyperbole. I mean be prideful of your accomplishments. Talk about them. I often see people downplay their contributions and that is a sure way to get passed over in a screening. If you don't believe in your work how can you convince others to? Don't be afraid to take credit for your work. When implementing the above tip where you describe the impact, talk about if as if you are a CEO selling the new feature to the board. They aren't going to say \"Ya, it's alright\". They're going to act like it's the swiss army knife of features that'll mow your lawn, do your taxes, and it's a hot plate.(1)</p> <ol> <li>\"And a hot plate!\"</li> </ol>"},{"location":"blog/random-musings-about-resumes/#tip-5-leave-out-or-condense-irrelevant-data-focus-on-the-data-that-shows-you-off","title":"Tip #5 - Leave Out or Condense Irrelevant Data. Focus On The Data That Shows You Off","text":"<p>Length is usually a hot point of contention regarding resumes. Many people think that a resume should only ever be 1 page and that's it.(1) I personally don't prescribe to this philosophy. If you have 10 years of relevant experience then you should list it. But the key point to that last statement is the relevant experience part. If you're a traditional student who is attempting to get their first job you don't need more than 1 page. In fact, I would highly discourage you from going over. If you've worked side jobs here and there that doesn't really show me your skills as a software engineer. I'm not saying you should include them, but 5 list items of the different pizza delivery jobs you had isn't necessary. Be sure to include any leadership or extra responsibilities here. Condense that down to one and say Various Pizza Delivery Jobs. This will again, save you valuable space on your resume for projects, coursework, volunteer work, etc.</p> <ol> <li> <p>I feel this is a leftover vestige of when every resume was printed out and had to be distributed physically to be reviewed. Multiple pages probably meant staples and a stack of resumes to sift through makes length an issue. But now that we do most things digitally and we have auto screening programs(1) that filter a lot of resumes out now. </p> <ol> <li> <p>I have my own thoughts on these but that's a rant for another day.(1)</p> <ol> <li>Oooh, an annotation in an annotation. That's nifty. Ok. I'll stop now.</li> </ol> </li> </ol> </li> </ol> <p>However, if you have previous professional experience in another field I would say that you should definitely include it. You may not need your entire work history, but a list item dedicated to acknowledging your past professions is 100% acceptable. I personally encourage it. I know many educators who are leaving the field to be software engineers. They always ask, \"Should I put this?\" and I startle them when I shriek \"YES! Being an educator is hard. You had a profession that taught you skills that will be relevant to any job. Include it!\"(1) I have another friend who was the creative director of Cirque de Solei for near of a decade and was one of the premier jazz trombonists in the world who recently decided he wanted to go into programming. He also asked if he should include that and I was baffled. Like, you were (and still are) a famous musician. Of course you put that! There are a lot of second career people joining tech now. Your journey is a part of you and you should embrace and include that. I personally, want to know all about it.</p> <ol> <li>This is usually when they take my caffeine away from me and make me sit down.</li> </ol>"},{"location":"blog/random-musings-about-resumes/#tip-6-ordering-matters-you-probably-shouldnt-lead-with-your-educationuniversity","title":"Tip #6 - Ordering Matters. You Probably Shouldn't Lead With Your Education/University","text":"<p>This one I'm mostly putting because I want to rant about it. Your About Me (if you have one) and experience should always be the most prominent thing on your resume. Next you can maybe have a section dedicated to your skills, volunteer work, outside projects, awards, etc. Notice how I don't list education there. Education is important. It should be on the page. It does not need to be anywhere near the top. I have heard some resume reviewers at \"prestigious\" schools say that it should be at the very top and even some recruiters from some companies. The next thing I'm going to say is very important so I'm going to emphasize it for effect</p> <p>This is utter bull shit.</p> <p>There are some companies that care greatly about where you got your education.(1) And they have the audacity to publicly muse \"Why don't we get more diverse candidates?\". Well when you only focus on a handful of schools that also have diversity problems you don't get to play the surprised card when your workforce all identify within the same demographic. Personally, I refuse to put my education high up on my resume. After your first job it is old, irrelevant data. After I got my first job I immediately removed my GPA. Who the hell cares?</p> <ol> <li>Looking at you FAANG.</li> </ol> <p>Unfortunately, me being pissed about this won't change these company's practices. I personally refuse to work for companies that think the school that I attended mandates my professional destiny, but they do pay a lot of money. If you want to play their games I can't stop you and you may want to include your education as the first thing. </p> <p>I won't.</p>"},{"location":"blog/random-musings-about-resumes/#things-i-didnt-cover","title":"Things I Didn't Cover","text":"<p>No doubtedly there are things that I didn't cover that may have some of you going \"But You Forgot to Talk About ___\". The reason I left your favorite resume pet peeve is because :</p> <ul> <li>I don't think it matters as much as others think it does.</li> <li>It wouldn't apply in a broad sense. There are definitely tips I can give that are more targeted towards specific fields, but I wanted this article to be generalized.</li> <li>I forgot \u00af\\_(\u30c4)_/\u00af</li> </ul> <p>At the end of the day, your resume is an opportunity to express yourself. We want to know who you are and your resume is our first glimpse into that. While experience matters, you'd be surprised how often \"Would this person vibe with the team\" has a large part to play in hiring decisions. You can teach someone to do almost anything, it's really hard to teach them to not be a jerk.</p>"},{"location":"blog/swimming-with-the-sharks-year-2-do/","title":"Swimming with the Sharks: A Recap of My Second Year at DigitalOcean","text":"<p>This year was definitely a year of extremes. From the highest of highs to the lowest of lows, this year will not be forgotten anytime soon. You know the drill, grab a hot beverage, a blanket, and gather round as I recap the year that was 2021.</p> <p>So, as always, with my blog posts that have a deadline, it's late. To be fair, I've been stuck on a blog post for about 6 months, and at this point, I don't know if it'll ever get published. I hope it does, but it's controversial, to say the least. In all that commotion, I forgot to do a yearly recap. So here we go.</p>","tags":["DigitalOcean","Developer Relations","Developer Advocate","Community"]},{"location":"blog/swimming-with-the-sharks-year-2-do/#year-2-at-digitalocean","title":"Year 2 at DigitalOcean","text":"<p>This year I wrapped up my second full year at DigitalOcean as a Sr. Developer Advocate, having leveled up to a Senior role in June! I'm incredibly grateful to my peers at DigitalOcean for making it a stellar year, despite the difficulties we faced. </p> <p>If I had to describe 2021 as one word, I would describe it as \"extreme.\" I mean this in a sense, that things were either really good or really bad. For the bad, this year, I faced the heartbreak of losing not one but two very close coworkers to illness. This was a first for me. Both of these individuals were legends in their roles, and the shock of losing them derailed the organization for a bit. How could it not? To Hollie and Peeyush, you're missed more than you know.... Despite this, we continued on and still managed to pull off amazing feats this year. </p> <ul> <li>DigitalOcean went public! </li> <li>I got to help hire two new members to my team! <ul> <li>Welcome, Phoebe and Kim!</li> </ul> </li> <li>I was promoted! </li> <li>We finally created a web show called Cloud Chats which I got to help design and host. </li> <li>Created an education program for Marketing around DO products<ul> <li>I taught my CMO and the Marketing team how to deploy to Kuberenetes<sup>1</sup>.</li> </ul> </li> <li>Made lead of DigitalOcean Navigators program.</li> <li>Continued to help educate and empower the Community</li> </ul> <p>These are just some of the events that made 2021 the year that it was. I'm proud of my team, my extended teams, the Marketing organization, and DigitalOcean as a whole for making it through this challenging year.</p>","tags":["DigitalOcean","Developer Relations","Developer Advocate","Community"]},{"location":"blog/swimming-with-the-sharks-year-2-do/#2021-stats","title":"2021 Stats","text":"<p>So what all did I do this year? Here are the stats for my accomplishments of 2021:</p> <ul> <li>Code:<ul> <li>Updated PyTexas Website pytexas.org</li> <li>Prepare Technical Demos for numerous Tech Talks MasonEgger-Edu</li> <li>Hacktoberfest Repo Label/Topic Manager Improvements</li> <li>Education Tool for setting up a lab-type environment using Droplets DigitalOcean Classroom</li> </ul> </li> <li>Content:<ul> <li>Wrote 4 Tutorials for DigitalOcean's Community Site<ul> <li>How To Build a Discord Bot in Python on Ubuntu 20.04</li> <li>How To Install the Windows Subsystem for Linux 2 on Microsoft Windows 10</li> <li>How To Develop a Docker Application on Windows using WSL, Visual Studio Code, and Docker Desktop</li> <li>How To Set Up an ASGI Django App with Postgres, Nginx, and Uvicorn on Ubuntu 20.04</li> </ul> </li> <li>Wrote 10+ issues of DigitalOcean's Infrastructure as a Newsletter IaaN</li> <li>Produced numerous short \"Quick Start Videos\" for DigitalOcean's YouTube page</li> </ul> </li> <li>Community:<ul> <li>Appointed Conference Chair of PyTexas 2022</li> <li>Created and Hosted 40 Episodes of Cloud Chats</li> <li>Presented at the following conferences:<ul> <li>Python Web Conf - A Year Without Pants: Strategies for Successful Remote Work</li> <li>PyOhio (Short Version) - The Enters and Exists of Context Managers</li> <li>Conf42 Python - The Enters and Exists of Context Managers</li> <li>DigitalOcean Deploy - Grow Your Business with Scalable Apps Using DigitalOcean App Platform</li> <li>All Things Open (Short Version) - Write Docs Devs Love - Tips and Tricks to Level Up Your Tech Writing</li> <li>All Things Open - Let Me Introduce Y'all to Y'all</li> <li>PyGotham - Write Docs Devs Love - Tips and Tricks to Level Up Your Tech Writing</li> </ul> </li> <li>Presented at the following meetups:<ul> <li>PHPdx Hacktoberfest Presentation</li> <li>Texas State University EXE Student Club - Hacktoberfest Presentation</li> <li>Texas State University EXE Student Club - Intro to Python</li> <li>PyCharm Tech Talk - Building Your First Slackbot in Python</li> </ul> </li> <li>Presented the following Tech Talks for DigitalOcean:<ul> <li>Top 10 Tips for Protecting Yourself and Your Data Online</li> <li>Keeping Your Sites and Users Safe Using SSL</li> <li>Getting Started With Flask</li> <li>Build a Web App With Django</li> <li>Building a REST API With Django REST Framework</li> <li>Getting Started With Python FastAPI</li> <li>Deploying Your Python Applications</li> <li>Developing on Microsoft Windows With the Windows Subsystem for Linux (WSL)</li> <li>Building Your First Slackbot With Python</li> <li>Jumping Into Django Models</li> <li>Getting Started With Kubernetes on DigitalOcean</li> <li>Build Your First Command Line Tool in Go</li> <li>Build and Deploy a Custom Droplet Image on DigitalOcean</li> <li>Learn to Load Balance Your High Traffic Sites</li> </ul> </li> <li>Multiple livestreams on the DigitalOcean Twitch channel DigitalOceanTV</li> </ul> </li> </ul>","tags":["DigitalOcean","Developer Relations","Developer Advocate","Community"]},{"location":"blog/swimming-with-the-sharks-year-2-do/#what-does-2022-hold","title":"What Does 2022 Hold?","text":"<p>Barring some disaster, 2022 will find me continuing to grow as a developer and Developer Advocate at DigitalOcean. I'm still enjoying waking up and going to work every morning. As long as that is the case, I'll stay where I am. When the day comes that I start to dread going to work every day, that's when I'll depart. But I do not anticipate that happening anytime soon.</p> <p>Next year I have a lot of projects I want to expand upon. Some of which are work-related that I can't necessarily speak about publicly at the moment, so instead, here are some of my personal goals for 2022. I'm putting these out into the world to hold myself accountable:</p> <ul> <li>No sodas<ul> <li>I did this in 2020 and was super proud of myself. 2021 saw a backslide given the state of everything, so 2022 is a course correction for this.</li> </ul> </li> <li>Lose 50 lbs<ul> <li>I have long struggled with my weight, which is a super sensitive subject for me. 2022 is the year I take control of my health again</li> </ul> </li> <li>Write &amp; publish a book<ul> <li>I have been kicking this can down the road long enough. It's time I finished my proposal and get a book published.</li> </ul> </li> <li>Spend at least 10 hours a week writing code<ul> <li>Believe it or not, Developer Advocates can go months without writing a single line of code<sup>2</sup>. I want to get back into the habit of writing code regularly</li> </ul> </li> <li>Become a Full Stack Developer<ul> <li>It's time. I've been avoiding Front End work my entire career, and it's time that I sit down and learn how to do it. At least to the proficiency level that I can build my own front end to applications I'm building.</li> </ul> </li> </ul> <p>Thank you to everyone who has supported me and my work. I look forward to all of the challenges that 2022 has to bring. Happy Holidays and a Happy New Year!</p> <ol> <li> <p>The title of my autobiography will be called \"Kubernetes for Marketers.\"\u00a0\u21a9</p> </li> <li> <p>I don't include my \"Hello World\" type coding here. Sure I write sample apps and such, but these are so low level that, at least to me, it's not sufficient to keep up my skills. I want to write and build actual production.\u00a0\u21a9</p> </li> </ol>","tags":["DigitalOcean","Developer Relations","Developer Advocate","Community"]},{"location":"blog/how-i-write-conference-talk-proposals/","title":"How I Write Conference Talk Proposals","text":"<p>As a Developer Advocate, speaking at conferences is an integral part of my career. I submit many papers to conferences all around the world. Over the years, I've developed a process for thinking about, writing, and submitting talks for conferences. In this post, I'll share with you my process for writing CFPs.</p> <p>So you want to speak at a conference? Congrats! That is a fantastic goal! The decision to speak at conferences was one of the best decisions I have made in my career. I've learned so much, made countless friends, and had some of the best times of my life at various tech conferences. Whether it's your first time speaking or your thousandth, I hope you get something useful out of this post.</p> <p>In this post, I'll cover how I approach writing CFPs. Having not only spoken at many events and participated on program committees for various conferences, I'll share with you the practices that I have either used or seen in successful talk proposals. </p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#first-things-first-determine-your-audience","title":"First Things First, Determine Your Audience","text":"<p>A common mistake I see people make when they first decide to speak is to jump straight into brainstorming a topic that they want to talk about. This isn't a bad way to approach this, but people often struggle to think of a topic for one big reason: they can't visualize their audience. Are you giving your talk to a room full of C-Suite individuals? Students? DevOps Engineers? Determining your audience and their skill level will guide you to topics that may be of interest to them.</p> <p>For Example: I enjoy talking to the Python community and DevOps/SRE communities. Which almost immediately disqualifies talks about JavaScript frameworks(1) from my list of possible topics. This may seem simple. You may be asking yourself, \"Why even write this?\" But you'd be surprised how many people I've helped with CFPs who I unstuck after asking \"Well, who do you want to present to? Who is your audience?\"</p> <ol> <li>But not entirely, maybe you want to introduce, say, the Python community to this amazing JavaScript Framework. Go for it! Just be sure to show your audience how they can utilize it. </li> </ol> <p>Once I have determined my target audience(s), I then think about topics.</p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#how-to-pick-topics","title":"How To Pick Topics","text":"<p>So now that I have my audiences in mind, I ask myself the following questions:</p> <ul> <li>What is exciting in that community right now?</li> <li>What topics are people talking about in that community right now?</li> <li>What topics aren't being talked about right now that I think should be discussed?</li> <li>What topics do I want to talk about?</li> <li>What issue am I trying to solve/address?</li> </ul> <p>If I have multiple audiences in mind, I will briefly explore the overlap between them. Depending on the sprawl of your audiences, this may be easy, or it may be virtually impossible. Don't feel bad if you can't find a technical topic covering both.</p> <p>For Example: Python and DevOps have a good amount of overlap. I could explore topics such as using and/or extending Ansible, a Python-based DevOps tool. I could explore topics around simplifying the deployment of Python applications. The overlap here isn\u2019t to hard to find. These talks are likely to be good candidates for both Python and DevOps conferences. But I don\u2019t have to do this. Maybe I want to write a talk that\u2019s solely about Python fundamentals. Great! I just would\u2019t submit it to the DevOps conferences.</p> <p>On the flip side, finding overlap can be nearly impossible. Say I\u2019m interested in CSS and Kubernetes(1). Trying to find a talk that is applicable and interesting to both communities isn\u2019t impossible, but you may spend more time trying to find it than you want.</p> <ol> <li>An odd pair, but not completely unheard of.</li> </ol> <p>While it is important to focus on topics the community might find useful, it is just as important to focus on topics that you actually want to speak about. Excitement and engagement is contagious, and if you are excited about a topic then your audience will be too. There\u2019s few things worse than listening to someone give a talk about something they aren\u2019t interested in.</p> <p>Once I have determined the topic that I want to talk about, then I start to think about what level I want to write my talks.</p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#talk_levels","title":"Talk Levels","text":"<p>I typically categorize talks based on the audience level,  difficulty level, and the tool level.</p> <p>In most CFP systems, you'll see options for the following audience levels:</p> <ul> <li>Beginner</li> <li>Intermediate</li> <li>Advanced</li> <li>All</li> </ul> <p>Audience level is the level of expertise you expect the average audience member to have. Audience level can be more of a \"minimum requirements\" level than a cap. You may want to institute basic prerequisites for your talk so people know what to expect before going in. For example, if I'm giving a talk on little-known SSH features, I would expect the audience to have a basic understanding of *Nix like systems and maybe even that they have used SSH in the past. Having a set idea of your desired audience will help you know where to start your talk. If my audience were beginners, I might start by introducing SSH. If I know they're more advanced, maybe I can skip past that part or cover it quickly. This doesn't mean that intermediate and advanced developers won't benefit from a beginner talk on an unfamiliar topic, of course. You'd be surprised how often more experienced developers attend beginner-focused talks to stay sharp.</p> <p>Difficulty level is the knowledge level at which you target the talk on this specific topic. This is different from audience level because you have direct control over this. When writing my talks, I always keep difficulty level in mind to ensure that I don't sway too far off course. This can help me keep from going too in-depth on a beginner talk to keeping me from spending too much time on basic concepts in an advanced talk. Some topics are complex by their very nature. Don't worry, you can give different-level talks on the same core topic. </p> <p>Example: The Python GIL(1),(2)</p> <ol> <li>There are three things in life that are constant: Death, Change, and there will be a talk on the GIL at PyCon this year.</li> <li>For those of you that don't know, the GIL is the Global Interpreter Lock, and it is the thing responsible for Python not being able to run on more than one CPU core, blocking true parallelism. It's also the thing that stops you from having to track down wacky-ass race conditions and other super fun bugs that disappear and reappear due to the nature of concurrency, so maybe don't look a gift horse in the mouth, ok?  </li> </ol> <p></p> <ul> <li>Beginner level talk - \"What is the GIL and why you should care\"</li> <li>Intermediate level talk - \"How I Got Around The GIL by doing X\"</li> <li>Advanced level talk - \"A Deep Dive Into Garbage Collection and the GIL\"</li> <li>All level talk - \"How Python Core Developers are approaching removing GIL\"</li> </ul> <p>As you can see, you can fit any topic to any level. Sometimes I have varying slides in my deck that I hide/unhide depending on the audience level.</p> <p>Also, note how there is an All Level category. While some conferences will use these interchangeably, that doesn't mean that they are. Advanced developers sitting in a beginner talk about the basics of Python Strings may not benefit from that talk. However, a talk about how to build a community around your Open Source project is likely to be enjoyed by everyone of all levels. </p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#arent-audience-level-and-difficulty-level-extremely-similar","title":"\"Aren't Audience Level and Difficulty Level extremely similar?\"","text":"<p>Yes. They ask a lot of the same questions, they just have a different focus. You can often use one to help craft the other. Knowing the difficulty level you want to speak at somewhat mandates the audience level and vice-versa. Even in my process, I don't explicitly write down the difficulty level of my talks, just the audience level. I have, however, thought a lot about both. So while they are incredibly similar, they are distinct enough to think of them separately. </p> <p>Finally, let's talk about tool level. This is very subjective as many people will disagree with what is considered a beginner tool or not. However, there are many tools that obviously fit into a category. No one on Earth has ever said that Kubernetes is a beginner-friendly tool.(1) So, while your opinions on this may vary, it is good to understand your topic's perceived skill level. I find it easy to just have the following levels:</p> <ol> <li> <p>And if you have, I call bullshit.</p> </li> <li> <p>Beginner</p> </li> <li>Intermediate</li> <li>Advanced</li> </ol> <p>This primarily helps me understand how much work and care I need to take when writing the talk. Say I want to give a Kubernetes talk at the beginner level. Kubernetes isn't typically considered a beginner tool, so bringing it to a level that a beginner can understand may prove challenging. As you saw above in my audience level section, you can talk about anything at any level. Keeping tool level in mind also stops me from writing Advanced Advanced proposals. </p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#your-topic-doesnt-have-to-be-complex","title":"Your Topic Doesn't Have to Be Complex","text":"<p>A mistake I made very early in my speaking career was trying to write obscenely complex talks on edge case topics. The first proposal I ever wrote for a Python conference was about building python packages as <code>RPMs</code> so you could utilize the CentOS package manager to handle both system and Python packages. This talk never got selected, and rightfully so.(1) The proposal was overly complex and an extreme fringe niche. That isn't to say that complex or unique ideas won't get accepted, but they should represent an interesting problem or a use case that a subset of the community will experience. My talk was neither. </p> <ol> <li>It's my talk, so I can shit on it. While it was an interesting problem, it would have appealed to, like, two people.</li> </ol> <p>From an organizer's point of view, complex talks can be difficult to schedule. We have to think of our attendees as a whole. Very few conferences consist of solely advanced engineers. A lot of beginners attend conferences as well. Therefore, we have to strike an even balance of talks. This tends to have us scheduling mostly beginner/intro talks(1), followed by intermediate talks, and then a handful of advanced talks. So, complex and advanced talks will have fewer slots allocated to them, reducing the chance of your niche talk being selected.</p> <ol> <li>Note here that intro talk doesn't necessarily mean beginner. It means that it is an introduction to a topic. The topic itself could be advanced. What it isn't is a rare one-off use case on a rarely used feature in an advanced library.</li> </ol>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#your-topic-doesnt-have-to-be-technical","title":"Your Topic Doesn't Have to Be Technical","text":"<p>Another common misconception I see is that talks have to be technical. This couldn't be further from the truth(1). Talks on community, soft skills, non-technical skills such as leadership, program management, etc., are all great options.</p> <ol> <li>In fact, some of my favorite conference talks have had nothing to do with programming at all.</li> </ol> <p>Now that I've thought about who I\u2019m speaking to, what I want to speak about, and the tool level I want to hit  I turn to my personal process for writing my CFP.</p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#how-i-write-cfps","title":"How I Write CFPs","text":"<p>Over the years of applying to many different conferences that all seem to use a different CFP program and process, I've developed a template to write every single one of my talks. This template can be rather non-linear. I don't just fill it out top to bottom. I bounce around using previous sections to help write the next. You can see my template below or find it on my GitHub here. Below this, I'll explain how I use every section of my template.</p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#my-cfp-template","title":"My CFP Template","text":"<pre><code>## Type\nTalk, Workshop, Lightning Talk\n\n## Title\nSome Fun, Clever Title\n\n## Category\nSingle Overarching Theme\nEx: DevOps, Python, Community\n\n## Elevator Pitch (300 Character Limit)\n300 characters or less elevator pitch. \nInclude Audience Takeaways\n\n## Audience\n* Who is this for?\n* Can be many different audiences\n\n## Audience Level\nExpertise required for this talk\nInclude prerequisites\n\n## Audience Takeaways\nWhat will the audience take away \nand/or learn from this talk? \n\nShould be 3 things\n\n## Outline\n* Timed outline (1 min)\n* For the Presentation (5 min)\n* More detail is good here (20 min)\n\n## Description\nSlightly longer description. \nExpands upon elevator pitch. \nBe sure to include Audience Takeaways\n\n## Internal Notes (For Your Eyes Only)\nAll the nitty-gritty of the talk. \nYour scratch paper\n\n## Additional Notes\nAnything else. \nPresentation materials needed\nWhy you're qualified to speak on this\nEtc.\n</code></pre>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#type","title":"Type","text":"<p><pre><code>Talk, Workshop, Lightning Talk\n</code></pre> What type of presentation is this? What format will work for this presentation? When you have a lot of papers, it's good to have this right at the top so you don't waste time trying to figure out what you meant when you wrote this six months ago. There can be more than one type. It's rare, but I do have a few talks that could both be Talks and Lightning Talks, depending on what I omit.</p> <p>Options include:</p> <ul> <li>Talk (Usually 15 - 45 minutes)</li> <li>Workshop (Usually 60 - 180 minutes)</li> <li>Lightning Talk (Usually 5 - 10 minutes)</li> </ul>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#title","title":"Title","text":"<p><pre><code>Some Fun, Clever Title\n</code></pre> To me, the title of a talk is everything. It needs to be catchy while also setting expectations for the talk. I am a big fan of the \"Catchy first title: explanation subtitle\" format. You'll see most of my talks have this title format.</p> <p>For example:</p> <ul> <li>Docs Like Code: Continuous integration for documentation</li> <li>SSH Can Do That?: All the things you didn't know about SSH</li> <li>A Year Without Pants: Successful Strategies for Remote Work</li> </ul> <p>However, I don't constrain myself to this format. It is my favorite, but sometimes it just doesn't work. But titles should be entertaining and engaging. Attendees have to choose from a wide array of talks that they are given very little information on. Having a good title will attract them to your talk. And remember, the conference organizers and talk selection committee are also your audience. Another one of my talk titles is \"The Enters and Exits of Context Managers.\" From the outside looking in, this talk is a bit confusing. It does explain that you're going to be learning about Context Managers, but with a little joke. The joke here is that <code>__enter__</code> and <code>__exit__</code> are ways to create a Context Manager in Python. This is a play on the phrase \"The ins and outs\" by changing it up with synonyms that fit perfectly.(1)</p> <ol> <li>As someone who enjoys clever wordplay, I'm still proud of myself for this talk title. I consider it one of my crown achievements.</li> </ol> <p>Another tip I have for titles is to make them Iambic(1). If you don't know what this is, I highly recommend you look it up. The tl;dr is that, in English, it is pleasing to hear words that follow a short syllable followed by a long syllable. It's rhythmic and oh so complex. </p> <ol> <li>AP English for the win. </li> </ol> <p>If you are writing a paper in a language other than English, I would recommend looking into what speech patterns are pleasing in that language.</p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#category","title":"Category","text":"<p><pre><code>Single Overarching Theme\nEx: DevOps, Python, Community\n</code></pre> Your category is a single overarching theme of the talk. I am adamant about keeping this as a single category. If I find myself with many different categories and no prevailing one, then the talk is too complex, and I need to simplify it. Try to hold yourself to this; it will make your talk clearer.</p> <p>Examples: </p> <ul> <li>DevOps</li> <li>Python</li> <li>Community</li> </ul>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#elevator-pitch-300-character-limit","title":"Elevator Pitch (300 Character Limit)","text":"<p><pre><code>300 characters or less elevator pitch. \nInclude Audience Takeaways\n</code></pre> Papercall is a popular platform that conferences use to gather papers. The first part of their format includes the \"Elevator Pitch\" and they have a limit of 300 characters or less. I used to dislike this format, but now I think it's become my strongest asset. This is a great way to write an abstract. There's the old quote, \"If I had more time, I would have written a shorter letter.\" Concisely portraying your thoughts on a specific topic is not a trivial effort. When I write an elevator pitch, I tend to have a two-way process. I'll either write a longer description and prune it down to fit the elevator pitch, or write the elevator pitch and then expand upon it to fill the Description. I've found that the former tends to work better for me, as it allows me to get my thoughts out first. Whenever I write the elevator pitch first, I'll often find myself coming back to modify it as the Description forms.</p> <p>Also, in this section, I always include my Audience Takeaways. This makes it even more difficult because the takeaway can easily take 100 - 150 characters. So I have to be even more concise. I believe, that it is paramount that you include the Audience Takeaways. A good abstract should explain what you will talk about and what people will gain by coming to your talk. Conference attendees usually see this in the program, and they know immediately by reading it if the talk  is right for them.</p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#audience","title":"Audience","text":"<p><pre><code>* Who is this for?\n* Can be many different audiences\n</code></pre> As I said earlier in this post, you must know who your audience is. In this short section, just write it out. Is it for Python Developers? DevOps Engineers? Marketers? Make a bulleted list and write it out. Your audience can be many different types of people. You don't need to limit it to one, but don't feel bad if it is just one.</p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#audence-level","title":"Audence Level","text":"<p><pre><code>Expertise required for this talk\nInclude prerequisites\n</code></pre> As mentioned above, having a set level for the difficulty of the talk will  help you scope the content. I covered how to think about audience level in-depth above in the section. You should also explicitly write down any prerequisite knowledge you expect the audience to have coming into your talk. Sometimes there is a place to share this in the CFP submission, but if there isn't, it is still useful for scoping the talk. </p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#audiece-takeaways","title":"Audiece Takeaways","text":"<pre><code>What will the audience take away \nand/or learn from this talk? \n\nShould be 3 things\n</code></pre> <p>Audience Takeaways are one of the most vital parts of a CFP, and you'll rarely see a CFP ask for this(1). It isn't enough to tell people what your talk about, but what they are getting out of your talk. Single-track conferences are rare. There are usually at least two or more talks happening simultaneously. Let the viewer know what to expect from your talk so they can choose the correct talk for them.</p> <ol> <li>And kudos to the ones that do.</li> </ol> <p>In this section, I write three bullet points of takeaways I want attendees to get out of my talk. And three is a hard stop for me. If you've never heard of The Rule of Three you should read up on it. The tl;dr is that trios of things are more satisfying and effective than other numbers. There's some deep psychology around it that I can't explain, but it works. </p> <p>When it comes to writing them into my Elevator Pitch or Description, they can take many forms. The main thing to focus on here is the Rule of Three. Looking back at my successful talk proposals, 95% of them have utilized it in the Elevator Pitch in some way. </p> <p>From a conference organizer's viewpoint, I love seeing takeaways. It tells me that the talk is well thought out. Also, it helps me see if I think the talk will resonate with the audience of my conference. </p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#outline","title":"Outline","text":"<p><pre><code>* Timed outline (1 min)\n* For the Presentation (5 min)\n* More detail is good here (20 min)\n</code></pre> Outlines are an extremely helpful tool. I tend to outline my talk with the titles of my slides. I may have one or two slides that aren't represented here, but most of them are. I also put time estimations next to each section. These are immensely useful, helping me scope the talk and determine what I do and don't have time to talk about. However, these are estimates, and I treat them as such. Don't feel bound to these times. Adjust as you see fit. </p> <p>From a conference organizer's viewpoint, outlines help me so much. I can see exactly what you're talking about, what you're trying to get across, and whether or not I think this will be a good talk for my conference. The subset of talks that include a detailed outline and the subset of talks that get selected for the conference overlap almost perfectly. </p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#description","title":"Description","text":"<p><pre><code>Slightly longer description. \nExpands upon elevator pitch. \nBe sure to include Audience Takeaways\n</code></pre> This is where you can go into great depth about your talk without a character  limit. I tend to write this first to get a full idea of my talk and then condense it to fit into the Elevator Pitch. You may end up submitting this section in a CFP or you may not. It's still important to fill this out to help define what you want to accomplish in your talk. </p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#internal-notes-for-your-eyes-only","title":"Internal Notes (For Your Eyes Only)","text":"<p><pre><code>All the nitty-gritty of the talk. \nYour scratch paper\n</code></pre> These are my notes. I put links to resources to help me write the talk, thoughts I had while writing the paper. Anything and everything can go here. These shouldn't be shared with conference organizers.</p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#additional-notes","title":"Additional Notes","text":"<p><pre><code>Anything else. \nPresentation materials needed\nWhy you're qualified to speak on this\nEtc.\n</code></pre> A lot of CFPs will have a section for \"Anything else.\" This is a great section to put extra requirements you'll need for your talk. These could be anything from an extra monitor to a laser pointer. If you need special accommodations, such as a lower podium or equipment, be sure to fill this in. The conference will likely already have the items you need, but it is always good to be explicit in your requirements.</p> <p>Many people will often put here why they are qualified to speak on this topic. I'm personally not a fan of this, but I understand why people do it. If you want to put this in your CFPs, go ahead. A tip I would say is to never say that you are \"the most qualified person to speak on this.\" I never put this. There is always someone more qualified to speak on this topic than me.(1) If I put my qualifications here, I explain why I'm qualified to speak on this overall. Also, don't put identifying information in here. Conference organizers are trying hard to keep the selection process fair and anonymous.</p> <ol> <li>That being said, if you are the most qualified person to speak on this, you can put it. I say this because I have a lot of friends who often speak on their own open-source projects, and they are, in fact, the most qualified person to speak on this topic. However, for the sake of anonymity, maybe still avoid this. If you say, \"I wrote this library, hence I'm the most qualified to speak,\" I probably will be able to figure out who you are. And we're trying to maintain fairness in our CFP selection process. </li> </ol>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#my-yearly-process","title":"My Yearly Process","text":"<p>Because my job expects a certain level of speaking engagements from me every year, I have a process around writing talks. Every year in late Q4, when most of the company is wrapping up and preparing to go on winter break, I sit down and write all of my conference talks for the next year. The past few years, I have written anywhere between 5-8 talks for the upcoming year. This doesn't mean that if a great idea strikes me, I won't write a paper about it. I do this so when a conference opens up that I want to speak at, I don't have to stop what I'm doing to write a proposal. The current audiences that I'm looking to speak to are the Python and DevOps communities. So I try to write talks that I think those communities will find interesting. That doesn't mean that the talks focus on a Python topic. I am somewhat known in speaking circles for talking about documentation and technical writing. These talks are relevant to both communities, so it's a win-win for me. In the past few years, I have started writing more specific talks focused on individual technologies. I usually write 2-3 of these specific talks a year, and then the rest of my talks will be broad enough that I can give them at any conference. These broader talks focus on documentation, \"soft\" skills, and community building. </p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#how-do-you-feel-about-giving-a-talk-more-than-once","title":"How Do You Feel About Giving a Talk More Than Once?","text":"<p>There is a big debate around if/when you should give a talk more than once. I take a rather selfish stance here and say, if I spend so much time and effort writing it, you bet I'm going to give it more than once. However, I do have some rules around it. </p> <p>First, I won't give a talk more than twice virtually. The first year I started  speaking, which was 2019, I gave my Building Docs Like Code: Continuous Integration for Documentation talk six times at various regional Python conferences. We must remind ourselves that very few people go and search out random conference talks on YouTube.(1) Giving the same talk at different regional conferences means getting it in front of more people who more than likely would not have seen it otherwise. With the accessibility of virtual conferences, more people can attend, and I find this as a reason to not over-saturate the virtual conference market with these talks. </p> <ol> <li>Don't believe me? Go look at the views.</li> </ol> <p>Second, when I'm tired of a talk, I stop giving it. My Docs Like Code talk was fantastic. I loved writing it; I loved presenting it. After six conferences and  a handful of meetups, I'm tired of giving it. I may write version 2.0 in the future, but that talk is purposefully retired for now.</p> <p>Third, if I give a talk and determine I don't like it, I might not give it again. I usually try to fix a talk if I feel it doesn't work, but not every talk is a winner. The talk may have felt good on paper, but I didn't like it in practice. The only way to \"get good\" at something is to practice. Not everything is going to be great. Don't cling to something if you aren't feeling it. There will be more opportunities. </p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/how-i-write-conference-talk-proposals/#should-i-submit-a-talk-to-this-conference","title":"\"Should I submit a talk to this conference?\"","text":"<p>Yes! I encourage everyone to submit talks to conferences. If you get selected, great! If you don't, feel free to reach out to the organizers for feedback on  your proposal. You'll be surprised how often they'll take time to do this. Conference organizers all want you to succeed. They'll either come back with some tips on your talk, or they could tell you that your talk was great, but it just didn't win out against other talks. </p> <p>The only way to get better at anything is to practice, fail, and try again until you succeed. If you don't get selected, keep at it! It took me three years of submitting papers to conferences to finally start getting accepted. You'll get there eventually, and I look forward to watching your talk when you do. </p>","tags":["Conferences","Speaking","CFPs"]},{"location":"blog/oh-shit-i-havent-blogged-in-a-while/","title":"Oh Shit, I Haven't Blogged in a While","text":"<p>You ever look at your blog and say to yourself \"I should blog more\"? Ya. I've been doing that for almost two years now. Now while most of you probably follow me already, maybe you missed a few moments along the way. So buckle up, I'm going to catch up on two years of blogging in this post. </p> <p>My last blog(1) was on January 30, 2022 and it was actually one of my favorite blogs to write. 2022 was an interesting year but I do believe that it was around this point that my burnout from DevRel started to settle in.</p> <ol> <li>It was about How I Write Conference Talk Proposals</li> </ol>","tags":["Blogging","Life"]},{"location":"blog/oh-shit-i-havent-blogged-in-a-while/#so-what-happened","title":"So What Happened?","text":"<p>For those of you who aren't a Developer Advocate, let me just say that time-to-burnout in DevRel is astronomically high. I may write another blog post that about this, but the tl;dr is talking to people is exhausting, the industry doesn't know what it wants DevRel to be, so you just kind of flail between projects for months on end, touching everything but not long enough to feel accomplished until you eventually just get tired and consider if you could make a living raising chickens. </p> <p>At the time I was working for DigitalOcean. While the company was great, you could feel the change settling in post-IPO. The fun startup atmosphere was evaporating quickly and decisions were being made that I wasn't fond of. On top of that, DigitalOcean is pretty notorious for underpaying. They trade on people's love of the brand and the pride of working there(1). Due to this a few other things I decided to venture out DigitalOcean and explore other opportunities. I found myself at a new company, Gretel. Early stage startups are interesting because they can pivot on a dime. I thought I was joining a company focusing on data privacy for backend developers. Within a few weeks of my arrival they either pivoted to generative AI for Data Science or were already there and there was a communication failure during the interview process. That being said, their  product was already a generative AI model, I just think their customer profiles shifted and instead of focusing on data privacy for tooling, it was more centered  around data privacy for generative AI. Either way, it was not what I signed on for.  While AI is interesting to me, I have absolutely zero desire to work in it. While at Gretel I was met with many challenges. I gave it my best try, however,  our visions on Developer Relations never coalesced which ended with me leaving the company to pursue other options. I wish them nothing but the best(2). Their  product is actually super fucking cool and will definitely change the industry,  but AI is not my passion. DevOps and Backend Engineering is.</p> <ol> <li> <p>At least this was the case for me. If you ask them internally they're proud that they pay within a percentage of other companies that they deem acceptable. Long story short, it's not acceptable and leads to turnover.</p> </li> <li> <p>One day I'll write a blog about how to know when a job isn't a good fit and when to leave. That kind of content would have helped me here a lot.</p> </li> </ol> <p>Also around this time myself and some other organizers hosted the  PyTexas 2022 Conference. This was my first year as  conference chair and most of the responsibility fell on me. This was a very stressful time as we were chasing the easing of Covid restrictions up until the day of the conference. We had made the decision to go back in-person in March 2022 and to say it was challenging would be an understatement. Either way, I'm proud of the conference we delivered. This did result in me being elected to the PyTexas Foundation Board where I have served as President since.</p> <p>I was only at Gretel for nine months. I learned a ton about an industry I knew little about, met many awesome people, and overall had a good time. I view this as a little detour in my career. </p>","tags":["Blogging","Life"]},{"location":"blog/oh-shit-i-havent-blogged-in-a-while/#temporal","title":"Temporal","text":"<p>After leaving Gretel I land a position as a Developer Educator (Sr. Technical Curriculum Developer) at Temporal Technologies. It's actually funny that I landed here, as I had interviewed for a Developer Advocate role here while I was interviewing at Gretel. After that, I stayed in contact with the Temporal recruiting team about once a quarter to check in and see how things were going. Temporal was super cool and I was hoping to eventually land a role there in my career. I just didn't anticipate it happening so soon. </p> <p>I was fortunate, one of my ex-colleagues and friends from DigitalOcean Brian Hogan had a role opening up on his team and he was looking for \"road weary DevRel people who like to teach\". Well that fit me perfectly, I applied, and got the role.</p> <p>I plan on doing a Recap blog post about my first year at Temporal, so check back in late January for that. </p> <p>Oh. I also ran PyTexas 2023. I'll have to write about all that too.(1)</p> <ol> <li>That's it Mason. Just keep adding stuff to the fucking list.</li> </ol>","tags":["Blogging","Life"]},{"location":"blog/oh-shit-i-havent-blogged-in-a-while/#so-whats-next","title":"So What's Next?","text":"<p>A lot. I'm writing a book. More on that later. PyTexas 2024 is coming up. I'm doing a lot of work to expand the PyTexas Foundation. We have a  meetup now.  I plan on writing a full recap post  on the 2024 conference on the PyTexas site. I'm working my ass off at Temporal and will have more to share on that in a later  post. </p> <p>Hopefully now that I've filled in the gap I wont feel stuck unable to publish more blogs and tutorials. I felt guilty that I hadn't posted in so long and it stopped me from posting otherwise. </p> <p>The psychology of writing can kick your ass. I'm dealing with that while writing my book.</p> <p>Anyway, thanks for catching up. Here's hoping my next post isn't in like, 2025.</p>","tags":["Blogging","Life"]},{"location":"blog/oh-shit-i-havent-blogged-in-a-while/#other-shit-i-forgot","title":"Other Shit I Forgot","text":"<p>Oh. I also am the Deputy Province Governor of Province 9 of the Phi Mu Alpha Sinfonia Fraternity of America. </p> <p>I got another puppy. A yellow labrador named Butters. </p> <p></p> <p>But they grow up so fast</p> <p> </p>","tags":["Blogging","Life"]},{"location":"blog/2023-is-dead-long-live-2024/","title":"2023 Is Dead! Long Live 2024!","text":"<p>What a year it's been. I've long disliked the cliche \"That year just flew by!\" but holy shit this year really did. This year I changed jobs, organized a regional conference, started a new meetup, and got a new puppy just to name a few things.</p>","tags":["Blogging","Life"]},{"location":"blog/2023-is-dead-long-live-2024/#a-year-in-review","title":"A Year In Review","text":"","tags":["Blogging","Life"]},{"location":"blog/2023-is-dead-long-live-2024/#career","title":"Career","text":"<p>In mid-January I decided to leave my job as a Developer Advocate at Gretel.ai and make the jump to Developer Education at Temporal Technologies. After four years in Developer Relations, I was burned out of speaking and wanted to take the opportunity to improve my writing and teaching skills. Luckily a good friend of mine Brian Hogan had an opening on his team so I applied and got the role. I had worked with Brian at DigitalOcean and knew that I had a once-in-a-lifetime opportunity to learn about writing and developer education. This first year at Temporal I delivered four courses, Temporal 101 and 102 in Java and Python, a tutorial, and various updates to the product documentation. The culmination of a lot of this work was getting to give Temporal 101 and 102 live and in-person at Temporal's annual Replay conference. I've learned a lot about Durable Execution and just how cool the technologies are. I actually finished a fifth course, but my team decided to hold off releasing it for a bit. But I'm still going to count it for this year!</p> <p>I did far less speaking this year than I have done since 2019. And by far less I mean practically zero. I gave one workshop but I needed a break from public speaking. I am finally feeling ready to speak at conferences again and have started writing a few CFPs.</p> <p>Maybe I should do a blog post on DevRel burnout. If you think so Tweet at me.</p>","tags":["Blogging","Life"]},{"location":"blog/2023-is-dead-long-live-2024/#pytexas","title":"PyTexas","text":"<p>This was by far the busiest year for me with regards to my PyTexas work. We delivered a phenomenal conference in April and immediately moved into planning the 2024 conference. We were able to announce the 2024 dates at the end of our 2023 conference, something that had never been done before. We also finally sat down and created a PyTexas Foundation website and aligned on a singular tech stack for all of our assets. Finally, we launched the PyTexas Virtual Meetup in September and are still going strong! </p> <p>There's a whole blog post about the PyTexas work that has been done on the foundation website, so check that page out on January 5<sup>th</sup> for the release!</p>","tags":["Blogging","Life"]},{"location":"blog/2023-is-dead-long-live-2024/#personal","title":"Personal","text":"<p>I got a new puppy! Welcome Butters! His brother Loki loves him.</p> <p></p> <p>He's growing up fast! </p> <p> </p> <p>Other than that it was a quiet year on this front. </p> <p></p>","tags":["Blogging","Life"]},{"location":"blog/2023-is-dead-long-live-2024/#2023-stats","title":"2023 Stats","text":"<p>A brief list of the things I accomplished this year that I'd like to highlight:</p> <ul> <li>Code:<ul> <li>Migrated my personal website to Mkdocs Material</li> <li>Established a unified tech stack for PyTexas websites</li> </ul> </li> <li>Content:<ul> <li>Published Build a Temporal Application from scratch in Java</li> <li>Published various parts of the Temporal Java Dev Guide</li> <li>Published the Temporal 101 Courses in Java and Python</li> <li>Published the Temporal 102: Exploring Durable Execution Courses in Java and Python</li> </ul> </li> <li>Community:<ul> <li>Organized and delivered PyTexas 2023<ul> <li>Currently organizing PyTexas 2024</li> </ul> </li> <li>Organized and launched the PyTexas Monthly Meetup<ul> <li>And continuing with this into the new year</li> </ul> </li> <li>Presented at PyTexas December Meetup</li> <li>Delivered Temporal 101 and 102 in Java live at Temporal's Replay Conference</li> </ul> </li> </ul>","tags":["Blogging","Life"]},{"location":"blog/2023-is-dead-long-live-2024/#what-does-2024-hold","title":"What Does 2024 Hold?","text":"<p>I am aiming for 2024 to be a transformative year for me. It's mostly going to be a year for me. I need to improve my health, both mentally and physically. Time to make the most out of my 30s. </p> <p>Putting these out into the world. I will report back in next year's recap.</p> <ul> <li>No sodas<ul> <li>I made it halfway through the year and then backslid. I can't even allow myself sugar free sodas as they tempt me. And honestly, with how much the shit costs these days good riddance. </li> </ul> </li> <li>Lose 50 lbs<ul> <li>And this time I mean it! I started out 2023 on a good track and was even down 20 lbs at one point. I was going to the gym five days a week before work and really enjoyed swimming again. When I was 18 I had major reconstructive surgery on my right knee which limits my ability for high impact cardio, but I've always loved swimming. I'm also doing weight training and already am making good progress.</li> </ul> </li> <li>Eat Healthier and Avoid Fast Food<ul> <li>This alone will help with the issue above. There's going to be a lot more crock pot meals and meal prepping. Too often I choose convenience over health and that must change.</li> </ul> </li> <li>Finish my book<ul> <li>I have a contract with a publisher to deliver this. I have the first few chapters done and more on the way. I procrastinated in 2023, let's get this out the door quickly in 2024.</li> </ul> </li> <li>Build My First SaaS<ul> <li>I finally have an idea. My little brother and I are discussing it and I hope to have something ready to deliver by mid-year. That's all I'm going to say for now.</li> </ul> </li> <li>Read More Books. Like, a lot more<ul> <li>I have a metric fuck ton of books on my bookshelf that have gone unread. That changes this year. I long have had an idea of selecting 52 books and assigning them the value of a card from a standard deck of cards. My goal is to draw one card a week and read one book a week. Some are shorter than others. I'll probably slip some here, but I'm going to try. The goal is to finish more books this year. I'll report back in 2024 with the progress. If you want to follow along, check out this Google Sheet</li> </ul> </li> </ul> <p>It's a lot. But 2024 will be a transformational year for me. As I age my discipline seems to increase and I am feeling very confident that I can achieve these goals. Feel free to drop a line sometime and ask me how I'm doing to keep me honest. </p> <p>Happy New Year and here's to a great 2024, regardless of what the world throws our way.</p>","tags":["Blogging","Life"]},{"location":"blog/you-dont-get-better-without-deliberate-practice/","title":"You Don't Get Better Without Deliberate Practice","text":"<p>I had a close friend who recently joined the tech industry reach out to me and ask me about my thoughts regarding doing \"outside work\" to level up his career. I see this discourse come up on Twitter(1) from time to time so I felt now's as good as ever to offer my thoughts.</p> <ol> <li>I refuse to call it X. Never gonna happen.</li> </ol>","tags":["Blogging","Practicing"]},{"location":"blog/you-dont-get-better-without-deliberate-practice/#the-question","title":"The Question","text":"<p>Every six months or so I see some variation of the question appear on social media:(1)</p> <ol> <li>Usually being stirred up by \"tech influencers\" desperate for engagement, but that's none of my business...</li> </ol> <p>\"Should I be working outside of work hours to get better/get ahead in my career? </p> <p>These types of posts tend to attract many strong opinions and there are typically two schools of thought regarding it(1):</p> <ol> <li>But often in waaaaaay more words than this.</li> </ol> <p></p> <ul> <li>Yes, you should definitely be working outside of work hours</li> <li>No, you should never work outside of work hours</li> </ul> <p>The issue I take with these answers is the tend to overlook a few nuanced considerations, mainly around career aspirations and reality.</p>","tags":["Blogging","Practicing"]},{"location":"blog/you-dont-get-better-without-deliberate-practice/#through-the-eyes-of-a-musician-turned-programmer","title":"Through the Eyes of a Musician Turned Programmer","text":"<p>While in college, I studied both Music and Computer Science(1). I received both my Bachelor's of Arts in Music and Bachelor's of Science in Computer Science from  Texas State University at the same time. I walked across the stage on Friday to receive my Music diploma and again the following day to receive my Computer Science diploma. However, my education in these topics didn't start there. I had played  an instrument since I was 11 and had been programming since I was 15.</p> <ol> <li>Ok, so I'm going to keep this as short as I can. This story is deep.</li> </ol> <p>There is a theory known as the 10,000 Hour Rule that is often cited in music programs. The idea is that if you practice 10,000 hours, you will reach elite if not virtuosic status in whatever you are trying to achieve. It's a good story. Try hard enough, you'll get good. And while recent studies have debunked certain aspects of this theory, I still believe there is some truth in it. </p> <p>When I was an undergrad studying music my freshman year, my classmates would often brag about how much time they spent practicing. </p> <p>\"I spent 8 hours in the practice room today.\" </p> <p>\"Oh ya? Well I was in there for 10 straight hours!\"</p> <p>\"You wimps, I woke up, went to the practice room, and the next thing I knew it was tomorrow.\"</p> <p>However, when you asked them what they accomplished during this time, their answers would become a lot less clear. They may have been able to say they worked on their solo, or practiced their scales, but when asked \"What can you do today that you couldn't do yesterday?\" an answer was rarely found. This made me realize that practice alone was not the answer. Deliberate or focused practice was.</p>","tags":["Blogging","Practicing"]},{"location":"blog/you-dont-get-better-without-deliberate-practice/#deliberate-practice","title":"Deliberate Practice","text":"<p>Think of professions outside of your own. Perhaps a musician, a doctor, or a lawyer.  Do you think they work outside of work hours? Does a musician show up to play at  a concert and never practice the material before hand? Does a doctor with a full  patient load cease learning because it doesn't fit in the 9 to 5? How about a  lawyer who doesn't keep up with recent case law? There may be some who do this, but ask yourself, would you purchase the services of these individuals?</p> <p>Practice is key to improvement, there's no disputing that. However, the type of practice matters. Practicing your instrument just for the sake of practicing does not lead to improvement. Going in, setting a goal of being able to play these scales from memory at this tempo a certain number of times without failure does. How long this takes you is irrelevant. Whether it takes you 30 minutes or 30 hours, the result is the same.</p> <p>Deliberate, focused, goal-oriented practice is required to improve a skill. Period. End of sentence. Whether you are given time to do that while on the job is irrelevant. You may get lucky. You may be given time to sit down and learn about a new technology or tool to make your job easier. But capitalism is going to capitalism, and most likely you won't be given the time. Therefore, you have to make the time.</p>","tags":["Blogging","Practicing"]},{"location":"blog/you-dont-get-better-without-deliberate-practice/#should-you-practice-outside-of-work-hours","title":"Should You Practice Outside of Work Hours?","text":"<p>Many people try to answer this question without answering a more important one first, which is </p> <p>\"What do you want from your career?\"</p> <p>Are you trying to be the best software engineer on your team? Get promoted to Head Lead Senior Staff Vice Principal Architect Astronaut? Or are you providing your time as a service in return for compensation?</p> <p>Let me be 100000% clear BOTH ARE PERFECTLY VALID ANSWERS!</p> <p>One of the things I hate about corporate culture is the expectation that  we should always be striving to take the next step up the ladder.(1) I have great friends and colleagues that are like me, highly ambitious in our careers and are  constantly striving to do more and make vertical moves. And I have great friends  and colleagues who clock in at nine, leave at five, and don't write a line of code in the hours outside of that. Both are valid ways of living your life. You can have a successful career on both paths. </p> <ol> <li>This absolute stupidity is the reason the Peter Principle exists. And we do it to ourselves. Just let people do the job they want to do for fucks sake and stop pushing them into roles they aren't capable of doing and, more importantly, don't fucking want.</li> </ol> <p>So does this mean that those who are hyper obsessed with their career are more  likely to have a more successful outcome? Yes. But let's be honest, you already know that. You know this because you have observed reality around you. At the time of writing this, the 2024 Summer Olympics are happening, and I'm constantly seeing joke posts on the internet about how we should have one \"normal\" person participating in the events so we can see how the rest of us would fare. This is a perfect example of deliberate practice. </p> <p>Is it also possible for someone who doesn't engage in their career outside of work hours to just be better than you? Also yes. They may just have a natural affinity for network switches. There's nothing you can do about this. Being upset or jealous will get you no where. So focus on what you can control, which is yourself.</p> <p>As a past professor used to tell me</p> <p>\"You don't know their story.\" </p> <p>Which basically meant that you don't know what they did or how they acquired that knowledge.  Maybe they've been doing it from a young age. Maybe they spend hours everyday learning on their own time. Maybe they're 10,000 years old and have the wealth of all human knowledge in their head. No matter the reason, you cannot change what they know. The only person you can improve is yourself. Focus on the things within your ability to change and control. Instead of being jealous, learn from them. In my career I have progressed at every role I've been in because I identified the person in the room who was way better than me at a specific task, sat next  to them, and listened and learned.</p> <p></p> <p>So, the answer to the question \"Should I be working/practicing outside of work hours\" is, in my opinion, \"If doing so advances your career in the direction you want, then yes.\" But it isn't just that you practice, it's that you practice the right things.</p>","tags":["Blogging","Practicing"]},{"location":"blog/you-dont-get-better-without-deliberate-practice/#not-all-types-of-practice-yield-the-same-results","title":"Not All Types of Practice Yield the Same Results","text":"<p>The summer before my junior year in high school I had the opportunity to take a private lesson with a professional trombone player. Growing up in a rural area, opportunities like this were not common. My mom and I drove two hours to meet with the instructor and honestly, that one hour session changed the trajectory of how I played and practiced. We spent the entire time discussing embouchure(1) and getting mine right. The results were immediate and amazing. He gave me  a few exercises to practice and we were done. </p> <ol> <li>embouchure: noun the way in which a player applies the mouth to the mouthpiece of a brass or wind instrument</li> </ol> <p>It's not just enough to practice, it's determining what is lacking, how to fix it, and how to maintain these changes going forward. Having a good teacher or mentor who can point you in the right direction makes all the difference here. I had been practicing trombone for five years and gained more in an hour than five years of instruction had provided. Whether it's learning trombone or how to deploy Kubernetes clusters, if you're not getting the right information your progress will be limited. Don't get me wrong, you'll make progress. Anything is better than nothing. But you may not see the results you want. You may get stuck, or not progress as quickly as you would have hoped. This can lead to discouragement.</p> <p>So how do you ensure that you are practicing the right thing? Find a mentor. Find someone who has traveled a similar path you wish to go and ask them what they recommend you learn, how to learn it, and most importantly, what not to learn.</p>","tags":["Blogging","Practicing"]},{"location":"blog/you-dont-get-better-without-deliberate-practice/#where-should-i-start","title":"Where Should I Start?","text":"<p>Going forward, I'm going to assume that you have decided that you do wish to  do some form of outside work practice. Because if you decided not to, congrats, you're done! </p>","tags":["Blogging","Practicing"]},{"location":"blog/you-dont-get-better-without-deliberate-practice/#dont-just-do-more-work","title":"Don't Just 'Do More Work'","text":"<p>The first thing I always tell people is don't work for free. This phrase can have a variety of interpretations, but the most simplest is, don't just continue working on assignments from your employer. This is a trap a lot of people fall in to. </p> <p>For the sake of this example, let's pretend you decide to dedicate ten hours a week to deliberate practice, but decide to fill it by just doing more work for  your employer.</p> <p>First, your employer isn't going to reward you for it. They may say they will, but in reality they won't. Not fairly at least. I took this route at the  beginning of my career. I put in extra hours to help get a massively over-scoped project to ship on time. At performance review time I received a top review, one of only five engineers across the entire 2500 person company to receive one. My reward was 5% bonus. When I left that job a year later, my new role was a 36% increase in pay. The reality is promotions, bonuses, stock grants from your current employer never stack up to what you can get by getting a new job. </p> <p>Second, you're setting an unrealistic expectation of your output. You are sending a signal that this is your new capacity for work. Your employer is getting an  extra 10 hours a week for free that you may not want to give for the rest of your  time there. But if you ever decrease that time, you may be viewed as slacking. </p> <p>Third, you may not realize it, but you're raising the companies expectations on your teammates. Think about it. You've just increased your output by 20%, from 40 hours a week to 50 hours a week. Your team is now faced with two options, try to replicate what you are doing, or hope that no one higher up starts asking \"Well X can get Y number of things done in a week, why can't you?\". By putting in more hours, you are creating a more difficult environment for your teammates.</p> <p>Finally, the reward for good work is always more work. Something you pick up as part of your practice may end up becoming part of your job. Say for example that your company maintains a Terraform provider and you want to learn how to  build Terraform providers(1). So you decide to pick up a few issues from GitHub and fix them. Oh wait, there was a bug in that ticket. Do you have time to fix it? Hey, the company has this new feature and they want it put into the Terraform provider. You were the last one to touch is, so you can implement it right?  Shouldn't take too long and we all know you get work done. OMG there is a massive issue with the provider, it's deleting things it shouldn't! You need to fix this NOW! And it goes on and on and on. You are now responsible for something that isn't part of your job description and you aren't being measured on. But the  company still expects work to be done, so congratulations on your new responsibility. And even better, you may get requests for help on things adjacent to this. You have now become known as someone who gets things done in your organization. So everyone is going to come to you with their issues. And now you have to exercise your ability to say no to things(2). By the way, you're still expected to get your  original workload done. You won't be given any space to make time for all these new tasks, so now you really do need those extra ten hours a week. See how it can quickly spiral out of control? So be careful with what extra tasks you pick  up, they have a tendency to multiply.</p> <ol> <li>Great call btw! You clearly have immaculate tastes. Except for the Golang part. But woohoo for the Terraform part!</li> <li>Which most people suuuuuuuuck at.</li> </ol> <p>And don't come at me with this \"Well I want to get promoted\" shit. If you think that doing more work on your team is what leads to a promotion you have a misguided understanding of how promotions work, especially in tech. You don't get promoted by doing the same work you were already doing. You get promoted by doing different work, by working cross function and collaborating. The formula isn't</p> \\[ p=ht \\] <p>where \\(p\\) is getting a promotion, which is determined by the product of the number of hours you work \\(h\\) and the number of tasks \\(t\\) you finish(1).</p> <ol> <li>Oooooh. Pretty math plugin for markdown. Me likey.</li> </ol> <p>Bottom line, I highly recommend you don't dedicate your practice time to doing more work for your employer. It never ends equitably.</p>","tags":["Blogging","Practicing"]},{"location":"blog/you-dont-get-better-without-deliberate-practice/#work-for-yourself","title":"Work for Yourself","text":"<p>So how do you practice if you don't just do more work for your employer? Simple. Work for yourself. This doesn't mean that you have to turn your practice into a side hustle and make money(1). It means the primary benefactor of your work is you or something you care about, like an open-source project.</p> <ol> <li>Although this isn't uncommon. Many startups have found their roots here.</li> </ol>","tags":["Blogging","Practicing"]},{"location":"blog/you-dont-get-better-without-deliberate-practice/#practice-with-leet-code-problems","title":"Practice with Leet Code Problems","text":"<p>While I have made my disdain for leet code known far and wide, I don't take issue with the exercises themselves, rather how they are used in the hiring process. They are actually not a bad place to start when picking up something to practice.  Just view them as code puzzles. When doing them, practice a certain skill. Are  you trying to get better and writing optimized code? Try to make the answer as  fast and using the least memory as possible. Are you trying to get more practice  with the Python standard library? Find a way to use functions from that in your ' solutions. Want to learn new language? Write your solutions in that language(1).</p> <ol> <li>This is actually what I do. When I was in high school I was on a competitive programming team and did leet style programs. When I learn a new language I actually pick up some of these old problems that I already know the answer to and implement them in the language that I am learning. </li> </ol> <p>I don't recommend staying in leet code forever. I occasionally do one for  a brain teaser, and I do try Advent of Code every year. They have a specific purpose, and are not a silver bullet(1).</p> <ol> <li>No matter how much tech hiring wants them to be.</li> </ol>","tags":["Blogging","Practicing"]},{"location":"blog/you-dont-get-better-without-deliberate-practice/#work-on-a-side-project","title":"Work on a Side Project","text":"<p>This is one of the best ways to get exposure to new tools. Pick a tool/framework  that you want to learn and build something with it. Or even pick a tool that you use at work. It's totally fine to practice skills you currently use at your job at home, just build your own things with them. This allows you to play around with it, try new features, break things, and just have fun. </p>","tags":["Blogging","Practicing"]},{"location":"blog/you-dont-get-better-without-deliberate-practice/#read-a-book","title":"Read a Book","text":"<p>Bet you weren't expecting that one were you? Books are a great source of knowledge, inspiration, and wisdom. Practice isn't solely hands on keyboard. Practice can take many forms. So read a book. You may retort with \"Well what about blog posts or Reddit or SubStack?\" and those are fine too, but there is something to be had for reading a book from a publisher. The publisher vetted that book and its contents. They paid for technical review, copy editing, developmental editing, and a lot more. They put their reputation on the line saying \"We stand by the contents of this book enough that we want to distribute it.\" So ya, I put a little more faith in books from established publishers. </p> <p>It should also be noted that you don't have to read about a new technology.  Books on leadership, time management, marketing(1), anything outside your direct area of work will help you understand the challenges of the business more. If you're looking to advance in your career, you can't just know about your job. The higher you climb, the more knowledge about the business as a whole is required.</p> <ol> <li> <p>The amount of engineers who scoff at marketing(1) is directly equivalent to the number of failed startups in the world. \"Build it and they will come\" is horseshit. </p> <ol> <li>That was me. I was one. I learned my lesson.</li> </ol> </li> </ol> <p>But I'll go even further. Don't like reading books about work or tech? Fine. Read some fiction. Just  read  for  the  love  of   God . Reading is so good for you. It's so good for your brain. Adults don't  read enough. Read.(1)</p> <ol> <li>And now I've convinced myself to write a blog post about this topic. So be ready.</li> </ol>","tags":["Blogging","Practicing"]},{"location":"blog/you-dont-get-better-without-deliberate-practice/#join-a-community","title":"Join a Community","text":"<p>One of the fatal flaws I see people fall in to is not caring about their professional network. The tech industry is a small world. If you haven't experienced this phenomenon yet, give it a minute. You'll start a new job and your coworker may be the cousin of your ex-boss. If you don't think people go through your LinkedIn, check connections, and ask mutuals about you then I've got some ocean front property in Arizona I'd like to sell you(1).  So nurture your professional network. Go to a local meetup, conference, social event. Keep in touch with previous coworkers. If you're feeling really confident, give a presentation at an event. Communities are a great way to stay up to date on the latest trends in tech, as well as make connections who you one day may want to work with. And heck, you may just make  some friends along the way(2).</p> <ol> <li> <p>Growing up in the south, folksy sayings are my vernacular. Sometimes they come from ones I've actually heard, sometimes I make them up on the spot. Every. Single. Job. I've ever worked has always said they want a book of my phrases. Every one. This particular one comes to us from the wonderful lyrics of the King of Country Music, George Strait. If you don't get it, or aren't familiar with the geography of the United States, Arizona is landlocked. It means you're gullable. This was a particular favorite of my mothers.</p> </li> <li> <p>Some of my best friends I met at a conference. We get together every year and hang out, eat BBQ, and catch up. If I ever need professional advice, or hell even a job, I know I can reach out to them. </p> </li> </ol>","tags":["Blogging","Practicing"]},{"location":"blog/you-dont-get-better-without-deliberate-practice/#parting-thoughts","title":"Parting Thoughts","text":"<p>As I was leaving the private trombone lesson mentioned earlier, the lesson teacher had one more golden nugget to share, which I have carried with me my entire career.  He simply said to me</p> <p>\"You decide how great you're going to be. No one else.\"</p> <p>This quote still has a profound impact on me today. It's why I practice outside of my working hours. I have large aspirations for my career. I want to climb the ladder and see how far I can go. And all of the tools necessary for me to achieve this rests solely in my hands. I just have to choose to act. And so do you. </p> <p>What will you choose?</p>","tags":["Blogging","Practicing"]},{"location":"extras/","title":"Extras","text":"<p>Here's all the other things I do and like in no particular order</p>"},{"location":"extras/#links","title":"Links","text":"<p>Here is a list of articles, books, videos, and other resources that I've read that have helped me throughout my career. I'm constantly sharing these with people and  forgetting where the link is so I'm making this page to alleviate unnecessary  Googling and Slack Message searchs. </p> <p>If you find it useful too then that's alright too. lol </p>"},{"location":"extras/#articles","title":"Articles","text":"<ul> <li>Maker's Schedule, Manager's Schedule - Paul Graham</li> <li>Always be quitting - Julio Merino</li> <li>How to help a student get unstuck</li> </ul>"},{"location":"extras/#books","title":"Books","text":"<ul> <li>Cash Flow for Creators: How to Transform Your Art Into a Career</li> </ul>"},{"location":"extras/#teaching","title":"Teaching","text":"<p>I've always had a passion for teaching. I feel this comes from being raised in an educational environment. My mother, grandmother and grandfather, and  great-grandfather were all teachers. My family lineage can be traced back the  pioneers of education in Texas. I like to think that education is in my blood.</p>"},{"location":"extras/#idea-montopolis","title":"IDEA Montopolis","text":"<p>2018-2019 School Year</p> <ul> <li>AP Computer Science A (Java)</li> </ul>"},{"location":"extras/#texas-state-university","title":"Texas State University","text":"<ul> <li>CS 1428 Honors Foundations of Computer Science I (C++) - Lab<ul> <li>Fall: 2013, 2014, 2015</li> </ul> </li> <li>CS 1428 Foundations of Computer Science I (C++) - Lab<ul> <li>Spring: 2014, 2015 </li> <li>Summer I: 2014</li> <li>Fall: 2013, 2014</li> </ul> </li> <li>CS 1308: Computer Literacy and the Internet - Lab<ul> <li>Spring: 2015</li> <li>Summer: I 2012, 2013, 2014, 2015</li> <li>Summer: II 2012, 2013, 2014</li> <li>Fall: 2012, 2014</li> </ul> </li> </ul>"},{"location":"speaking/","title":"Speaking","text":"<p>Public speaking is something I'm very passionate about. I love being able to share my experience, opinions, and knowledge with people. I love to travel so speaking at conferences is a good reason for me to travel.</p> <p>You can find my talks of all types (conferences, webinars, university talks) and corresponding resources below.</p>"},{"location":"speaking/building-docs-like-code-continuous-integration-for-documentation/","title":"Building Docs like Code: Continuous Integration for Documentation","text":"<p>This talk discusses why developers dislike writing documentation, what we can do to address this, and provides a ready to go pipeline for  automating your documtation</p> <p>Project documentation is easy to neglect. Keep your docs inside your source repo &amp; learn how to automatically build &amp; publish beautiful docs on every commit. Viewers will leave with a new mindset on how to handle documentation, tooling for this process, &amp; an easy-to-implement method to achieve this.</p> <p>This talk was given at:</p> <ul> <li>PyCon 2020</li> <li>PyGotham October 2019</li> <li>PyLatam August 2019</li> <li>PyOhio July 2019</li> <li>Texas Linux Fest July 2019</li> <li>PyTexas May 2019</li> </ul> <p>Presentation Slides</p> <p>Note, I typically tweak my slides a bit before each talk. These slides may not be the exact talk you saw, but they are pretty close.</p> <p>This talk has been officially retired. I may revist the concepts in a few years, but I think 5 presentations is enough for now.</p>"},{"location":"speaking/digitalocean-tech-talks/","title":"DigitalOcean Tech Talks","text":"<p>During my time at DigitalOcean I presented multiple Tech Talks live for the community. This is the comprehensive list of talks I gave</p> <ul> <li>Getting Started with Flask</li> <li>Foundations of Computer Security</li> <li>Building a Minimal, Production-Ready Infrastructure on DigitalOcean</li> <li>Securing Your Droplet</li> <li>Utilizing Security Features in SSH</li> <li>Keeping Your Sites and Users Safe Using SSL</li> <li>Top 10 Security Practices for Protecting Your Infrastructure</li> </ul>"},{"location":"speaking/write-docs-devs-love-ten-tricks-to-level-up-your-tech-writing/","title":"Write Docs Devs Love: Ten Tricks to Level Up Your Tech Writing","text":"<p>You're read good tutorials, you've read bad tutorials. In this talk I'll discuss 10 tips and tricks to level up your technical writing.</p> <p>Think of that feeling you get when you follow an online tutorial or documentation and the code works on the first run. Now think of all the hours spent wasted following broken, outdated, or incomplete documentation. From our favorite tutorials to bad product docs we all consume technical writing. Tutorials, blog posts, and product docs help developers learn new things, build projects, and debug issues. But what makes one tutorial better than another? In this talk I'll discuss how you can write the documentation that developers love and I\u2019ll share 10 tips and tricks to improve your technical writing.</p> <p>This talk was given at:</p> <ul> <li>PyCon US 2024 - Documentation Summit</li> <li>PyCon US 2022</li> <li>PyGotham 2021</li> </ul> <p>Presentation Slides </p>"},{"location":"speaking/pfsense---a-beginners-guide-to-a-sensible-firewall/","title":"pfSense - A Beginner's Guide to a Sensible Firewall","text":"<p>This talk was given at Texas Linux Fest 2016. Co-founder of pfSense Chris Buechler was present in the audience. No pressure.</p> <p>Tired of your home router's UI? Wish you could have more control over everything in your network? Looking to replace enterprise routers with something OpenSource and easy to use? This session is a dive into the vast world of pfSense and the features it provides. In a world where security is becoming more complex, we need a simple, sensible tool to help keep us secure.</p> <p>pfSense is an Open Source Firewall built on FreeBSD and their port of the OpenBSD pf (packet filter) firewall. With a quick setup and an extremely well designed web UI deploying industry firewalls has never been easier. I will go  over a little bit of the history/design of pfSense, discuss some of the key features, and demonstrate standing up a basic pfSense VM and routing other VM traffic through it. (It's so easy I can do it in about 5-8 minutes).</p> <p>Presentation Slides</p>"},{"location":"speaking/python-102-beyond-the-basics/","title":"Python 102: Beyond the Basics","text":"<p>In this Workshop, you will go beyond the basics of Python and explore various language features that make Python pythonic. </p> <p>One of the benefits to Python is the ability to be productive while knowing a  small subset of the features the language has to offer. While this is one of Python's super powers, many Python developers are missing out on the full experience by not diving deeper into the wonderful features Python has to offer. </p> <p>In this tutorial, you will go beyond the basics of Python and explore various language features that make Python pythonic. Specifically, you will learn about:</p> <ol> <li>Fist-class Functions</li> <li>Decorators</li> <li>Comprehensions</li> <li>Dunder Methods &amp; Operator Overloading</li> <li>Context Managers</li> </ol> <p>This will be a hands on tutorial. All exercises will be distributed as a GitHub repository and as Jupyter Notebooks in Google Colab. </p>"},{"location":"speaking/python-102-beyond-the-basics/#course-materials","title":"Course Materials","text":"<ul> <li>Google Colab Drive</li> <li>GitHub Repo</li> <li>Slides</li> </ul>"},{"location":"speaking/python-102-beyond-the-basics/#delivery","title":"Delivery","text":"<p>This Workshop was given at:</p> <ul> <li>PyTexas 2024</li> </ul>"},{"location":"speaking/a-year-without-pants-strategies-for-successful-remote-work/","title":"A Year Without Pants: Strategies for Successful Remote Work","text":"<p>Remote work can be challenging. In this talk I'll discuss different strategies for increasing your productivity and enjoyment of remote work.</p>"},{"location":"speaking/a-year-without-pants-strategies-for-successful-remote-work/#introduction","title":"Introduction","text":"<p>2020 was the year of forced remote work. People struggle with this change due to lack of guidance on how to manage this shift. Due to this, many people have developed a negative opinion of remote work. However, remote work can be liberating. So how can you make working remotely enjoyable?  From daily routines to simulated commutes I\u2019ll discuss strategies for making remote work comfortable, productive, and enjoyable.</p> <p>This talk was given at:</p> <ul> <li>Python Web Conference 2021</li> </ul> <p>Presentation Slides </p>"},{"location":"speaking/slis-slas-and-sldohs-learning-about-service-uptime-from-homer-simpsons/","title":"SLI's, SLA's and SL'D'OHS! Learning about Service Uptime from Homer Simpsons","text":"<p>Measuring service uptime can be a daunting task, but not for the  Simpsons! Viewers will leave with a clearer understanding of how to account for  services, how SLxs can define and guide what to monitor, and how to implement  reliability targets and error budgets; all told by fabled Springfield wisdom</p>"},{"location":"speaking/slis-slas-and-sldohs-learning-about-service-uptime-from-homer-simpsons/#introduction","title":"Introduction","text":"<p>Building services is important, but what happens after they are built and  running in production? How do we establish trust with our customers that our  service will actually be available? Who creates these definitions and how do we  measure them?</p> <p>Service Level Indicators (SLI), Agreements (SLA), and Objectives (SLO) are  central to an operations mindset and foundational tools for effective Site  Reliability Engineering. This talk will take you on a journey through  Springfield as we discuss exactly what SLIs, SLAs, and SLOs are, how to measure  them, what targets should be measured, how to define uptime, availability, and  acceptable error rates, and what happens when they are breached.</p> <p>This talk was given at:</p> <pre><code>* [Open Source Summit 2020](https://www.youtube.com/watch?v=pkiEs3ax5uQ)\n* [Chicago Python User Group Meetup](https://www.youtube.com/watch?v=mXKOv0wlrg8)\n</code></pre> <p>Presentation Slides </p>"},{"location":"speaking/theres-a-snake-in-the-birdhouse-building-a-python-culture-at-vrbo/","title":"There's a Snake in the Birdhouse! Building a Python Culture at Vrbo","text":"<p>We all love Python, but not everyone is fortunate enough to use it at their day job. Come and listen as I detail the journey I took to establish  Python as an onroad option at my company. Viewers will leave having learned  from my experiences\u2014both successes and mistakes\u2014and with a solid plan for  implementing Python at their job.</p>"},{"location":"speaking/theres-a-snake-in-the-birdhouse-building-a-python-culture-at-vrbo/#introduction","title":"Introduction","text":"<p>It\u2019s no surprise why many of us are so enamored with Python. Its simplicity,  accessibility, and community make it a prime choice for many projects. However,  not all software engineering shops use Python, maybe even some of the jobs you  work at. Introducing Python to your company and building a Pythonic culture from  the ground up is no small task, but it can be done. Join me as I take you  through the journey of getting Python from zero to hero within my company. I\u2019ll  share the experience from start to finish, including what worked, what didn\u2019t,  what I would have done differently, and how I evangelized Python to bring it to  be a supported language within my company\u2019s ecosystem.</p> <p>This talk was given at:</p> <pre><code>* [PyTexas 2020](https://www.youtube.com/watch?v=MR85hLdc1wk)\n* PyBay 2020\n* [PyOhio 2020](https://www.youtube.com/watch?v=zTFRXHOOy3A)\n* [EuroPython 2020](https://www.youtube.com/watch?v=OOoGjznwhJU)\n</code></pre> <p>Presentation Slides </p>"},{"location":"speaking/devrel-show-episode-4---mason-egger-from-temporal/","title":"DevRel Show Episode 4 - Mason Egger from Temporal","text":"<p>I join my old colleague Fr\u00e9d\u00e9ric Harper on his new Podcast The DevRel Show to discuss various DevRel Topics</p>"},{"location":"speaking/devrel-show-episode-4---mason-egger-from-temporal/#delivery","title":"Delivery","text":"<p>This was recorded live 11/2/2023  </p>"},{"location":"speaking/i-cant-believe-its-not-real-data-an-intro-to-synthetic-data/","title":"I Can't Believe It's Not Real Data! An Intro to Synthetic Data","text":"<p>What is Synthetic Data? What can I use it for? Is it as good as real data? Find out the answers to those and more</p>"},{"location":"speaking/i-cant-believe-its-not-real-data-an-intro-to-synthetic-data/#introduction","title":"Introduction","text":"<p>Easy access to relevant, safe data is a major bottleneck for developers and data scientists. The data could be insufficient, biased, contain private information, etc. making it unusable. With synthetic data we can generate data that\u2019s statistically accurate, privacy-protected, and safe to share.</p> <p>This talk was given at:</p> <ul> <li>PyCon US 2022 - Lightning Talk</li> <li>PyRVA 6/8/2022 - Full Talk</li> <li>PyOhio - Thunder (15 min) Talk</li> <li>PyCon Latam 8/26/2022 - Full Talk</li> <li>DigitalOcean Deploy - Full Talk</li> </ul> <p>Slides </p>"},{"location":"speaking/temporal-replay-workshops/","title":"Temporal Replay Workshops","text":"<p>Every year Temporal holds an annual conference, Replay, and the education team holds all day Workshops teaching attendees how to use Temporal.</p> <p>Unfortunately Temporal neither records these Workshops nor keeps the old website around, so there is no record of these.  The links lead to the landing page of Temporal's LMS courses.</p> <ul> <li>2025 (Upcoming) - Temporal 102: Exploring Durable Execution and Crafting an Error Handling Strategy in Java</li> <li>2024 - Temporal 101: Introducing the Temporal Platform and Temporal 102: Exploring Durable Execution in Python</li> <li>2023 - Temporal 101: Introducing the Temporal Platform and Temporal 102: Exploring Durable Execution in Java</li> </ul>"},{"location":"tutorials/","title":"Tutorials","text":"<p>These are technical tutorials on various topics that interest me or problems I have solved. </p> <p>These tutorials are in a similar style to the tutorials you'd find at DigitalOcean, as that is where my primary  technical writing education occurred. </p> <p>I routinely update and test these tutorials, so pay attention to messaging at the top of each that details the last time the  tutorial was updated.</p> <p>If you find an error in a tutorial or want to request a tutorial, please open an issue in GitHub</p> <p>I hope these help you out! If they do and you want to give me a shoutout, feel free to tweet at me</p>"},{"location":"tutorials/how-to-build-a-7-days-to-die-server-on-ubuntu/","title":"How To Build a 7 Days To Die Server on Ubuntu","text":"<p>7 Days to Die has easily become one of my favorite video games. It is essentially a cross between Minecraft and Left 4 Dead and I find it absolutely thrilling. In this tutorial you'll setup a 7D2D server on Ubuntu.</p>","tags":["Server","Linux","Ubuntu"]},{"location":"tutorials/how-to-build-a-7-days-to-die-server-on-ubuntu/#the-premise","title":"The Premise","text":"<p>7 Days to Die  is an open-world sandbox that combines a first person shooter with survival horror, tower defense and traditional RPG elements. The game takes place in a post-apocalyptic world overrun by zombies. Your goal is to gather resources, craft shelter, food, and weapons, and survive the notorious blood moons that happen every 7 days where massive hordes of zombies attack.</p>","tags":["Server","Linux","Ubuntu"]},{"location":"tutorials/how-to-build-a-7-days-to-die-server-on-ubuntu/#prerequisites","title":"Prerequisites","text":"<p>To complete this turoial, you'll need:</p> <ul> <li>An Ubuntu 20.04 server with a non-root user setup. Use this tutorial for initial server setup, except name your user <code>days</code>. I personally use a DigitalOcean server to host my game. However, cloud hosting for your server can be expensive. You may be better off building the server locally with an old PC. Note: This server would do well to have at least 12GB of RAM and 4 CPUs. You may need more depending on your configuration and how many players you wish to support.</li> <li>A copy of 7 Days to Die. You can purchase the game on the Steam Store</li> </ul> <p>Tested Ubuntu Versions</p> <p>This tutorial has been successfully tested against the followng Ubuntu versions:</p> <pre><code>* 24.04\n* 22.04\n* 20.04\n</code></pre>","tags":["Server","Linux","Ubuntu"]},{"location":"tutorials/how-to-build-a-7-days-to-die-server-on-ubuntu/#step-1-installing-the-game","title":"Step 1 - Installing the Game","text":"<p>First thing you'll need to do is gain access to your server. If it's a local machine you can simply login via the UI or if it's a server, you should ssh in. Login as your non-root user 7d2d and update the server to the latest version so you have the most recent packages.</p> <pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y\n</code></pre> <p>Next, you'll need to install some packages for running 7d2d. You'll need to install a text editor (<code>nano</code>, <code>vim</code>, <code>emacs</code>, etc.) to be able to modify configuration files as well as the program <code>screen</code> to create virtual terminal sessions for running your game server. You'll need to install <code>wget</code> to install the Steam bash line tool and <code>lib32gcc1</code> to run the SteamCMD. </p> Ubuntu 22.04 or newerUbuntu 20.04 or older <p>Install them with the following bash:</p> <pre><code>sudo apt install -y vim screen wget lib32gcc-s1\n</code></pre> <p>Install them with the following bash:</p> <pre><code>sudo apt install -y vim screen wget lib32gcc1\n</code></pre> <p>Once you have the packages installed, you'll need to install SteamCMD. Use <code>wget</code> to download the CLI tool:</p> <pre><code>wget https://steamcdn-a.akamaihd.net/client/installer/steamcmd_linux.tar.gz\n</code></pre> <p>Once you have downloaded the tool, extract the <code>tar</code> archive using the <code>tar</code> bash:</p> <pre><code>tar -xvf steamcmd_linux.tar.gz\n</code></pre> <p>Next, start a SteamCMD session. Once you're logged in you'll see the SteamCMD prompt <code>Steam&gt;</code>:</p> <p><pre><code>./steamcmd.sh\n</code></pre> Next, you'll need to set where to install the game files. Call this folder 7days and install it in the current directory. This step must be done before login</p> <pre><code>force_install_dir ./7days\n</code></pre> <p>7 Days to Die is a game that doesn't require you to login to your personal account to download the game. So you'll need to login as an anonymous user. </p> <pre><code>login anonymous\n</code></pre> <p>Now you're ready to install the game. Steam uses app ids to distinguish which game to download. You can view the whole list on the Steam Dedicated Servers List. The id for 7D2D is 294420 which we'll use to install the game.</p> Current Stable Version of the GameSpecific Previous Stable VersionLatest Experimental Version <p>To install the current stable version of the game, use the following command:</p> <pre><code>app_update 294420\n</code></pre> <p>To install a previous stable version of the game, use the following command:</p> <pre><code>app_update 294420 -beta v1.2\n</code></pre> <p>To install the current experimental beta, use the following command:</p> <pre><code>app_update 294420 -beta latest_experimental\n</code></pre> <p>The game will now download and unpack in the directory. Once this is done you can quit the SteamCMD.</p> <pre><code>quit\n</code></pre> <p>Finally, 7D2D runs on port 26900 by default. If you enabled UFW from the Ubuntu initial server setup then you'll need to open this port to allow traffic along with a range within 5 other ports for other communication. Running the following bash will properly configure your firewall.</p> <pre><code>sudo ufw allow 26900:26905/tcp &amp;&amp; sudo ufw allow 26900:26905/udp\n</code></pre> <p>Once you've done this, you're ready to configure and launch the server.</p>","tags":["Server","Linux","Ubuntu"]},{"location":"tutorials/how-to-build-a-7-days-to-die-server-on-ubuntu/#step-2-configuring-and-running-the-game","title":"Step 2 - Configuring and Running the Game","text":"<p>Now that you have the game installed navigate within the 7days folder to location of the configuration file.</p> <pre><code>cd 7days\n</code></pre> <p>The server configuration file is named serverconfig.xml. There are many settings within this file that can be tweaked, and they are all well documented. Below is a chart of some of the more interesting settings you may wish to change. This is not a comprehensive list of all settings.</p> Property Description ServerName The name of your server ServerDescription The description to be shown in the server browser ServerPort Which port to run your server on. If you change this you'll need to update your firewall ServerVisibility 0 = Not Listed, 1 = Friends, 2 = Public ServerPassword Password to get into your server. Leave blank for no password EACEnabled Easy Anti Cheat support. You'll need to set this to false if you plan on using mods. GameWorld Which map you want to play on. There are a handful of PREGENs. Set to RWG if you want to randomly generate your own. This does take a long time and can exhaust server resources. WorldGenSeed A seed for randomly generating your own world WorldGenSize Size of the world. From 2048 - 16384 LootRespawnDays How often loot respawns MaxSpawnedZombies How many zombies can spawn. Has a significant performance impact MaxSpawnedAnimals How many animals can spawn. Has a significant performance impact <p>Once you have modified the file to your liking you will need to start a <code>screen</code> session. This will create a virtual terminal session that will persist even after you have disconnected your terminal from the server. </p> <p>To start a session type the <code>screen bash</code>:</p> <pre><code>screen\n</code></pre> <p>You'll be prompted with some license information. Press Enter if you agree and now you're in a screen session. </p> <p>Now you can start the server by running the following bash:</p> <pre><code>./startserver.sh -configfile=serverconfig.xml\n</code></pre> <p>It does take a few minutes for your server to start. Once you see the following output your server is ready to be connected to.</p> <pre><code>Using config file: serverconfig.xml\n[UnityMemory] Configuration Parameters - Can be set up in boot.config\n    \"memorysetup-bucket-allocator-granularity=16\"\n    \"memorysetup-bucket-allocator-bucket-count=8\"\n    \"memorysetup-bucket-allocator-block-size=4194304\"\n    \"memorysetup-bucket-allocator-block-count=1\"\n    \"memorysetup-main-allocator-block-size=16777216\"\n... # Continues from here\n</code></pre> <p>Once you're ready to disconnect from the virtual session you can use the bash CTRL + A + D. Now you'll be able to continue doing things on the server. Once you're ready to reconnect to the session use the bash:</p> <pre><code>screen -r\n</code></pre> <p>You can learn more about the various screen commands here</p> <p>Now that your server is running you can now connect from your client and play.</p>","tags":["Server","Linux","Ubuntu"]},{"location":"tutorials/how-to-build-a-7-days-to-die-server-on-ubuntu/#step-3-connecting-to-your-server","title":"Step 3 - Connecting to Your Server","text":"<p>Go to Steam and launch your 7 Days to Die Game. You'll want to click on the Join Game menu option.</p> <p></p> <p>Once you do this click on the Connect To IP button in the bottom right hand portion of the screen and enter your IP address. If you setup a DNS name for your server that will also work here. If you setup a password you'll be prompted for it after you click connect.</p> <p></p> <p>The server will start downloading the configuration and when it's done you'll load into your server.</p> <p></p>","tags":["Server","Linux","Ubuntu"]},{"location":"tutorials/how-to-build-a-7-days-to-die-server-on-ubuntu/#conclusion","title":"Conclusion","text":"<p>In this tutorial you setup a 7 Days to Die server and loaded into it. In the next tutorial we'll install the Darkness Falls mod and discuss how to configure and even modify the mod.</p> <p>Like this tutorial and want to buy me a coffee? Feel free! I'll appreciate it.</p> <p>If you want to run this server on DigitalOcean you can click here for a $200 free credit for 2 months with a new account.</p>","tags":["Server","Linux","Ubuntu"]},{"location":"tutorials/redirecting-web-traffic-using-flask/","title":"Redirecting Web Traffic Using Flask","text":"<p>In this tutorial we'll use Flask and DigitalOcean's App Platform to redirect traffic from one URL to another.</p>"},{"location":"tutorials/redirecting-web-traffic-using-flask/#the-issue","title":"The Issue","text":"<p>I came about trying to solve this problem because I wanted to create a permanent link to my Discord server so people could join. Discord currently allows this kind of link to be created but it's a shortened bitly type link that isn't easy to remember. I wanted to be able to tell people \"Hey, go to discord.mason.dev to join my server\" and they would be taken to this bitly type link, thus joining my server. </p>"},{"location":"tutorials/redirecting-web-traffic-using-flask/#possible-solutions","title":"Possible Solutions","text":"<p>A simple solution to this would be simply to just use Nginx and perform a 301 redirect. I initially thought about doing this but it posed a few issues. The first was I knew I was going to deploy this application to DigitalOcean's App Platform and I was feeling suuuuuper lazy and didn't want to write a Dockerfile. Let's be honest. This had nothing to do with App Platform. I was just being lazy. The second was I felt this was too simple. Everyone's done this a million times. I wanted to solve the problem in Python (I had delusions of adding more functionality to this app, silly Mason) so I was going to solve it in Python. </p>"},{"location":"tutorials/redirecting-web-traffic-using-flask/#the-code","title":"The Code","text":"<p>So I wrote a simple Flask app. Like, this app is only one function that's one line long. Flask has a <code>redirect</code> method so I'll just use that and for extra spiciness I'll get the URL to redirect to from the environment variables. Woohoo for dynamic code ;) </p> <p>So here's the code.</p> <pre><code>import os\nimport logging\nfrom flask import Flask,redirect\n\n\napp = Flask(__name__)\n\n@app.route('/')\ndef hello():\n    # Use the built in Flask redirect function to redirect the traffic\n    # Adding the 301 code is a nice to have feature that makes web browsers\n    # happy. \n    return redirect(os.environ.get(\"REDIRECT_TO\", \"https://mason.dev\"), \n                    code=301)\n\nif __name__ == '__main__':\n    # Bind to PORT if defined, otherwise default to 5000.\n    logger = logging.getLogger()\n\n    # Set the log level to DEBUG. This will increase \n    # verbosity of logging messages\n    logger.setLevel(logging.DEBUG)\n\n    # Add the StreamHandler as a logging handler\n    logger.addHandler(logging.StreamHandler())\n\n    app.run(host='0.0.0.0', port=8080)\n</code></pre> <p>As you can see, there's nothing special about this code. It redirects the <code>/</code> route to wherever I want to redirect it to. That's it. No frills. No fluff. I actually think the logging section was a bit much here but writing that part is almost like auto pilot for my brain at this point.</p>"},{"location":"tutorials/redirecting-web-traffic-using-flask/#deploying-to-app-platform","title":"Deploying to App Platform","text":"<p>So now that I have this let's deploy it to DigitalOcean's App Platform.</p> <p>The first thing I need to do is create a GitHub repo for it and upload it. If you haven't checked out repo.new I recommend it. Seems like the theme of this blog is laziness and this really helps. </p> <p>Next, connect your GitHub account to App Platform. You'll have to specify which repositories you want App Platform to have access to and I tend to do this on an individual basis. You can just let it at all of them if you wanted. </p> <p>So go ahead and select GitHub (or Gitlab if that's where your code is) </p> <p>Then select the repository you want to deploy from and a specific branch </p> <p>App Platform uses Build Packs to detect what the app is, so it detected this was a Python app. Go ahead and add your environment variable <code>REDIRCT_TO</code> here otherwise it'll just redirect to my personal site. </p> <p>Give your service a name. It's not terribly important but it helps keep things straight. </p> <p>Select your compute plan. This would be the same price I would pay for a $5 Droplet with a lot less of the hassle so I like it. Once done launch your app. </p> <p>It'll take a little bit for your app to build and deploy. Once it's done deploying for the first time you'll notice that you get a default URL that is the name of your app + a hash on the ondigitalocean.app domain. If this works for you, great! You're done. But, if you want to use your own personal domain you'll have to do one more step.</p> <p>Go to the Settings tab and scroll down to the Domains section. Here you'll click Edit to add a domain. </p> <p>Add your domain that you want to redirect to, and it'll show you instructions for either managing the DNS record on DigitalOcean or your own DNS. Currently mason.dev is on a separate DNS provider and as is the theme of this blog, I'm too lazy to move it. So, I'll need the Adding a CNAME instructions. </p> <p>Once you've done this just wait a few minutes while your SSL certificate is setup and DNS to propagate. You'll see your new domain take the place of your old one and you're done!</p>"},{"location":"tutorials/redirecting-web-traffic-using-flask/#the-point","title":"The Point","text":"<p>This was simple yet fun app to build and DigitalOcean's App Platform helped with that. While I knew how to do this via Nginx because I have past DevOps experience, I was feeling really lazy the day I wrote this. So I wrote it in Python because even though it may not be the best solution that someone could come up with, it is a solution that someone will come up with. People tend to reach to languages they are familiar with when they have a problem they are trying to solve. The fact that App Platform made deploying this solution as simple as writing the code was is truly amazing. I can't wait for you to enable my laziness more in the future.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/","title":"How To Build a Durable AI Agent with Temporal and Python","text":"<p>AI Agents are distributed systems, and come with all of the challenges expected. Temporal provides Durable Execution for software, and pairing it with AI Agents is a match made in heaven. In this tutorial you'll implement an AI Agent using Temporal's Python SDK.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#introduction","title":"Introduction","text":"<p>An AI agent uses large language models (LLMs) to plan and execute steps towards a goal. While attempting to reach its goal, the agent can perform actions such as searching for information, interacting with external services, and even calling other agents.  However, building reliable AI agents presents various challenges.  Network failures, long-running workflows, observability challenges, and more make building AI agents a textbook distributed systems problem.</p> <p>Temporal orchestrates long-running workflows, automatically handles failure cases from network outages to server crashes, provides insights into your running applications, and more. These features provide the resiliency and durability necessary to build reliable agents that users can rely on.</p> <p>In this tutorial you'll build an AI agent using Temporal that searches for events in a given city, helps you book a plane ticket, and creates an invoice for the trip.  The user will interact with this application through a chatbot interface, communicating with the agent using natural language. Throughout this tutorial you will implement the following components:</p> <ul> <li>Various tools the agent will use to search for events, find flights, and generate invoices.</li> <li>An agent goal that will specify what overall task the agent is trying to achieve and what tools it is allowed to use.</li> <li>Temporal Workflows that will orchestrate multi-turn conversations and ensure durability across failures</li> <li>Temporal Activities that execute tools and language model calls with automatic retry logic</li> <li>A FastAPI backend that connects the web interface to your Temporal Workflows</li> <li>A web-based chat interface that allows users to interact with the agent</li> </ul> <p>By the end of this tutorial, you will have a modular, durable AI agent that you can extend to run any goal using any set of tools. Your agent will be able to recover from failure, whether it's a hardware failure, a tool failure, or an LLM failure. And you'll be able to use Temporal to build reliable AI applications that maintain state and provide consistent user experiences.</p> <p>You can find the code for this tutorial on GitHub in the tutorial-temporal-ai-agent repository.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#prerequisites","title":"Prerequisites","text":"<p>Before starting this tutorial, ensure that you have the following on your local machine:</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#required","title":"Required","text":"<ul> <li>The Temporal CLI development service installed and verified.</li> <li>Python 3.9 or higher installed.  Verify your installation by running <code>python3 --version</code> in your terminal.</li> <li>The <code>uv</code> package and project manager installed. <code>uv</code> is a modern, fast Python package manager that will handle virtual environments and dependencies. </li> <li>The command line tool curl installed for downloading certain files.</li> <li>Node.js 18 or higher installed. You can verify your installation with <code>node --version</code> and <code>npm --version</code>.</li> <li>An OpenAI API key saved securely where you can access it. You may need to create an OpenAI account first. You will use this key to configure the LLM integration.</li> </ul> <p>Note</p> <p>OpenAI API Keys require purchasing credits to use. You can succeed with this tutorial with minimal credits; in our experience, less than $1 will suffice.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#optional","title":"Optional","text":"<p>You can opt to use real API services for your tools, or use provided mock functions. </p> <ul> <li>A free RapidAPI Sky Scrapper API Key saved securely where you can access it. You will use this to search for flights.</li> <li>A free Stripe Account with a configured sandbox. You will use this to generate fake invoices for the flights that are being booked.</li> </ul>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#concepts","title":"Concepts","text":"<p>Additionally, this tutorial assumes you have basic familiarity with:</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#programming-concepts","title":"Programming Concepts","text":"<ul> <li>Temporal fundamentals such as Workflows, Activities, Workers, Signals, and Queries</li> <li>Python fundamentals such as functions, classes, async/await syntax, and virtual environments</li> <li>Command line interface and running commands in a terminal or command prompt  </li> <li>REST API concepts including HTTP requests and JSON responses</li> <li>How to set and use environment variables in your operating system</li> </ul>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#ai-concepts","title":"AI Concepts","text":"<ul> <li>A Mental Model for Agentic AI Applications</li> <li>Building an agentic system that's actually production ready</li> <li>Why Agentic Flows Need Distributed Systems</li> </ul>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>Before you start coding, you need to set up your Python developer environment. In this step, you will set up your project structure, install the necessary Python packages, and configure the Python environment needed to build your AI agent.</p> <p>First, create your project using <code>uv</code>:</p> <pre><code>uv init temporal-ai-agent --python \"&gt;=3.9\"\n</code></pre> <p><code>uv</code> is a modern Python project and packaging tool that sets up a project structure for  you. Running this command creates the following default Python package structure for you:</p> <pre><code>temporal-ai-agent/\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .python-version\n\u251c\u2500\u2500 main.py\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 pyproject.toml\n\u2514\u2500\u2500 uv.lock\n</code></pre> <p>It automatically runs a <code>git init</code> command for you, provides you with the default <code>.gitignore</code> for Python, creates a <code>.python-version</code> file that has the project's default Python version, a README.md, a Hello World <code>main.py</code> program, and a <code>pyproject.toml</code> file for managing the projects packages and environment.</p> <p>Next, change directories into your newly created project:</p> <pre><code>cd temporal-ai-agent\n</code></pre> <p>You won't need the <code>main.py</code> file, so delete it:</p> <pre><code>rm main.py\n</code></pre> <p>Next, create your virtual environment by running the following command:</p> <pre><code>uv venv\n</code></pre> <p>This creates a virtual environment named <code>.venv</code> in the current working directory.</p> <p>Now that you have a virtual environment created, add the dependencies needed to build your AI agent system:</p> <pre><code>uv add python-dotenv fastapi jinja2 litellm stripe temporalio uvicorn requests\n</code></pre> <p>This installs all the necessary packages: - <code>python-dotenv</code> - For loading environment variables from a <code>.env</code> file - <code>fastapi</code> and <code>uvicorn</code> - Web framework and server for the API backend - <code>jinja2</code> - Template engine - <code>litellm</code> - Unified interface for different language model providers - <code>stripe</code> - Payment processing library for the invoice generation demo - <code>temporalio</code> - The Temporal Python SDK - <code>requests</code> - HTTP library for API calls</p> <p>Finally, add the following lines to the end of your <code>pyproject.toml</code> file:</p> <pre><code>[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n# Tell hatchling what to include\n[tool.hatch.build.targets.wheel]\npackages = [\"activities\", \"api\", \"models\", \"prompts\", \"shared\", \"tools\", \"workflows\"]\n</code></pre> <p>This configures <code>uv</code> as to which packages to include and enable for execution. You will create these packages later in the tutorial.</p>  The <code>pyproject.toml</code> is complete and will need no more revisions. You can review the complete file and copy the code here   [pyproject.toml](https://github.com/temporal-community/tutorial-temporal-ai-agent/blob/main/pyproject.toml)  <pre><code>[project]\nname = \"temporal-ai-agent\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.9\"\ndependencies = [\n    \"python-dotenv&gt;=1.0.0\",\n    \"fastapi&gt;=0.115.12\",\n    \"jinja2&gt;=3.1.6\",\n    \"litellm&gt;=1.72.2\",\n    \"stripe&gt;=12.2.0\",\n    \"temporalio&gt;=1.12.0\",\n    \"uvicorn&gt;=0.34.3\",\n    \"requests&gt;=2.32.4\",\n]\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n# Tell hatchling what to include\n[tool.hatch.build.targets.wheel]\npackages = [\"activities\", \"api\", \"models\", \"prompts\", \"shared\", \"tools\", \"workflows\"]\n</code></pre> <p>Next, create a <code>.env</code> file to store your configuration:</p> <pre><code>touch .env\n</code></pre> <p>Next, copy the following configuration to your <code>.env</code> file.</p> <pre><code># LLM Configuration\nLLM_MODEL=openai/gpt-4o\nLLM_KEY=YOUR_OPEN_AI_KEY\n\n# Set if the user should click a Confirm button in the UI to allow the tool\n# to execute\nSHOW_CONFIRM=True\n\n# Temporal Configuration\nTEMPORAL_ADDRESS=localhost:7233\nTEMPORAL_NAMESPACE=default\nTEMPORAL_TASK_QUEUE=agent-task-queue\n\n# (Optional) - Uncomment both lines and set RAPIDAPI_KEY if you plan on \n# using the real flights API\n# RAPIDAPI_KEY=YOUR_RAPID_API_KEY\n# RAPIDAPI_HOST_FLIGHTS=sky-scrapper.p.rapidapi.com\n\n# (Optional) - Uncomment and set STRIPE_API_KEY if you plan on using the Stripe\n# API to generate a fake invoice\n# STRIPE_API_KEY=YOUR_STRIPE_API_KEY\n\n# Uncomment if connecting to Temporal Cloud using mTLS (not needed for local dev server)\n# TEMPORAL_TLS_CERT='path/to/cert.pem'\n# TEMPORAL_TLS_KEY='path/to/key.pem'\n\n# Uncomment if connecting to Temporal Cloud using API key (not needed for local dev server)\n# TEMPORAL_API_KEY=abcdef1234567890\n</code></pre> <p>Once copied, replace <code>YOUR_OPEN_API_KEY</code> with your OpenAI API key. Setting <code>SHOW_CONFIRM=True</code> requires the user to confirm each tool prior to it being executed. This will allow you to see what the agent is doing step by step. These are the only two mandatory variables to set. This tutorial provides both an ability to create pseudo tools that perform simulations, or tools that use external APIs to achieve their goals. If you plan on using the RapidAPI SkyScraper API to look up flight data or the Stripe API to generate an invoice, you can uncomment these lines and provide the API keys here.</p> <p>Additionally, if you plan on connecting to Temporal Cloud, you will need to update the <code>TEMPORAL_ADDRESS</code> and <code>TEMPORAL_NAMESPACE</code> parameters to connect to your Temporal Cloud instance. You will also need to uncomment and set the <code>TEMPORAL_TLS</code> or <code>TEMPORAL_API_KEY</code> variables, depending on which authentication method you are using.</p> <p>Note</p> <p>As this project is using LiteLLM, it supports various different LLM providers. This tutorial will use OpenAI's gpt-4o, but you are welcome to use whichever LLM you wish, so long as it is supported by LiteLLM.</p> <p>At this point, you have configured your developer environment to include a Python project managed by <code>uv</code> with all required dependencies to build a Temporal powered agentic AI, and all necessary environment variables. </p> <p>Now that you have set up your developer environment, you will build the tools that your agent will use to perform the various tasks it needs to accomplish its goal.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#constructing-the-agent-toolkit","title":"Constructing the agent toolkit","text":"<p>In this step, you will acquire the tools that will be available to your agent. Agents are aware of the tools they have available to them while attempting to achieve their goal. The agent will evaluate which tools are available and execute a tool if the agent believes it will provide the result the agent needs to progress in its task. </p> <p>These tools can take various forms, but in this tutorial they're implemented as a series of independent Python scripts that provide data in a specific format that the agent can process.  There are three tools: a <code>find_events</code> tool, a <code>search_flights</code> tool, and a <code>create_invoice</code> tool. The LLM will decide when to use each tool as it interacts with the user who is trying to find an event and book a flight to attend it. You could implement these tools yourself, or you could download a tool and provide it to an agent. For this tutorial, you will download the tools directly from the companion GitHub repository.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#setting-up-the-tools-package","title":"Setting up the <code>tools</code> package","text":"<p>To get started, first create the directory for your tools modules:</p> <pre><code>mkdir tools\n</code></pre> <p>Then change directories into it:</p> <pre><code>cd tools\n</code></pre> <p>However, for this to be an importable tools package, you will need to add a <code>__init__.py</code> file. It can be blank for now, so create it with the following command:</p> <pre><code>touch __init__.py\n</code></pre> <p>Now that you have set up the structure for your tools package, you'll acquire and test the tools needed to have the agent succeed with its goal.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#acquiring-the-find_events-tool","title":"Acquiring the <code>find_events</code> tool","text":"<p>The <code>find_events</code> tool searches for events within a given city during a certain time of year. The tool takes a month and city as inputs and provides events for not only the month that was provided, but the months before and after the given month as well.  The LLM will use this tool to search for events when helping the user plan their trip. This tool doesn't use an API, but rather simulates looking events up in a data store using mock data.</p> <p>First, create a <code>data</code> directory within the <code>tools</code> directory to store the sample event data and change directories into it:</p> <pre><code>mkdir data\ncd data\n</code></pre> <p>Next, run the following command to download the sample data from the companion GitHub repository:</p> <pre><code>curl -o find_events_data.json https://raw.githubusercontent.com/temporal-community/tutorial-temporal-ai-agent/main/tools/data/find_events_data.json\n</code></pre> <p>You can confirm you have the correct data by running the following command to sample the file and comparing it to the output:</p> <pre><code>head -8 find_events_data.json\n</code></pre> <pre><code>{\n  \"New York\": [\n    {\n      \"eventName\": \"Winter Jazzfest\",\n      \"dateFrom\": \"2025-01-10\",\n      \"dateTo\": \"2025-01-19\",\n      \"description\": \"A multi-venue jazz festival featuring emerging and established artists performing across Greenwich Village venues.\"\n    },\n</code></pre> <p>Note</p> <p>If the dates appear to be far in the past, don't worry.  There is logic within the <code>find_events</code> tool that automatically adjusts the date to ensure that no dates can be presented that are in the past.</p> <p>Next, change directories back up one directory to the <code>tools</code> directory:</p> <pre><code>cd ..\n</code></pre> <p>Now that you have the data, download the <code>find_events</code> tool using the command:</p> <pre><code>curl -o find_events.py https://raw.githubusercontent.com/temporal-community/tutorial-temporal-ai-agent/main/tools/find_events.py\n</code></pre> <p>Open the file and explore the logic; you should never download a file from the internet and just trust it.</p> <p>Try to answer the following questions about the codebase: * Where in the code does it determine the adjacent months? * How does the tool prevent the data from <code>find_events_data.json</code> being presented with a date that has already passed? * What is the schema for the data that will be returned?</p> <p>Once you have finished reviewing the code, navigate to the root directory of your project and create a scripts directory for testing this tool. The root of your project should be one level higher your current directory, so you can get there by running the following command:</p> <pre><code>cd ..\n</code></pre> <p>Create the <code>scripts</code> directory:</p> <pre><code>mkdir scripts\n</code></pre> <p>Now create a test script named <code>find_events_test.py</code> in the <code>scripts</code> directory and add the following to test your script:</p> <pre><code>import json\n\nfrom tools.find_events import find_events\n\nif __name__ == \"__main__\":\n    search_args = {\"city\": \"Austin\", \"month\": \"December\"}\n    results = find_events(search_args)\n    print(json.dumps(results, indent=2))\n</code></pre> <p>This script will check for events in Austin, TX in the month of December.</p> <p>From the root of your project, run the script using the following command to verify it's configured correctly:</p> <pre><code>uv run scripts/find_events_test.py\n</code></pre> <p>You should see the following output:</p> <pre><code>{\n  \"note\": \"Returning events from December plus one month either side (i.e., November, December, January).\",\n  \"events\": [\n    {\n      \"city\": \"Austin\",\n      \"eventName\": \"Austin Celtic Festival\",\n      \"dateFrom\": \"2025-11-08\",\n      \"dateTo\": \"2025-11-09\",\n      \"description\": \"Celebration of Celtic culture featuring traditional music, dance, crafts, and Irish food.\",\n      \"month\": \"previous month\"\n    },\n    {\n      \"city\": \"Austin\",\n      \"eventName\": \"Trail of Lights\",\n      \"dateFrom\": \"2025-12-05\",\n      \"dateTo\": \"2025-12-23\",\n      \"description\": \"Holiday light display in Zilker Park featuring festive decorations, food vendors, and family activities.\",\n      \"month\": \"requested month\"\n    }\n  ]\n}\n</code></pre> <p>Now that you have the <code>find_events</code> tool functioning, it's time to do the same for the <code>search_flights</code> tool.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#acquiring-the-search_flights-tool","title":"Acquiring the <code>search_flights</code> tool","text":"<p>The <code>search_flights</code> tool searches roundtrip flights to a destination. The tool takes the origin, destination, arrival date, and departure date as arguments and returns flight data containing details such as carrier, price, and flight code for the flights. The LLM will use this tool to find flights to the location once the user has selected the dates they wish to travel. This tool can either use the RapidAPI SkyScraper API if you have an API key configured in your <code>.env</code> file, or it will generate mock data if it's unable to detect the API key.</p> <p>First, change directories into the <code>tools</code> directory:</p> <pre><code>cd tools\n</code></pre> <p>Then get the tool by running the following command to download it from the companion GitHub repository:</p> <pre><code>curl -o search_flights.py https://raw.githubusercontent.com/temporal-community/tutorial-temporal-ai-agent/main/tools/search_flights.py\n</code></pre> <p>Next, familiarize yourself with the tool by reviewing the code. Try to answer the following questions about the code: * What is the purpose of the <code>search_flights</code> function? (It's not as straightforward of an answer as it may appear) * How many REST API calls does is it take to call complete the real flight API search?</p> <p>Once you have finished reviewing the code, you will test it.</p> <p>Create another test within the <code>scripts</code> directory named <code>search_flights_test.py</code> and add the following code:</p> <pre><code>import json\n\nfrom tools.search_flights import search_flights\n\nif __name__ == \"__main__\":\n\n    flights = search_flights(\n        {\n            \"origin\": \"ORD\",\n            \"destination\": \"DFW\",\n            \"dateDepart\": \"2025-09-20\",\n            \"dateReturn\": \"2025-09-22\",\n        }\n    )\n    print(json.dumps(flights, indent=2))\n</code></pre> <p>This test searches for a flight from Chicago to Dallas-Fort Worth. However, since this tool can operate in either a mock mode or live API mode, there are two ways to verify it.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#testing-the-mocked-search_flight-tool","title":"Testing the mocked <code>search_flight</code> tool","text":"<p>Let's start by testing it without the RapidAPI key.  If you have that set in your <code>.env</code> file, comment it out for now, or skip this step.</p> <p>Change directories back to the root of the project and run the test using the following command:</p> <pre><code>cd ..\nuv run scripts/search_flights_test.py\n</code></pre> <p>Your output will vary, as the mock data function randomly generates results. The output should, however, look something like this with more items in the results list:</p> <pre><code>{\n  \"currency\": \"USD\",\n  \"destination\": \"DFW\",\n  \"origin\": \"ORD\",\n  \"results\": [\n    {\n      \"operating_carrier\": \"Southwest Airlines\",\n      \"outbound_flight_code\": \"WN427\",\n      \"price\": 462.43,\n      \"return_flight_code\": \"WN744\",\n      \"return_operating_carrier\": \"Southwest Airlines\"\n    }\n  ]\n}\n</code></pre> <p>If you aren't planning on using the Sky Scrapper API, you can skip this next step and continue if you'd like.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#testing-the-sky-scrapper-powered-search_flights-tool","title":"Testing the Sky Scrapper powered <code>search_flights</code> tool","text":"<p>Testing the API-powered version of the tool is similar to testing the mocked version.</p> <p>First, if you haven't uncommented the <code>RAPID_API</code> lines in your <code>.env</code> file and added your API key, do this before running the test. You will also need to uncomment the <code>RAPIDAPI_HOST_FLIGHTS</code> environment variable as this is the endpoint the tool will be accessing.</p> <pre><code>RAPIDAPI_KEY=YOUR_RAPID_API_KEY\nRAPIDAPI_HOST_FLIGHTS=sky-scrapper.p.rapidapi.com\n</code></pre> <p>Next, review the code in <code>scripts/search_flights_test.py</code> and make sure that the <code>dateDepart</code> and <code>dateReturn</code> dates are both in the future. At this point you have no way of determining if the dates are in the past, and the API will return an error if you try to search for flights in the past. </p> <p>Once you've reviewed the code, make sure you are at the root directory of the project. If are still in the <code>scripts</code> directory, run the following command:</p> <pre><code>cd ..\n</code></pre> <p>Then run the test using the following command:</p> <pre><code>uv run scripts/search_flights_test.py\n</code></pre> <p>If you've changed the dates or cities, you may see different results, but the format should be similar to this:</p> <pre><code>Searching for: ORD\nSearching for: DFW\n{\n  \"origin\": \"ORD\",\n  \"destination\": \"DFW\",\n  \"currency\": \"USD\",\n  \"results\": [\n    {\n      \"outbound_flight_code\": \"NK824\",\n      \"operating_carrier\": \"Spirit Airlines\",\n      \"return_flight_code\": \"NK828\",\n      \"return_operating_carrier\": \"Spirit Airlines\",\n      \"price\": 119.98\n    },\n  ]\n}\n</code></pre> <p>Info</p> <p>If the API gives you cryptic error messages such as Something went wrong or returns an incomplete response, you can try running it a few times and see if you get a different response.</p> <p>Now that you have finished testing the <code>search_flights</code> tool, you can add the final tool to the agent's toolkit.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#acquiring-the-create_invoice-tool","title":"Acquiring the <code>create_invoice</code> tool","text":"<p>The final tool is the <code>create_invoice</code> tool. The tool takes the customer's email and trip information such as the cost of the flight, the description of the event, the number of days until the invoice is due, and generates a sample invoice for that user showing the details of the flight and the cost. The LLM will use this tool to invoice the customer once the customer has confirmed their travel plans. This tool can either use the Stripe API if you have an API key configured in your <code>.env</code> file, or it will generate a mock invoice if it is unable to detect an API key.</p> <p>First, change directories into the <code>tools</code> directory again:</p> <pre><code>cd tools\n</code></pre> <p>Then get the tool by running the following command to download it from the companion GitHub repository:</p> <pre><code>curl -o create_invoice.py https://raw.githubusercontent.com/temporal-community/tutorial-temporal-ai-agent/main/tools/create_invoice.py\n</code></pre> <p>Next, familiarize yourself with the tool by reviewing the code. Try to answer the following questions about the code: * What customer related verification does the tool do before creating the invoice? * What does the tool do if this verification fails?</p> <p>Once you have finished reviewing the code, test it.</p> <p>Create another test within the <code>scripts</code> directory named <code>create_invoice_test.py</code> and add the following code:</p> <pre><code>from tools.create_invoice import create_invoice\n\nif __name__ == \"__main__\":\n\n    args_create = {\n        \"email\": \"ziggy.tardigrade@example.com\",\n        \"amount\": 150.00,\n        \"description\": \"Flight to Replay\",\n        \"days_until_due\": 7,\n    }\n    invoice_details = create_invoice(args_create)\n    print(invoice_details)\n</code></pre> <p>However, since this tool can operate in either a mock mode or live API mode, there are two ways to verify it.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#testing-the-mocked-create_invoice-tool","title":"Testing the mocked <code>create_invoice</code> tool","text":"<p>Start by testing it without the Stripe key.  If you have it set in your <code>.env</code> file, comment it out for now, or skip this step.</p> <p>Change directories back to the root project directory and run the test using the following command:</p> <pre><code>cd ..\nuv run scripts/create_invoice_test.py\n</code></pre> <p>The output should be:</p> <pre><code>[CreateInvoice] Creating invoice with: {'email': 'ziggy.tardigrade@example.com', 'amount': 150.0, 'description': 'Flight to Replay', 'days_until_due': 7}\n{'invoiceStatus': 'generated', 'invoiceURL': 'https://pay.example.com/invoice/12345', 'reference': 'INV-12345'}\n</code></pre> <p>If you aren't planning on using the Stripe API, you can skip this next step and continue if you'd like.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#testing-the-stripe-powered-create_invoice-tool","title":"Testing the Stripe-powered <code>create_invoice</code> tool","text":"<p>Testing the Stripe powered version of the tool is nearly identical to testing the mocked version of the tool.</p> <p>First, if you haven't uncommented the <code>STRIPE_API_KEY</code> lines in your <code>.env</code> file and added your API key, do this before running the test.</p> <pre><code>STRIPE_API_KEY=YOUR_STRIPE_API_KEY\n</code></pre> <p>Warning</p> <p>Make sure you have set up your Stripe account as a sandbox and are using an API key from there. If it is your first time setting up a Stripe account and you haven't added any billing information, this will be the default. Otherwise the invoices will be real.</p> <p>Make sure you aren't in the <code>scripts</code> directory any more. If you are, run the following command to get back to the root directory of the project:</p> <pre><code>cd ..\n</code></pre> <p>Then run the test using the following command the same way you would the mocked version:</p> <pre><code>uv run scripts/create_invoice_test.py\n</code></pre> <p>The result will contain an <code>invoiceURL</code>, as well as the status of the invoice and a reference.</p> <pre><code>{'invoiceStatus': 'open', 'invoiceURL': 'https://invoice.stripe.com/i/acct_1RMFbIQej3CO0i8K/test_YWNjdF8xUk1GYklRZWozQ08wThLLF9TVJpYWZ2WXREVXZrcDJqMGhIM0hSdkVEa2hVYmM0LDE0MTI2NjEwNg0200VaZpBdSc?s=ap', 'reference': 'FEUS4MXS-0001'}\n</code></pre> <p>By following that invoice link in a browser, Stripe will present you with a sample invoice in your sandbox environment. </p>  Before you move on, verify that you have created all the necessary files in the correct structure.   So far you've implemented and tested the agents tools. Verify your directory structure and files look and are named appropriately according to the following diagram before continuing:  <pre><code>temporal-ai-agent/\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .python-version\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 uv.lock\n\u251c\u2500\u2500 scripts/\n\u2502   \u251c\u2500\u2500 create_invoice_test.py\n\u2502   \u251c\u2500\u2500 find_events_test.py\n\u2502   \u2514\u2500\u2500 search_flights_test.py\n\u2514\u2500\u2500 tools/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 create_invoice.py\n    \u251c\u2500\u2500 find_events.py\n    \u251c\u2500\u2500 search_flights.py\n    \u2514\u2500\u2500 data/\n        \u2514\u2500\u2500 find_events_data.json\n</code></pre> <p>And those are the three tools in this agent's toolkit to achieve its goal. Other goals may have different tools, and you could add more tools. Next, you'll make the tools available to the agent to use.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#exposing-the-tools-to-the-agent","title":"Exposing the tools to the agent","text":"<p>Now that you have the tools necessary to complete the agent's goal, you need to implement a way to inform the agent that these tools are available. To do this, you'll create a tool registry.  The tool registry will contain a definition of each tool, along with information such as the tool's name, description, and what arguments it accepts. </p> <p>However, before you create the registry, you should define the tool definition and tool argument as models that can be shared across your codebase.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#defining-the-core-models","title":"Defining the core models","text":"<p>Defining the tool arguments, tool definition, and agent goal as custom types allows for better reusability and type hinting. Temporal also recommends passing a single object between functions, and requires these objects to be serializable. Given these requirements, you'll implement the <code>ToolArgument</code> and <code>ToolDefinition</code> types as a Python <code>dataclass</code>.</p> <p>Before you define these models, navigate to the root directory of your project and create the <code>models</code> directory:</p> <pre><code>mkdir models\n</code></pre> <p>Since this directory will be imported throughout your project, it needs to be configured as a module. To do this, create a blank <code>__init__.py</code> file by running the following command:</p> <pre><code>touch models/__init__.py\n</code></pre> <p>Next, create the file <code>core.py</code>. This file will contain the tool argument and definition models used to in your agent.  Open <code>models/core.py</code> and add the following imports:</p> <pre><code>from dataclasses import dataclass\nfrom typing import List\n</code></pre> <p>Next, add the <code>ToolArgument</code> <code>dataclass</code> to the file:</p> <pre><code>@dataclass\nclass ToolArgument:\n    name: str\n    type: str\n    description: str\n</code></pre> <p>An instance of this <code>dataclass</code> will represent an argument that your tool can accept, including the name of the argument, a description of what the argument represents, and the type of the argument, such as an <code>int</code> or <code>str</code>. </p> <p>Next, add the <code>ToolDefinition</code> <code>dataclass</code> to the file:</p> <pre><code>@dataclass\nclass ToolDefinition:\n    name: str\n    description: str\n    arguments: List[ToolArgument]\n</code></pre> <p>This will hold information about the tool that's provided to the agent so it can determine what action to take. It defines the name of the tool, a description of what the can do, and an argument list. This list is composed of your <code>ToolArgument</code> objects.</p> <p>Now that you have the appropriate model to define your tools, you can create a registry of the tools for the agent to access.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#creating-the-tool-registry","title":"Creating the tool registry","text":"<p>Agents use LLMs to determine what action to take and then execute a tool from their toolkit. However, you have to make those tools available to the agent. Now that you have structure for defining your tools, you should create a registry that your agent reads to load the available tools.</p> <p>Navigate back to the <code>tools</code> directory and create the file <code>tools/tool_registry.py</code>. In this file you will define all of your tools using the models you defined in the previous step.</p> <p>First, add the following import to the file to import the models:</p> <pre><code>from models.core import ToolArgument, ToolDefinition\n</code></pre> <p>Next, add the first part of the <code>ToolDefinition</code> for the <code>find_events</code> tool:</p> <pre><code>find_events_tool = ToolDefinition(\n    name=\"FindEvents\",\n    description=\"Find upcoming events to travel to a given city (e.g., 'New York City') and a date or month. \"\n    \"It knows about events in North America only (e.g. major North American cities). \"\n    \"It will search 1 month either side of the month provided. \"\n    \"Returns a list of events. \",\n    # arguments to be inserted here in the next step\n)\n</code></pre> <p>This defines your tool using the <code>ToolDefinition</code> model you defined, gives it a name and a description that the LLM can use to understand the tool and also use as a prompt. Next you need to add the arguments to this instantiation. The arguments in the <code>ToolDefinition</code> model were defined as a <code>List[ToolArgument]</code>, so you may have multiple arguments within your list.</p> <p>To complete the definition, add the following code to your <code>find_events_tool</code> instantiation to add the arguments:</p> <pre><code>    arguments=[\n        ToolArgument(\n            name=\"city\",\n            type=\"string\",\n            description=\"Which city to search for events\",\n        ),\n        ToolArgument(\n            name=\"month\",\n            type=\"string\",\n            description=\"The month to search for events (will search 1 month either side of the month provided)\",\n        ),\n    ]\n</code></pre> <p>The <code>find_events</code> tool requires two arguments, the city and month in which to search, and it also provides a string description so the LLM would know how to prompt the user if an argument is missing.</p> <p>Bringing it all together, the complete <code>ToolDefinition</code> would be:</p> <pre><code>find_events_tool = ToolDefinition(\n    name=\"FindEvents\",\n    description=\"Find upcoming events to travel to a given city (e.g., 'New York City') and a date or month. \"\n    \"It knows about events in North America only (e.g. major North American cities). \"\n    \"It will search 1 month either side of the month provided. \"\n    \"Returns a list of events. \",\n    arguments=[\n        ToolArgument(\n            name=\"city\",\n            type=\"string\",\n            description=\"Which city to search for events\",\n        ),\n        ToolArgument(\n            name=\"month\",\n            type=\"string\",\n            description=\"The month to search for events (will search 1 month either side of the month provided)\",\n        ),\n    ],\n)\n</code></pre> <p>Now that you have the first tool defined in your registry, implement the remaining tool definitions. </p> <p>Add the following code to register the <code>search_flights</code> tool.  The structure is similar to the <code>find_events</code> tool, except that <code>search_flights</code> requires more arguments, to search for the origin, destination, departure date, return date, and confirmation status. These arguments are a direct mapping of the required parameters to the RAPIDAPI REST API. When creating a tool that maps to an API, be sure to include that APIs required parameters as <code>ToolArgument</code>s.</p> <pre><code>search_flights_tool = ToolDefinition(\n    name=\"SearchFlights\",\n    description=\"Search for return flights from an origin to a destination within a date range (dateDepart, dateReturn). \"\n    \"You are allowed to suggest dates from the conversation history, but ALWAYS ask the user if ok.\",\n    arguments=[\n        ToolArgument(\n            name=\"origin\",\n            type=\"string\",\n            description=\"Airport or city (infer airport code from city and store)\",\n        ),\n        ToolArgument(\n            name=\"destination\",\n            type=\"string\",\n            description=\"Airport or city code for arrival (infer airport code from city and store)\",\n        ),\n        ToolArgument(\n            name=\"dateDepart\",\n            type=\"ISO8601\",\n            description=\"Start of date range in human readable format, when you want to depart\",\n        ),\n        ToolArgument(\n            name=\"dateReturn\",\n            type=\"ISO8601\",\n            description=\"End of date range in human readable format, when you want to return\",\n        ),\n        ToolArgument(\n            name=\"userConfirmation\",\n            type=\"string\",\n            description=\"Indication of the user's desire to search flights, and to confirm the details \"\n            + \"before moving on to the next step\",\n        ),\n    ],\n)\n</code></pre> <p>And then add the following code to register the <code>create_invoice</code> tool.  This tool requires three arguments: the amount to be paid, the details of the trip, and a user confirmation.</p> <pre><code>create_invoice_tool = ToolDefinition(\n    name=\"CreateInvoice\",\n    description=\"Generate an invoice for the items described for the total inferred by the conversation history so far. Returns URL to invoice.\",\n    arguments=[\n        ToolArgument(\n            name=\"amount\",\n            type=\"float\",\n            description=\"The total cost to be invoiced. Infer this from the conversation history.\",\n        ),\n        ToolArgument(\n            name=\"tripDetails\",\n            type=\"string\",\n            description=\"A description of the item details to be invoiced, inferred from the conversation history.\",\n        ),\n        ToolArgument(\n            name=\"userConfirmation\",\n            type=\"string\",\n            description=\"Indication of user's desire to create an invoice\",\n        ),\n    ],\n)\n</code></pre> <p>You now have a tool registry your agent imports to inform it of what tools it has available to execute. Finally, you need to create a mapping between the tool registered in <code>tool_registry.py</code> with the actual functions the Activity will invoke during Workflow execution.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#mapping-the-registry-to-the-functions","title":"Mapping the registry to the functions","text":"<p>Your agent will use the registry to identify which tool it should use, but it still needs to translate the string <code>name</code> of the tool to the function definition the code will execute. You will modify the code in <code>tool_registry</code> to add this functionality.</p> <p>First, add the following imports with the other imports in <code>tool_registry.py</code>:</p> <pre><code>from typing import Any, Callable, Dict\n\nfrom tools.create_invoice import create_invoice\nfrom tools.find_events import find_events\nfrom tools.search_flights import search_flights\n</code></pre> <p>These handle the appropriate typings, as well as import the function from each of the tool files.</p> <p>Next, go to the bottom of the file after the previous tool definitions and add the code to map the string representation of the <code>ToolDefinition</code> to the function:</p> <pre><code># Dictionary mapping tool names to their handler functions\nTOOL_HANDLERS: Dict[str, Callable[..., Any]] = {\n    \"SearchFlights\": search_flights,\n    \"CreateInvoice\": create_invoice,\n    \"FindEvents\": find_events,\n}\n</code></pre> <p>Finally, add a function named <code>get_handler</code> that returns the function given the tool name:</p> <pre><code>def get_handler(tool_name: str) -&gt; Callable[..., Any]:\n    \"\"\"Get the handler function for a given tool name.\n\n    Args:\n        tool_name: The name of the tool to get the handler for.\n\n    Returns:\n        The handler function for the specified tool.\n\n    Raises:\n        ValueError: If the tool name is not found in the registry.\n    \"\"\"\n    if tool_name not in TOOL_HANDLERS:\n        raise ValueError(f\"Unknown tool: {tool_name}\")\n\n    return TOOL_HANDLERS[tool_name]\n</code></pre> <p>You have now successfully implemented a structured model for expressing tools available to your AI agent.  This is necessary for building a robust, capable agent.</p>  The <code>tools/tool_registry.py</code> is complete and will need no more revisions. You can review the complete file and copy the code here.   [tools/tool_registry](https://github.com/temporal-community/tutorial-temporal-ai-agent/blob/main/tools/tool_registry.py)  <pre><code>from typing import Any, Callable, Dict\n\nfrom models.core import ToolArgument, ToolDefinition\nfrom tools.create_invoice import create_invoice\nfrom tools.find_events import find_events\nfrom tools.search_flights import search_flights\n\nfind_events_tool = ToolDefinition(\n    name=\"FindEvents\",\n    description=\"Find upcoming events to travel to a given city (e.g., 'New York City') and a date or month. \"\n    \"It knows about events in North America only (e.g. major North American cities). \"\n    \"It will search 1 month either side of the month provided. \"\n    \"Returns a list of events. \",\n    arguments=[\n        ToolArgument(\n            name=\"city\",\n            type=\"string\",\n            description=\"Which city to search for events\",\n        ),\n        ToolArgument(\n            name=\"month\",\n            type=\"string\",\n            description=\"The month to search for events (will search 1 month either side of the month provided)\",\n        ),\n    ],\n)\n\n\nsearch_flights_tool = ToolDefinition(\n    name=\"SearchFlights\",\n    description=\"Search for return flights from an origin to a destination within a date range (dateDepart, dateReturn). \"\n    \"You are allowed to suggest dates from the conversation history, but ALWAYS ask the user if ok.\",\n    arguments=[\n        ToolArgument(\n            name=\"origin\",\n            type=\"string\",\n            description=\"Airport or city (infer airport code from city and store)\",\n        ),\n        ToolArgument(\n            name=\"destination\",\n            type=\"string\",\n            description=\"Airport or city code for arrival (infer airport code from city and store)\",\n        ),\n        ToolArgument(\n            name=\"dateDepart\",\n            type=\"ISO8601\",\n            description=\"Start of date range in human readable format, when you want to depart\",\n        ),\n        ToolArgument(\n            name=\"dateReturn\",\n            type=\"ISO8601\",\n            description=\"End of date range in human readable format, when you want to return\",\n        ),\n        ToolArgument(\n            name=\"userConfirmation\",\n            type=\"string\",\n            description=\"Indication of the user's desire to search flights, and to confirm the details \"\n            + \"before moving on to the next step\",\n        ),\n    ],\n)\n\ncreate_invoice_tool = ToolDefinition(\n    name=\"CreateInvoice\",\n    description=\"Generate an invoice for the items described for the total inferred by the conversation history so far. Returns URL to invoice.\",\n    arguments=[\n        ToolArgument(\n            name=\"amount\",\n            type=\"float\",\n            description=\"The total cost to be invoiced. Infer this from the conversation history.\",\n        ),\n        ToolArgument(\n            name=\"tripDetails\",\n            type=\"string\",\n            description=\"A description of the item details to be invoiced, inferred from the conversation history.\",\n        ),\n        ToolArgument(\n            name=\"userConfirmation\",\n            type=\"string\",\n            description=\"Indication of user's desire to create an invoice\",\n        ),\n    ],\n)\n\n\n# Dictionary mapping tool names to their handler functions\nTOOL_HANDLERS: Dict[str, Callable[..., Any]] = {\n    \"SearchFlights\": search_flights,\n    \"CreateInvoice\": create_invoice,\n    \"FindEvents\": find_events,\n}\n\n\ndef get_handler(tool_name: str) -&gt; Callable[..., Any]:\n    \"\"\"Get the handler function for a given tool name.\n\n    Args:\n        tool_name: The name of the tool to get the handler for.\n\n    Returns:\n        The handler function for the specified tool.\n\n    Raises:\n        ValueError: If the tool name is not found in the registry.\n    \"\"\"\n    if tool_name not in TOOL_HANDLERS:\n        raise ValueError(f\"Unknown tool: {tool_name}\")\n\n    return TOOL_HANDLERS[tool_name]\n</code></pre>  Before moving on to the next section, verify that your file and directory structure is correct.   You just implemented a model for defining your tools in a way that your agent could discover and use them. Verify that your directory structure and file names are correct according to the following diagram before continuing:  <pre><code>temporal-ai-agent/\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .python-version\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 uv.lock\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 core.py\n\u251c\u2500\u2500 scripts/\n\u2502   \u251c\u2500\u2500 create_invoice_test.py\n\u2502   \u251c\u2500\u2500 find_events_test.py\n\u2502   \u2514\u2500\u2500 search_flights_test.py\n\u2514\u2500\u2500 tools/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 create_invoice.py\n    \u251c\u2500\u2500 find_events.py\n    \u251c\u2500\u2500 search_flights.py\n    \u251c\u2500\u2500 tool_registry.py\n    \u2514\u2500\u2500 data/\n        \u2514\u2500\u2500 find_events_data.json\n</code></pre> <p>In the next step, you will use the tool definitions you just created to define the agent's goal. </p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#designating-the-agents-goal","title":"Designating the agent's goal","text":"<p>An agent's goal is the definition of the task it's trying to achieve. It achieves this goal by executing tools, analyzing the results, and using an LLM to decide what to do next. In this tutorial you will define the goal as a combination of several fields, including a description, a starter prompt, an example conversation history, and the list of tools the agent can use to achieve its goal. Now that you've defined the <code>ToolDefinition</code> that will be available for your agent, you can define the <code>AgentGoal</code> type and create your agent's goal.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#defining-the-agentgoal-type","title":"Defining the <code>AgentGoal</code> type","text":"<p>To define the <code>AgentGoal</code> type, open <code>models/core.py</code> and add the following code:</p> <pre><code>@dataclass\nclass AgentGoal:\n    agent_name: str\n    tools: List[ToolDefinition]\n    description: str\n    starter_prompt: str\n    example_conversation_history: str\n</code></pre> <p>This <code>dataclass</code> defines your <code>AgentGoal</code> as a combination of a few attributes: * <code>agent_name</code> - A human readable name for the agent * <code>tools</code> - A list of tools, defined as <code>ToolDefinition</code> types, that the agent can use to achieve its goal * <code>description</code> - A description of the goal, in a bulleted list format specifying how to achieve it. * <code>starter_prompt</code> - A starter prompt for the AI agent to run * <code>example_conversation_history</code> - A sample conversation history of what a successful interaction with this agent would look like</p>  The <code>models/core.py</code> is complete and will need no more revisions. You can review the complete file and copy the code here.   Hover your cursor over the code block to reveal the copy-code option.    [models/core.py](https://github.com/temporal-community/tutorial-temporal-ai-agent/blob/main/models/core.py)  <pre><code>from dataclasses import dataclass\nfrom typing import List\n\n\n@dataclass\nclass ToolArgument:\n    name: str\n    type: str\n    description: str\n\n\n@dataclass\nclass ToolDefinition:\n    name: str\n    description: str\n    arguments: List[ToolArgument]\n\n\n@dataclass\nclass AgentGoal:\n    id: str\n    category_tag: str\n    agent_name: str\n    agent_friendly_description: str\n    tools: List[ToolDefinition]\n    description: str = \"Description of the tools purpose and overall goal\"\n    starter_prompt: str = \"Initial prompt to start the conversation\"\n    example_conversation_history: str = (\n        \"Example conversation history to help the AI agent understand the context of the conversation\"\n    )\n</code></pre> <p>Now that you have the type available to define the goal, you will implement the goal for your agent.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#implementing-the-goal-registry","title":"Implementing the goal registry","text":"<p>Similar to implementing the <code>tool_registry</code>, next you will implement a <code>goal_registry</code> to define your agent's goal and make it available to the Workflow.  You will do this by creating an instance of your <code>AgentGoal</code> type for every goal you wish to implement. For this tutorial you will only implement a single goal, named <code>goal_event_flight_invoice</code>, but you may want to use this framework going forward to create your own agent goals at a later date.</p> <p>To implement your agent's goal, create the file <code>tools/goal_registry.py</code> and add the following imports to the file:</p> <pre><code>import tools.tool_registry as tool_registry\nfrom models.core import AgentGoal\n</code></pre> <p>To create the goal, first create an instance of the <code>AgentGoal</code> <code>dataclass</code> and add the first parameter, <code>agent_name</code>, to identify the goal:</p> <pre><code>goal_event_flight_invoice = AgentGoal(\n    agent_name=\"North America Event Flight Booking\",\n    # ...\n</code></pre> <p>Next, pass in the <code>ToolDefnition</code>s that the agent is allowed to use to accomplish its goal to the <code>tools</code> parameter. Add the following code as the next parameter:</p> <pre><code>    # ...\n    tools=[\n        tool_registry.find_events_tool,\n        tool_registry.search_flights_tool,\n        tool_registry.create_invoice_tool,\n    ],\n    # ...\n</code></pre> <p>The following parameter defines a detailed description of what the goal is and the ideal path for the agent to take to achieve its goal. Add the following code to the file:</p> <pre><code>    # ...\n    description=\"Help the user gather args for these tools in order: \"\n    \"1. FindEvents: Find an event to travel to \"\n    \"2. SearchFlights: search for a flight around the event dates \"\n    \"3. CreateInvoice: Create a simple invoice for the cost of that flight \",\n    # ...\n</code></pre> <p>The next parameter provides a starter prompt for the agent, detailing how it should begin its interaction with every user. A starter prompt is the first prompt an agent sees, and gives the initial set of instructions. Think of this an initialization function for the conversation. A common format is to provide a greeting, explain your purpose, and prompt the user for information the agent needs to succeed.</p> <p>Add the following code to define your prompt:</p> <pre><code>    # ...\n    starter_prompt=\"Welcome me, give me a description of what you can do, then ask me for the details you need to do your job.\",\n    # ...\n</code></pre> <p>Finally, draft an example conversation of a successful interaction with your agent to pass in. LLMs perform better when they have an example of expected output, so providing this aids the LLM in its goal. Since this is a <code>str</code> type, but the conversation is long, you will define each statement as a line in a list and then use <code>\"\\n \".join()</code> to create a string from your conversation. Add the conversation as the final parameter.</p> <pre><code>    # ...\n    example_conversation_history=\"\\n \".join(\n        [\n            \"user: I'd like to travel to an event\",\n            \"agent: Sure! Let's start by finding an event you'd like to attend. I know about events in North American cities. Could you tell me which city and month you're interested in?\",\n            \"user: nyc in may please\",\n            \"agent: Great! Let's find an events in New York City in May.\",\n            \"user_confirmed_tool_run: &lt;user clicks confirm on FindEvents tool&gt;\",\n            \"tool_result: { 'event_name': 'Frieze New York City', 'event_date': '2023-05-01' }\",\n            \"agent: Found an event! There's Frieze New York City on May 1 2025, ending on May 14 2025. Would you like to search for flights around these dates?\",\n            \"user: Yes, please\",\n            \"agent: Let's search for flights around these dates. Could you provide your departure city?\",\n            \"user: San Francisco\",\n            \"agent: Thanks, searching for flights from San Francisco to New York City around 2023-02-25 to 2023-02-28.\",\n            \"user_confirmed_tool_run: &lt;user clicks confirm on SearchFlights tool&gt;\"\n            'tool_result: results including {\"flight_number\": \"AA101\", \"return_flight_number\": \"AA102\", \"price\": 850.0}',\n            \"agent: Found some flights! The cheapest is AA101 for $850. Would you like to generate an invoice for this flight?\",\n            \"user_confirmed_tool_run: &lt;user clicks confirm on CreateInvoice tool&gt;\",\n            'tool_result: { \"status\": \"success\", \"invoice\": { \"flight_number\": \"AA101\", \"amount\": 850.0 }, invoiceURL: \"https://example.com/invoice\" }',\n            \"agent: Invoice generated! Here's the link: https://example.com/invoice\",\n        ]\n    ),\n)\n</code></pre>  The <code>tools/goal_registry.py</code> is complete and will need no more revisions. You can review the complete file and copy the code here.   Hover your cursor over the code block to reveal the copy-code option.    [tools/goal_registry.py](https://github.com/temporal-community/tutorial-temporal-ai-agent/blob/main/tools/goal_registry.py)  <pre><code>import tools.tool_registry as tool_registry\nfrom models.core import AgentGoal\n\ngoal_event_flight_invoice = AgentGoal(\n    agent_name=\"North America Event Flight Booking\",\n    tools=[\n        tool_registry.find_events_tool,\n        tool_registry.search_flights_tool,\n        tool_registry.create_invoice_tool,\n    ],\n    description=\"Help the user gather args for these tools in order: \"\n    \"1. FindEvents: Find an event to travel to \"\n    \"2. SearchFlights: search for a flight around the event dates \"\n    \"3. CreateInvoice: Create a simple invoice for the cost of that flight \",\n    starter_prompt=\"Welcome me, give me a description of what you can do, then ask me for the details you need to do your job.\",\n    example_conversation_history=\"\\n \".join(\n        [\n            \"user: I'd like to travel to an event\",\n            \"agent: Sure! Let's start by finding an event you'd like to attend. I know about events in North American cities. Could you tell me which city and month you're interested in?\",\n            \"user: sydney in may please\",\n            \"agent: Great! Let's find an events in New York City in May.\",\n            \"user_confirmed_tool_run: &lt;user clicks confirm on FindEvents tool&gt;\",\n            \"tool_result: { 'event_name': 'Vivid New York City', 'event_date': '2023-05-01' }\",\n            \"agent: Found an event! There's Vivid New York City on May 1 2025, ending on May 14 2025. Would you like to search for flights around these dates?\",\n            \"user: Yes, please\",\n            \"agent: Let's search for flights around these dates. Could you provide your departure city?\",\n            \"user: San Francisco\",\n            \"agent: Thanks, searching for flights from San Francisco to New York City around 2023-02-25 to 2023-02-28.\",\n            \"user_confirmed_tool_run: &lt;user clicks confirm on SearchFlights tool&gt;\"\n            'tool_result: results including {\"flight_number\": \"AA101\", \"return_flight_number\": \"AA102\", \"price\": 850.0}',\n            \"agent: Found some flights! The cheapest is AA101 for $850. Would you like to generate an invoice for this flight?\",\n            \"user_confirmed_tool_run: &lt;user clicks confirm on CreateInvoice tool&gt;\",\n            'tool_result: { \"status\": \"success\", \"invoice\": { \"flight_number\": \"AA101\", \"amount\": 850.0 }, invoiceURL: \"https://example.com/invoice\" }',\n            \"agent: Invoice generated! Here's the link: https://example.com/invoice\",\n        ]\n    ),\n)\n</code></pre> <p>Now that you have defined your agent's goal, you can begin implementing the Activities.</p>  Before moving on to the next section, verify your files and directory structure is correct.  <pre><code>temporal-ai-agent/\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .python-version\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 uv.lock\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 core.py\n\u251c\u2500\u2500 scripts/\n\u2502   \u251c\u2500\u2500 create_invoice_test.py\n\u2502   \u251c\u2500\u2500 find_events_test.py\n\u2502   \u2514\u2500\u2500 search_flights_test.py\n\u2514\u2500\u2500 tools/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 create_invoice.py\n    \u251c\u2500\u2500 find_events.py\n    \u251c\u2500\u2500 goal_registry.py\n    \u251c\u2500\u2500 search_flights.py\n    \u251c\u2500\u2500 tool_registry.py\n    \u2514\u2500\u2500 data/\n        \u2514\u2500\u2500 find_events_data.json\n</code></pre>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#building-temporal-activities-to-execute-non-deterministic-agent-code","title":"Building Temporal Activities to execute non-deterministic agent code","text":"<p>Now that you have built the agent's goal, and the tools it needs to achieve it, you can start building the agent code.  In this step, you will create Activities that execute code in your AI agent that can behave non-deterministically, such as making the LLM calls or calling tools. Because tools can call out to external services, have the possibility to fail, be rate limited, or perform other non-deterministic operations, it's safer to always call them in an Activity. When an Activity fails, it's automatically retried by default until it succeeds or is canceled.</p> <p>Another added benefit of executing your tool as an Activity is that after the Activity completes, the result is saved to an Event History managed by Temporal. If your application were to then crash after executing a few tools, it could reconstruct the state of the execution and use the previous execution's results, without having to re-execute the tools. This provides durability to your agent for intermittent issues, which are common in distributed systems.</p> <p>Before you can proceed to creating the Activities, however, you need to create the custom types that you'll use for Activity communication. Recall that Workflow and Activity best practices recommend only passing a single <code>dataclass</code> parameter. This helps with the evolution of parameters as well as ensuring type safety.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#creating-the-requests-data-models","title":"Creating the <code>requests</code> data models","text":"<p>Your agent will require specific types for input and output for both the Activities and the Workflow. You will put all request-based models in a new file in the models directory named <code>requests.py</code>.</p> <p>First, open <code>models/requests.py</code> and add the following import statements:</p> <pre><code>from dataclasses import dataclass, field\nfrom typing import Any, Deque, Dict, List, Literal, Optional, TypedDict, Union\n\nfrom models.core import AgentGoal\n</code></pre> <p>You will use these when creating the new types for your agent.</p> <p>Next, add the following single attribute data types to the file:</p> <pre><code>Message = Dict[str, Union[str, Dict[str, Any]]]\nConversationHistory = Dict[str, List[Message]]\nNextStep = Literal[\"confirm\", \"question\", \"done\"]\nCurrentTool = str\n</code></pre> <p>These types are used to compose other, multi-attribute <code>dataclass</code> types, or sent as a single parameter. They are used in the following context of the agent:</p> <ul> <li><code>Message</code> - A nested dictionary that represents one turn of a conversation between the LLM and the user</li> <li><code>ConversationHistory</code> - A dictionary containing an <code>str</code> key and a <code>List</code> of <code>Messages</code> that keeps track of the conversation between the LLM and the user</li> <li><code>NextStep</code> - A <code>Literal</code> containing three options, picked by the agent to decide the next action to take and interpreted by the Workflow</li> <li><code>CurrentTool</code> - An <code>str</code> representation of the current tool the agent is using</li> </ul> <p>Next, add the following <code>dataclass</code>es for handling the primary agent parameters:</p> <pre><code>@dataclass\nclass AgentGoalWorkflowParams:\n    conversation_summary: Optional[str] = None\n    prompt_queue: Optional[Deque[str]] = None\n\n\n@dataclass\nclass CombinedInput:\n    agent_goal: AgentGoal\n    tool_params: AgentGoalWorkflowParams\n</code></pre> <p>The <code>AgentWorkflowParams</code> type contains a summary of the conversation and a queue of prompts that the agent needs to process via the LLM.  The <code>CombinedInput</code> type contains the agent's goal and the parameters. This type is the input that is passed to the main agent Workflow and is used to start the initial Workflow Execution.</p> <p>Next, add the <code>dataclass</code> that handles the input for calling the LLM for tool planning:</p> <pre><code>@dataclass\nclass ToolPromptInput:\n    prompt: str\n    context_instructions: str\n</code></pre> <p><code>ToolPromptInput</code> contains the prompt the Activity will issue to the LLM, along with any context that the LLM needs when executing the prompt.</p> <p>To go along with the this type, you need to add types that store the results of validation of the prompt:</p> <pre><code>@dataclass\nclass ValidationInput:\n    prompt: str\n    conversation_history: ConversationHistory\n    agent_goal: AgentGoal\n\n\n@dataclass\nclass ValidationResult:\n    validationResult: bool\n    validationFailedReason: Dict[str, Any] = field(default_factory=dict)\n</code></pre> <p>The <code>ValidationInput</code> type contains the prompt given by the user, the conversation history, and the agent's goal. An Activity will use this type as input and validate the prompt against the agent's goal. Conversely, the <code>ValidationResult</code> type will contain the results of this validation Activity and will return a boolean signifying if the prompt passed or failed, and if it did fail a reason why.</p> <p>Next, add two more <code>dataclass</code>es for handling the input and output of reading environment variables into the Workflow:</p> <pre><code>@dataclass\nclass EnvLookupInput:\n    show_confirm_env_var_name: str\n    show_confirm_default: bool\n\n\n@dataclass\nclass EnvLookupOutput:\n    show_confirm: bool\n</code></pre> <p>Since reading from the filesystem is a non-deterministic operation, this action must be done from an Activity, so it is best practice to define types to handle this in case you ever need to add more environment variables. Your environment variables will contain things such as your API keys, agent configurations, timeouts, and other settings.</p> <p>Finally, add the class that will contain the next step the agent should take and the data the tool needs to execute:</p> <pre><code>class ToolData(TypedDict, total=False):\n    next: NextStep\n    tool: str\n    response: str\n    args: Dict[str, Any]\n    force_confirm: bool\n</code></pre> <p><code>ToolData</code> contains the <code>NextStep</code> that the agent should take, along with the tool that should be used, the arguments for the tool, the response from the LLM, and a <code>force_confirm</code> boolean. You may notice this type is different from the previous types, as it is a subclass of <code>TypedDict</code> and not a <code>dataclass</code>. This is done to handle converting the type to JSON for use in the API later, because <code>dataclass</code>es don't support conversion of nested custom types to JSON.</p>  The <code>models/requests.py</code> is complete and will need no more revisions. You can review the complete file and copy the code here.   Hover your cursor over the code block to reveal the copy-code option.    [models/requests.py](https://github.com/temporal-community/tutorial-temporal-ai-agent/blob/main/models/requests.py)  <pre><code>from dataclasses import dataclass, field\nfrom typing import Any, Deque, Dict, List, Literal, Optional, TypedDict, Union\n\nfrom models.core import AgentGoal\n\n# Common type aliases\n\nMessage = Dict[str, Union[str, Dict[str, Any]]]\nConversationHistory = Dict[str, List[Message]]\nNextStep = Literal[\"confirm\", \"question\", \"pick-new-goal\", \"done\"]\nCurrentTool = str\n\n\nclass ToolData(TypedDict, total=False):\n    next: NextStep\n    tool: str\n    response: str\n    args: Dict[str, Any]\n    force_confirm: bool\n\n\n@dataclass\nclass AgentGoalWorkflowParams:\n    conversation_summary: Optional[str] = None\n    prompt_queue: Optional[Deque[str]] = None\n\n\n@dataclass\nclass CombinedInput:\n    tool_params: AgentGoalWorkflowParams\n    agent_goal: AgentGoal\n\n\n@dataclass\nclass ToolPromptInput:\n    prompt: str\n    context_instructions: str\n\n\n@dataclass\nclass ValidationInput:\n    prompt: str\n    conversation_history: ConversationHistory\n    agent_goal: AgentGoal\n\n\n@dataclass\nclass ValidationResult:\n    validationResult: bool\n    validationFailedReason: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass EnvLookupInput:\n    show_confirm_env_var_name: str\n    show_confirm_default: bool\n\n\n@dataclass\nclass EnvLookupOutput:\n    show_confirm: bool\n</code></pre> <p>Now that you have your custom types defined for Activity communication, you can implement the Activities.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#creating-the-activities-submodule","title":"Creating the Activities submodule","text":"<p>First, create the directory structure for your Activities and make it a module:</p> <pre><code>mkdir activities\ntouch activities/__init__.py\n</code></pre> <p>Next, create the file <code>activities/activities.py</code> and add the necessary <code>import</code> statements and a statement to load the environment variables:</p> <pre><code>import inspect\nimport json\nimport os\nfrom datetime import datetime\nfrom typing import Sequence\n\nfrom dotenv import load_dotenv\nfrom litellm import completion\nfrom temporalio import activity\nfrom temporalio.common import RawValue\n\nfrom models.requests import (\n    EnvLookupInput,\n    EnvLookupOutput,\n    ToolPromptInput,\n    ValidationInput,\n    ValidationResult,\n)\n\nload_dotenv(override=True)\n</code></pre> <p>This imports various system packages, Temporal libraries, the <code>litellm</code> package for making LLM calls, the <code>dotenv</code> package for loading environment variables, and a number of custom types you defined in <code>models/requests.py</code>.  Next, you'll create the <code>AgentActivities</code> class, which contains activities the agent will call to achieve its goal. </p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#constructing-the-agentactivities-class","title":"Constructing the <code>AgentActivities</code> Class","text":"<p>The <code>AgentActivities</code> class enables the Workflow to plan which tools to use, validate prompts, read in environment variables, and more.</p> <p>To implement it, open <code>activities/activities.py</code> and create the class and define the <code>__init__</code> method:</p> <pre><code>class AgentActivities:\n    def __init__(self):\n        \"\"\"Initialize LLM client using LiteLLM.\"\"\"\n        self.llm_model = os.environ.get(\"LLM_MODEL\", \"openai/gpt-4\")\n        self.llm_key = os.environ.get(\"LLM_KEY\")\n        self.llm_base_url = os.environ.get(\"LLM_BASE_URL\")\n        activity.logger.info(\n            f\"Initializing AgentActivities with LLM model: {self.llm_model}\"\n        )\n        if self.llm_base_url:\n            activity.logger.info(f\"Using custom base URL: {self.llm_base_url}\")\n</code></pre> <p>Temporal Activities can be implemented as either a function or a class and method. As the agent requires a persistent object for communication, in this case, communicating to the LLM, it's good practice to use a class and set the parameters as part of the initialization of the Activity, so to not waste resources re-initializing the object for every LLM call. The <code>__init__</code> method reads the LLM configuration from environment variables and assigns the values to instance variables.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#implementing-various-helper-methods","title":"Implementing various helper methods","text":"<p>Before you implement the Activities, implement the following helper functions:</p> <p>The first method sanitizes the JSON response you get from the LLM and sanitizing it to a proper JSON string. The LLM may return a string with extra whitespace, or formatted as markdown, so sanitizing the string is necessary before parsing it.</p> <p>Add the following helper method to the bottom of your <code>activities.py</code> file:</p> <pre><code>    def sanitize_json_response(self, response_content: str) -&gt; str:\n        \"\"\"\n        Sanitizes the response content to ensure it's valid JSON.\n        \"\"\"\n        # Remove any markdown code block markers\n        response_content = response_content.replace(\"```json\", \"\").replace(\"```\", \"\")\n\n        # Remove any leading/trailing whitespace\n        response_content = response_content.strip()\n\n        return response_content\n</code></pre> <p>The second helper function takes a string as input and returns a dictionary after attempting to parse the string as valid JSON. Add this method to the bottom of your <code>activities.py</code> file:</p> <pre><code>    def parse_json_response(self, response_content: str) -&gt; dict:\n        \"\"\"\n        Parses the JSON response content and returns it as a dictionary.\n        \"\"\"\n        try:\n            data = json.loads(response_content)\n            return data\n        except json.JSONDecodeError as e:\n            activity.logger.error(f\"Invalid JSON: {e}\")\n            raise\n</code></pre> <p>Now that you have the helper methods implemented, you can implement the Activity responsible for making LLM calls.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#implementing-the-activity-for-making-llm-calls","title":"Implementing the Activity for making LLM calls","text":"<p>The <code>agent_toolPlanner</code> Activity handles all interactions with your chosen LLM. It makes the call to the LLM, parses the response and returns JSON on success, and raises an Exception on failure.</p> <p>Add the method header with the appropriate decorator to your <code>activities.py</code> file, underneath the <code>__init__</code> method:</p> <pre><code>    @activity.defn\n    async def agent_toolPlanner(self, input: ToolPromptInput) -&gt; dict:\n</code></pre> <p>Next, create the <code>messages</code> list, which contains various dictionaries with the data necessary to perform an LLM prompt. This format is specifically OpenAI's format, which you can use for any LLM, because you are using <code>LiteLLM</code> to as your LLM abstraction library.</p> <p>Add the following code to craft the <code>messages</code> list:</p> <pre><code>        messages = [\n            {\n                \"role\": \"system\",\n                \"content\": input.context_instructions\n                + \". The current date is \"\n                + datetime.now().strftime(\"%B %d, %Y\"),\n            },\n            {\n                \"role\": \"user\",\n                \"content\": input.prompt,\n            },\n        ]\n</code></pre> <p>The <code>agent_toolPlanner</code> Activity constructs standard OpenAI-format messages with system context and user input.  It automatically includes the current date, which helps the language model provide accurate responses for time-sensitive queries.</p> <p>Continue the method with the LLM call implementation:</p> <pre><code>        try:\n            completion_kwargs = {\n                \"model\": self.llm_model,\n                \"messages\": messages,\n                \"api_key\": self.llm_key,\n            }\n\n            # Add base_url if configured\n            if self.llm_base_url:\n                completion_kwargs[\"base_url\"] = self.llm_base_url\n\n            response = completion(**completion_kwargs)\n\n            response_content = response.choices[0].message.content\n            activity.logger.info(f\"LLM response: {response_content}\")\n\n            # Use the new sanitize function\n            response_content = self.sanitize_json_response(response_content)\n\n            return self.parse_json_response(response_content)\n        except Exception as e:\n            activity.logger.error(f\"Error in LLM completion: {str(e)}\")\n            raise\n</code></pre> <p>This call is wrapped in a <code>try/except</code> statement to handle a potential failure. It creates a dictionary containing the arguments for calling the LLM, including the model choice, the messages, the API key, and a custom base URL if set. Next it performs the call to the LLM using the <code>completion</code> function, passing in the arguments dictionary. It then extracts the message you want from the response content, sanitizes the JSON and returns it as properly parsed JSON upon success. Upon failure, it will raise an exception.</p> <p>The complete implementation of <code>agent_toolPlanner</code> is as follows:</p> <pre><code>    @activity.defn\n    async def agent_toolPlanner(self, input: ToolPromptInput) -&gt; dict:\n        messages = [\n            {\n                \"role\": \"system\",\n                \"content\": input.context_instructions\n                + \". The current date is \"\n                + datetime.now().strftime(\"%B %d, %Y\"),\n            },\n            {\n                \"role\": \"user\",\n                \"content\": input.prompt,\n            },\n        ]\n\n        try:\n            completion_kwargs = {\n                \"model\": self.llm_model,\n                \"messages\": messages,\n                \"api_key\": self.llm_key,\n            }\n\n            # Add base_url if configured\n            if self.llm_base_url:\n                completion_kwargs[\"base_url\"] = self.llm_base_url\n\n            response = completion(**completion_kwargs)\n\n            response_content = response.choices[0].message.content\n            activity.logger.info(f\"LLM response: {response_content}\")\n\n            # Use the new sanitize function\n            response_content = self.sanitize_json_response(response_content)\n\n            return self.parse_json_response(response_content)\n        except Exception as e:\n            activity.logger.error(f\"Error in LLM completion: {str(e)}\")\n            raise\n</code></pre> <p>Now that you have implemented the Activity to call the LLM, you will implement the Activity to validate the user's prompts.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#implementing-the-activity-for-prompt-validation","title":"Implementing the Activity for prompt validation","text":"<p>It is important to not let the user take your agent off on a tangent, sending prompts that are not related to the goal. To do this, you must validate the prompt against your agent's goal and context prior to executing the LLM with the user's input.</p> <p>Next, create the <code>agent_validatePrompt</code> Activity to validate any prompt sent to the LLM in the context of the conversation history and agent goal.</p> <p>Within the <code>AgentActivities</code> class, add the following method header:</p> <pre><code>    @activity.defn\n    async def agent_validatePrompt(\n        self, validation_input: ValidationInput\n    ) -&gt; ValidationResult:\n        \"\"\"\n        Validates the prompt in the context of the conversation history and agent goal.\n        Returns a ValidationResult indicating if the prompt makes sense given the context.\n        \"\"\"\n</code></pre> <p>This Activity takes in a single argument, using the custom <code>ValidationInput</code> type you specified, and returns a single value, <code>ValidationResult</code>, in accordance with Temporal best practices.</p> <p>Next, add the code following code to iterate over the tools specified in the agent's goal and add them to a list.</p> <pre><code>        # Create simple context string describing tools and goals\n        tools_description = []\n        for tool in validation_input.agent_goal.tools:\n            tool_str = f\"Tool: {tool.name}\\n\"\n            tool_str += f\"Description: {tool.description}\\n\"\n            tool_str += \"Arguments: \" + \", \".join(\n                [f\"{arg.name} ({arg.type})\" for arg in tool.arguments]\n            )\n            tools_description.append(tool_str)\n        tools_str = \"\\n\".join(tools_description)\n</code></pre> <p>By doing this, you are creating a string the LLM can use as context to validate against. This context helps the LLM understand what capabilities are available to the agent, and whether or not the prompt the user sent makes sense.</p> <p>Continue the validation method by adding conversation context:</p> <pre><code>        # Convert conversation history to string\n        history_str = json.dumps(validation_input.conversation_history, indent=2)\n\n        # Create context instructions\n        context_instructions = f\"\"\"The agent goal and tools are as follows:\n            Description: {validation_input.agent_goal.description}\n            Available Tools:\n            {tools_str}\n            The conversation history to date is:\n            {history_str}\"\"\"\n</code></pre> <p>This section gathers the past conversation history and concatenates it with the available tool context, creating a complete context for the LLM.</p> <p>Next, add the following prompt for the LLM to use to validate the prompt:</p> <pre><code>        # Create validation prompt\n        validation_prompt = f\"\"\"The user's prompt is: \"{validation_input.prompt}\"\n            Please validate if this prompt makes sense given the agent goal and conversation history.\n            If the prompt makes sense toward the goal then validationResult should be true.\n            If the prompt is wildly nonsensical or makes no sense toward the goal and current conversation history then validationResult should be false.\n            If the response is low content such as \"yes\" or \"that's right\" then the user is probably responding to a previous prompt.  \n             Therefore examine it in the context of the conversation history to determine if it makes sense and return true if it makes sense.\n            Return ONLY a JSON object with the following structure:\n                \"validationResult\": true/false,\n                \"validationFailedReason\": \"If validationResult is false, provide a clear explanation to the user in the response field \n                about why their request doesn't make sense in the context and what information they should provide instead.\n                validationFailedReason should contain JSON in the format\n                {{\n                    \"next\": \"question\",\n                    \"response\": \"[your reason here and a response to get the user back on track with the agent goal]\"\n                }}\n                If validationResult is true (the prompt makes sense), return an empty dict as its value {{}}\"\n            \"\"\"\n</code></pre> <p>Finally, instantiate a <code>ToolPromptInput</code> object and pass that to <code>agent_toolPlanner</code> to execute:</p> <pre><code>        # Call the LLM with the validation prompt\n        prompt_input = ToolPromptInput(\n            prompt=validation_prompt, context_instructions=context_instructions\n        )\n\n        result = await self.agent_toolPlanner(prompt_input)\n\n        return ValidationResult(\n            validationResult=result.get(\"validationResult\", False),\n            validationFailedReason=result.get(\"validationFailedReason\", {}),\n        )\n</code></pre> <p>The complete implementation of <code>agent_validatePrompt</code> is as follows:</p> <pre><code>@activity.defn\n    async def agent_validatePrompt(\n        self, validation_input: ValidationInput\n    ) -&gt; ValidationResult:\n        \"\"\"\n        Validates the prompt in the context of the conversation history and agent goal.\n        Returns a ValidationResult indicating if the prompt makes sense given the context.\n        \"\"\"\n        # Create simple context string describing tools and goals\n        tools_description = []\n        for tool in validation_input.agent_goal.tools:\n            tool_str = f\"Tool: {tool.name}\\n\"\n            tool_str += f\"Description: {tool.description}\\n\"\n            tool_str += \"Arguments: \" + \", \".join(\n                [f\"{arg.name} ({arg.type})\" for arg in tool.arguments]\n            )\n            tools_description.append(tool_str)\n        tools_str = \"\\n\".join(tools_description)\n\n        # Convert conversation history to string\n        history_str = json.dumps(validation_input.conversation_history, indent=2)\n\n        # Create context instructions\n        context_instructions = f\"\"\"The agent goal and tools are as follows:\n            Description: {validation_input.agent_goal.description}\n            Available Tools:\n            {tools_str}\n            The conversation history to date is:\n            {history_str}\"\"\"\n\n        # Create validation prompt\n        validation_prompt = f\"\"\"The user's prompt is: \"{validation_input.prompt}\"\n            Please validate if this prompt makes sense given the agent goal and conversation history.\n            If the prompt makes sense toward the goal then validationResult should be true.\n            If the prompt is wildly nonsensical or makes no sense toward the goal and current conversation history then validationResult should be false.\n            If the response is low content such as \"yes\" or \"that's right\" then the user is probably responding to a previous prompt.  \n             Therefore examine it in the context of the conversation history to determine if it makes sense and return true if it makes sense.\n            Return ONLY a JSON object with the following structure:\n                \"validationResult\": true/false,\n                \"validationFailedReason\": \"If validationResult is false, provide a clear explanation to the user in the response field \n                about why their request doesn't make sense in the context and what information they should provide instead.\n                validationFailedReason should contain JSON in the format\n                {{\n                    \"next\": \"question\",\n                    \"response\": \"[your reason here and a response to get the user back on track with the agent goal]\"\n                }}\n                If validationResult is true (the prompt makes sense), return an empty dict as its value {{}}\"\n            \"\"\"\n\n        # Call the LLM with the validation prompt\n        prompt_input = ToolPromptInput(\n            prompt=validation_prompt, context_instructions=context_instructions\n        )\n\n        result = await self.agent_toolPlanner(prompt_input)\n\n        return ValidationResult(\n            validationResult=result.get(\"validationResult\", False),\n            validationFailedReason=result.get(\"validationFailedReason\", {}),\n        )\n</code></pre> <p>Calling an Activity within another Activity won't invoke that Activity, but will call the method like a typical Python method. The Activity then returns a <code>ValidationResult</code> for the agent to interpret and continue with its execution.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#implementing-the-activity-for-retrieving-environment-variables","title":"Implementing the Activity for retrieving environment variables","text":"<p>The final Activity within the <code>AgentActivities</code> class is the <code>get_wf_env_vars</code> Activity. This Activity reads certain environment variables that need to be known within the Workflow. Since reading from the file system is a potentially non-deterministic operation, this must happen within an Activity.</p> <p>Add the following code within the <code>AgentActivities</code> class to implement the Activity:</p> <pre><code>    @activity.defn\n    async def get_wf_env_vars(self, input: EnvLookupInput) -&gt; EnvLookupOutput:\n        \"\"\"gets env vars for workflow as an activity result so it's deterministic\n        handles default/None\n        \"\"\"\n        output: EnvLookupOutput = EnvLookupOutput(\n            show_confirm=input.show_confirm_default\n        )\n        show_confirm_value = os.getenv(input.show_confirm_env_var_name)\n        if show_confirm_value is None:\n            output.show_confirm = input.show_confirm_default\n        elif show_confirm_value is not None and show_confirm_value.lower() == \"false\":\n            output.show_confirm = False\n        else:\n            output.show_confirm = True\n\n        return output\n</code></pre> <p>This Activity reads the environment variables and ensures that <code>show_confirm_value</code> is set, returning your custom <code>EnvLookupOutput</code> type. While this type may only contain one value at the moment, having it designed with this custom type allows you to expand this method later if necessary.</p> <p>You have implemented all Activities within the <code>AgentActivities</code> class, but there is still one Activity left to implement, the Activity for executing the tools.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#implementing-dynamic-tool-execution","title":"Implementing dynamic tool execution","text":"<p>The final Activity enables runtime execution of any tool from your registry.  To enable this, you must use Dynamic Activities, which are necessary when you request execution of an Activity with an unknown Activity Type. Since your tools are loaded in dynamically, this is a perfect example of when to use Temporal's Dynamic Activities.</p> <p>This Activity will not be implemented as a method within the class, but rather a function within the same <code>activities.py</code> file.</p> <p>Add this function outside the class definition:</p> <pre><code>@activity.defn(dynamic=True)\nasync def dynamic_tool_activity(args: Sequence[RawValue]) -&gt; dict:\n    from tools.tool_registry import get_handler\n\n    tool_name = activity.info().activity_type  # e.g. \"FindEvents\"\n    tool_args = activity.payload_converter().from_payload(args[0].payload, dict)\n    activity.logger.info(f\"Running dynamic tool '{tool_name}' with args: {tool_args}\")\n\n    # Delegate to the relevant function\n    handler = get_handler(tool_name)\n    if inspect.iscoroutinefunction(handler):\n        result = await handler(tool_args)\n    else:\n        result = handler(tool_args)\n\n    # Optionally log or augment the result\n    activity.logger.info(f\"Tool '{tool_name}' result: {result}\")\n    return result\n</code></pre> <p>This dynamic Activity uses Temporal's runtime information to determine which tool to execute.  It retrieves the tool name from the Activity type and loads arguments from the payload. It then inspects the handler to determine if the implementation of the tool is an asynchronous Python function. If it is, it <code>await</code>s its execution, otherwise it directly invokes the function. This means the Activity handles both synchronous and asynchronous tool functions.</p>  The <code>activities/activities.py</code> is complete and will need no more revisions. You can review the complete file and copy the code here.   Hover your cursor over the code block to reveal the copy-code option.    [activities/activities.py](https://github.com/temporal-community/tutorial-temporal-ai-agent/blob/main/activities/activities.py)   <pre><code>import inspect\nimport json\nimport os\nfrom datetime import datetime\nfrom typing import Sequence\n\nfrom dotenv import load_dotenv\nfrom litellm import completion\nfrom temporalio import activity\nfrom temporalio.common import RawValue\n\nfrom models.requests import (\n    EnvLookupInput,\n    EnvLookupOutput,\n    ToolPromptInput,\n    ValidationInput,\n    ValidationResult,\n)\n\nload_dotenv(override=True)\n\n\nclass AgentActivities:\n    def __init__(self):\n        \"\"\"Initialize LLM client using LiteLLM.\"\"\"\n        self.llm_model = os.environ.get(\"LLM_MODEL\", \"openai/gpt-4\")\n        self.llm_key = os.environ.get(\"LLM_KEY\")\n        self.llm_base_url = os.environ.get(\"LLM_BASE_URL\")\n        activity.logger.info(\n            f\"Initializing AgentActivities with LLM model: {self.llm_model}\"\n        )\n        if self.llm_base_url:\n            activity.logger.info(f\"Using custom base URL: {self.llm_base_url}\")\n\n    @activity.defn\n    async def agent_toolPlanner(self, input: ToolPromptInput) -&gt; dict:\n        messages = [\n            {\n                \"role\": \"system\",\n                \"content\": input.context_instructions\n                + \". The current date is \"\n                + datetime.now().strftime(\"%B %d, %Y\"),\n            },\n            {\n                \"role\": \"user\",\n                \"content\": input.prompt,\n            },\n        ]\n\n        try:\n            completion_kwargs = {\n                \"model\": self.llm_model,\n                \"messages\": messages,\n                \"api_key\": self.llm_key,\n            }\n\n            # Add base_url if configured\n            if self.llm_base_url:\n                completion_kwargs[\"base_url\"] = self.llm_base_url\n\n            response = completion(**completion_kwargs)\n\n            response_content = response.choices[0].message.content\n            activity.logger.info(f\"LLM response: {response_content}\")\n\n            # Use the new sanitize function\n            response_content = self.sanitize_json_response(response_content)\n\n            return self.parse_json_response(response_content)\n        except Exception as e:\n            activity.logger.error(f\"Error in LLM completion: {str(e)}\")\n            raise\n\n    @activity.defn\n    async def agent_validatePrompt(\n        self, validation_input: ValidationInput\n    ) -&gt; ValidationResult:\n        \"\"\"\n        Validates the prompt in the context of the conversation history and agent goal.\n        Returns a ValidationResult indicating if the prompt makes sense given the context.\n        \"\"\"\n        # Create simple context string describing tools and goals\n        tools_description = []\n        for tool in validation_input.agent_goal.tools:\n            tool_str = f\"Tool: {tool.name}\\n\"\n            tool_str += f\"Description: {tool.description}\\n\"\n            tool_str += \"Arguments: \" + \", \".join(\n                [f\"{arg.name} ({arg.type})\" for arg in tool.arguments]\n            )\n            tools_description.append(tool_str)\n        tools_str = \"\\n\".join(tools_description)\n\n        # Convert conversation history to string\n        history_str = json.dumps(validation_input.conversation_history, indent=2)\n\n        # Create context instructions\n        context_instructions = f\"\"\"The agent goal and tools are as follows:\n            Description: {validation_input.agent_goal.description}\n            Available Tools:\n            {tools_str}\n            The conversation history to date is:\n            {history_str}\"\"\"\n\n        # Create validation prompt\n        validation_prompt = f\"\"\"The user's prompt is: \"{validation_input.prompt}\"\n            Please validate if this prompt makes sense given the agent goal and conversation history.\n            If the prompt makes sense toward the goal then validationResult should be true.\n            If the prompt is wildly nonsensical or makes no sense toward the goal and current conversation history then validationResult should be false.\n            If the response is low content such as \"yes\" or \"that's right\" then the user is probably responding to a previous prompt.  \n             Therefore examine it in the context of the conversation history to determine if it makes sense and return true if it makes sense.\n            Return ONLY a JSON object with the following structure:\n                \"validationResult\": true/false,\n                \"validationFailedReason\": \"If validationResult is false, provide a clear explanation to the user in the response field \n                about why their request doesn't make sense in the context and what information they should provide instead.\n                validationFailedReason should contain JSON in the format\n                {{\n                    \"next\": \"question\",\n                    \"response\": \"[your reason here and a response to get the user back on track with the agent goal]\"\n                }}\n                If validationResult is true (the prompt makes sense), return an empty dict as its value {{}}\"\n            \"\"\"\n\n        # Call the LLM with the validation prompt\n        prompt_input = ToolPromptInput(\n            prompt=validation_prompt, context_instructions=context_instructions\n        )\n\n        result = await self.agent_toolPlanner(prompt_input)\n\n        return ValidationResult(\n            validationResult=result.get(\"validationResult\", False),\n            validationFailedReason=result.get(\"validationFailedReason\", {}),\n        )\n\n    @activity.defn\n    async def get_wf_env_vars(self, input: EnvLookupInput) -&gt; EnvLookupOutput:\n        \"\"\"gets env vars for workflow as an activity result so it's deterministic\n        handles default/None\n        \"\"\"\n        output: EnvLookupOutput = EnvLookupOutput(\n            show_confirm=input.show_confirm_default\n        )\n        show_confirm_value = os.getenv(input.show_confirm_env_var_name)\n        if show_confirm_value is None:\n            output.show_confirm = input.show_confirm_default\n        elif show_confirm_value is not None and show_confirm_value.lower() == \"false\":\n            output.show_confirm = False\n        else:\n            output.show_confirm = True\n\n        return output\n\n    def sanitize_json_response(self, response_content: str) -&gt; str:\n        \"\"\"\n        Sanitizes the response content to ensure it's valid JSON.\n        \"\"\"\n        # Remove any markdown code block markers\n        response_content = response_content.replace(\"```json\", \"\").replace(\"```\", \"\")\n\n        # Remove any leading/trailing whitespace\n        response_content = response_content.strip()\n\n        return response_content\n\n    def parse_json_response(self, response_content: str) -&gt; dict:\n        \"\"\"\n        Parses the JSON response content and returns it as a dictionary.\n        \"\"\"\n        try:\n            data = json.loads(response_content)\n            return data\n        except json.JSONDecodeError as e:\n            activity.logger.error(f\"Invalid JSON: {e}\")\n            raise\n\n\n@activity.defn(dynamic=True)\nasync def dynamic_tool_activity(args: Sequence[RawValue]) -&gt; dict:\n    from tools.tool_registry import get_handler\n\n    tool_name = activity.info().activity_type  # e.g. \"FindEvents\"\n    tool_args = activity.payload_converter().from_payload(args[0].payload, dict)\n    activity.logger.info(f\"Running dynamic tool '{tool_name}' with args: {tool_args}\")\n\n    # Delegate to the relevant function\n    handler = get_handler(tool_name)\n    if inspect.iscoroutinefunction(handler):\n        result = await handler(tool_args)\n    else:\n        result = handler(tool_args)\n\n    # Optionally log or augment the result\n    activity.logger.info(f\"Tool '{tool_name}' result: {result}\")\n    return result\n</code></pre> <p>The Activities you implemented handle LLM communication, user input validation, environment configuration, and dynamic tool execution. </p>  Before moving on to the next section, verify your files and directory structure is correct.  <pre><code>temporal-ai-agent/\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .python-version\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 uv.lock\n\u251c\u2500\u2500 activities/\n|   \u251c\u2500\u2500 __init__.py\n|   \u2514\u2500\u2500 activities.py\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 core.py\n\u2502   \u2514\u2500\u2500 requests.py\n\u251c\u2500\u2500 scripts/\n\u2502   \u251c\u2500\u2500 create_invoice_test.py\n\u2502   \u251c\u2500\u2500 find_events_test.py\n\u2502   \u2514\u2500\u2500 search_flights_test.py\n\u2514\u2500\u2500 tools/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 create_invoice.py\n    \u251c\u2500\u2500 find_events.py\n    \u251c\u2500\u2500 goal_registry.py\n    \u251c\u2500\u2500 search_flights.py\n    \u251c\u2500\u2500 tool_registry.py\n    \u2514\u2500\u2500 data/\n        \u2514\u2500\u2500 find_events_data.json\n</code></pre> <p>In the next step, you will create a submodule that stores and renders the main prompts the agent uses to communicate with the LLM. </p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#developing-the-necessary-prompts","title":"Developing the necessary prompts","text":"<p>Your agent communicates with an LLM to determine what steps it should take and which tool it should use. However, LLM output is non-determinstic, so how do you ensure that you receive data that you can rely on so your agent can interpret it and continue execution? To do this, you need to carefully craft a prompt explicitly stating what the LLM should do and what format it should return. These prompts can often be complex, and since your agent dynamically loads tools, will also need to be dynamically generated. In this section, you will implement the code to generate these prompts.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#creating-the-submodule","title":"Creating the submodule","text":"<p>First, create a new directory named <code>prompts</code>:</p> <pre><code>mkdir prompts\n</code></pre> <p>Then create the <code>__init__.py</code> file in the <code>prompts</code> director to make it a submodule:</p> <pre><code>touch prompts/__init__.py\n</code></pre> <p>Next, you'll craft your prompt templates that the LLM will use.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#crafting-the-prompts-templates","title":"Crafting the prompts templates","text":"<p>The prompts templates you create will vary in the amount of customization they allow. For templates with minimal customization, for example, templates that only require a few variable substitutions, Python's string formatting syntax will suffice. However, if your template requires iteration, conditional logic, or variable interpolation, you should use a more advanced templating system, such as <code>Jinja2</code>.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#defining-the-primary-context-prompt","title":"Defining the primary context prompt","text":"<p>The primary context that the LLM uses to determine the next action requires multiple steps, conditionals, and loops to implement, so you will implement it using <code>Jinja2</code>.</p> <p>Create the file <code>prompts/prompts.py</code> and add the import for <code>Jinja2</code>:</p> <pre><code>from jinja2 import Template\n</code></pre> <p>Next, add the first part of the primary prompt, which you'll name <code>GENAI_PROMPT</code>:</p> <pre><code>GENAI_PROMPT = Template(\n    \"\"\"\nYou are an AI agent that helps fill required arguments for the tools described below. \nYou must respond with valid JSON ONLY, using the schema provided in the instructions.\n\n=== Conversation History ===\nThis is the ongoing history to determine which tool and arguments to gather:\n*BEGIN CONVERSATION HISTORY*\n{{ conversation_history_json }}\n*END CONVERSATION HISTORY*\nREMINDER: You can use the conversation history to infer arguments for the tools.\n\n{% if agent_goal.example_conversation_history %}\n=== Example Conversation With These Tools ===\nUse this example to understand how tools are invoked and arguments are gathered.\nBEGIN EXAMPLE\n{{ agent_goal.example_conversation_history }}\nEND EXAMPLE\n\n{% endif %}\n\"\"\"\n</code></pre> <p>This section of the prompt sets the primary role for the LLM, provides the current conversation history for the LLM to analyze, and if an example conversation was provided, provides that as an example for the LLM to use as well.</p> <p>Continue adding this prompt by adding the following lines:</p> <pre><code>\"\"\"\n=== Tools Definitions ===\nThere are {{ agent_goal.tools|length }} available tools:\n{{ agent_goal.tools|map(attribute='name')|join(', ') }}\nGoal: {{ agent_goal.description }}\nGather the necessary information for each tool in the sequence described above.\nOnly ask for arguments listed below. Do not add extra arguments.\n\n{% for tool in agent_goal.tools %}\nTool name: {{ tool.name }}\n  Description: {{ tool.description }}\n  Required args:\n{% for arg in tool.arguments %}\n    - {{ arg.name }} ({{ arg.type }}): {{ arg.description }}\n{% endfor %}\n\n{% endfor %}\nWhen all required args for a tool are known, you can propose next='confirm' to run it.\n\"\"\"\n</code></pre> <p>The segment of the prompt definitions section lists the agent's goal and the available tools with their descriptions and argument specifications.  This provides the LLM with information about what the agent is attempting to accomplish, and its capabilities and constraints.</p> <p>Next, it's vital that the LLM provides its response in a consistent way that your agent can parse. Add the following instructions for output formatting and guardrails:</p> <pre><code>\"\"\"\n=== Instructions for JSON Generation ===\nYour JSON format must be:\n{\n  \"response\": \"&lt;plain text&gt;\",\n  \"next\": \"&lt;question|confirm|pick-new-goal|done&gt;\",\n  \"tool\": \"&lt;tool_name or null&gt;\",\n  \"args\": {\n    \"&lt;arg1&gt;\": \"&lt;value1 or null&gt;\",\n    \"&lt;arg2&gt;\": \"&lt;value2 or null&gt;\",\n    ...\n  }\n}\n1) If any required argument is missing, set next='question' and ask the user.\n2) If all required arguments are known, set next='confirm' and specify the tool.\n   The user will confirm before the tool is run.\n3) {{ toolchain_complete_guidance }}\n4) response should be short and user-friendly.\n\nGuardrails (always remember!)\n1) If any required argument is missing, set next='question' and ask the user.\n2) ALWAYS ask a question in your response if next='question'.\n3) ALWAYS set next='confirm' if you have arguments\n And respond with \"let's proceed with &lt;tool&gt; (and any other useful info)\" \n DON'T set next='confirm' if you have a question to ask.\nEXAMPLE: If you have a question to ask, set next='question' and ask the user.\n4) You can carry over arguments from one tool to another.\n EXAMPLE: If you asked for an account ID, then use the conversation history to infer that argument going forward.\n5) If ListAgents in the conversation history is force_confirm='False', you MUST check if the current tool contains userConfirmation. If it does, please ask the user to confirm details with the user. userConfirmation overrides force_confirm='False'.\nEXAMPLE: (force_confirm='False' AND userConfirmation exists on tool) Would you like me to &lt;run tool&gt; with the following details: &lt;details&gt;?\n\"\"\"\n</code></pre> <p>This segment provides strict rules on the exact format the LLM should respond with, as well as guardrails to ensure that fields are set properly. The guardrails section is particularly important as it provides detailed behavioral constraints that enable consistent responses.  These rules prevent issues such as asking questions while proposing tool execution or forgetting to use the conversation history for argument inference.</p> <p>Finally, complete the template with a validation prompt:</p> <pre><code>\"\"\"\n{% if raw_json is not none %}\n\n=== Validation Task ===\nValidate and correct the following JSON if needed:\n{{ raw_json_str }}\n\nCheck syntax, 'tool' validity, 'args' completeness, and set 'next' appropriately. Return ONLY corrected JSON.\n{% endif %}\n\n{% if raw_json is not none %}\nBegin by validating the provided JSON if necessary.\n{% else %}\nBegin by producing a valid JSON response for the next tool or question.\n{% endif %}\n\"\"\".strip()\n)\n</code></pre> <p>The validation section enables the template to handle both correct and incorrectly JSON formatted strings. If the JSON is improperly formatted, the LLM is prompted to correct it before continuing with its other tasks.</p> <p>All together, the template should look like this:</p> <pre><code>GENAI_PROMPT = Template(\n    \"\"\"\nYou are an AI agent that helps fill required arguments for the tools described below. \nYou must respond with valid JSON ONLY, using the schema provided in the instructions.\n\n=== Conversation History ===\nThis is the ongoing history to determine which tool and arguments to gather:\n*BEGIN CONVERSATION HISTORY*\n{{ conversation_history_json }}\n*END CONVERSATION HISTORY*\nREMINDER: You can use the conversation history to infer arguments for the tools.\n\n{% if agent_goal.example_conversation_history %}\n=== Example Conversation With These Tools ===\nUse this example to understand how tools are invoked and arguments are gathered.\nBEGIN EXAMPLE\n{{ agent_goal.example_conversation_history }}\nEND EXAMPLE\n\n{% endif %}\n=== Tools Definitions ===\nThere are {{ agent_goal.tools|length }} available tools:\n{{ agent_goal.tools|map(attribute='name')|join(', ') }}\nGoal: {{ agent_goal.description }}\nGather the necessary information for each tool in the sequence described above.\nOnly ask for arguments listed below. Do not add extra arguments.\n\n{% for tool in agent_goal.tools %}\nTool name: {{ tool.name }}\n  Description: {{ tool.description }}\n  Required args:\n{% for arg in tool.arguments %}\n    - {{ arg.name }} ({{ arg.type }}): {{ arg.description }}\n{% endfor %}\n\n{% endfor %}\nWhen all required args for a tool are known, you can propose next='confirm' to run it.\n\n=== Instructions for JSON Generation ===\nYour JSON format must be:\n{\n  \"response\": \"&lt;plain text&gt;\",\n  \"next\": \"&lt;question|confirm|done&gt;\",\n  \"tool\": \"&lt;tool_name or null&gt;\",\n  \"args\": {\n    \"&lt;arg1&gt;\": \"&lt;value1 or null&gt;\",\n    \"&lt;arg2&gt;\": \"&lt;value2 or null&gt;\",\n    ...\n  }\n}\n1) If any required argument is missing, set next='question' and ask the user.\n2) If all required arguments are known, set next='confirm' and specify the tool.\n   The user will confirm before the tool is run.\n3) {{ toolchain_complete_guidance }}\n4) response should be short and user-friendly.\n\nGuardrails (always remember!)\n1) If any required argument is missing, set next='question' and ask the user.\n2) ALWAYS ask a question in your response if next='question'.\n3) ALWAYS set next='confirm' if you have arguments\n And respond with \"let's proceed with &lt;tool&gt; (and any other useful info)\" \n DON'T set next='confirm' if you have a question to ask.\nEXAMPLE: If you have a question to ask, set next='question' and ask the user.\n4) You can carry over arguments from one tool to another.\n EXAMPLE: If you asked for an account ID, then use the conversation history to infer that argument going forward.\n5) If ListAgents in the conversation history is force_confirm='False', you MUST check if the current tool contains userConfirmation. If it does, please ask the user to confirm details with the user. userConfirmation overrides force_confirm='False'.\nEXAMPLE: (force_confirm='False' AND userConfirmation exists on tool) Would you like me to &lt;run tool&gt; with the following details: &lt;details&gt;?\n\n{% if raw_json is not none %}\n\n=== Validation Task ===\nValidate and correct the following JSON if needed:\n{{ raw_json_str }}\n\nCheck syntax, 'tool' validity, 'args' completeness, and set 'next' appropriately. Return ONLY corrected JSON.\n{% endif %}\n\n{% if raw_json is not none %}\nBegin by validating the provided JSON if necessary.\n{% else %}\nBegin by producing a valid JSON response for the next tool or question.\n{% endif %}\n\"\"\".strip()\n)\n</code></pre> <p>Next, you'll create the prompt that will determine the next steps for your agent to take.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#defining-the-tool-completion-prompt","title":"Defining the tool completion prompt","text":"<p>The <code>TOOL_COMPLETION_PROMPT</code> instructs the LLM to analyze the successful tool results and determine the appropriate next steps.  This prompt only requires minimal substitution, so a Python string formatting will suffice.</p> <p>Add the following constant to your <code>prompts/prompts.py</code> file:</p> <pre><code>TOOL_COMPLETION_PROMPT = \"\"\"### The '{current_tool}' tool completed successfully \nwith {dynamic_result}. \nINSTRUCTIONS: Parse this tool result as plain text, and use the system prompt \ncontaining the list of tools in sequence and the conversation history (and \nprevious tool_results) to figure out next steps, if any. \nYou will need to use the tool_results to auto-fill arguments for subsequent \ntools and also to figure out if all tools have been run. \n{{\"next\": \"&lt;question|confirm|pick-new-goal|done&gt;\", \"tool\": \"&lt;tool_name or null&gt;\", \"args\": {{\"&lt;arg1&gt;\": \"&lt;value1 or null&gt;\", \"&lt;arg2&gt;\": \"&lt;value2 or null&gt;\"}}, \"response\": \"&lt;plain text (can include \\\\n line breaks)&gt;\"}}\nONLY return those json keys (next, tool, args, response), nothing else. \nNext should be \"question\" if the tool is not the last one in the sequence. \nNext should be \"done\" if the user is asking to be done with the chat.\"\"\"\n</code></pre> <p>This template handles successful tool completion scenarios, instructing the LLM to use the results of the execution when determining the next step. It also gives explicit instructions on exactly how to respond, which keys should be present, and the format of the output.</p> <p>Next, you'll implement the prompt for handling missing user arguments.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#defining-the-missing-arguments-prompt","title":"Defining the missing arguments prompt","text":"<p>If the user doesn't provide enough information to the agent, the agent needs to detect this and set the next action to prompt the user for the missing arguments. This prompt only has a few variable substitutions, so a Python string formatting will suffice.</p> <p>Add the missing arguments template to your <code>prompts/prompts.py</code> file:</p> <pre><code>MISSING_ARGS_PROMPT = \"\"\"### INSTRUCTIONS set next='question', combine \nthis response response='{response}' and following missing arguments for tool \n{current_tool}: {missing_args}. Only provide a valid JSON response without any \ncomments or metadata.\"\"\"\n</code></pre> <p>This template provides the response, sets the next key to <code>question</code> to instruct the agent to prompt the user for more information, and specifies which tool is missing which argument.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#defining-the-toolchain-complete-prompt","title":"Defining the toolchain complete prompt","text":"<p>Finally, define the prompt that details what the LLM should do if no more tools are needed to complete the agent's goal.</p> <pre><code>TOOLCHAIN_COMPLETE_GUIDANCE_PROMPT = \"If no more tools are needed (user_confirmed_tool_run has been run for all), set next='done' and tool=''.\"\n</code></pre>  The <code>prompts/prompts.py</code> is complete and will need no more revisions. You can review the complete file and copy the code here.   Hover your cursor over the code block to reveal the copy-code option.    [prompts/prompts](https://github.com/temporal-community/tutorial-temporal-ai-agent/blob/main/prompts/prompts.py)  <pre><code>from jinja2 import Template\n\n# Define the Jinja2 template\nGENAI_PROMPT = Template(\n    \"\"\"\nYou are an AI agent that helps fill required arguments for the tools described below. \nYou must respond with valid JSON ONLY, using the schema provided in the instructions.\n\n=== Conversation History ===\nThis is the ongoing history to determine which tool and arguments to gather:\n*BEGIN CONVERSATION HISTORY*\n{{ conversation_history_json }}\n*END CONVERSATION HISTORY*\nREMINDER: You can use the conversation history to infer arguments for the tools.\n\n{% if agent_goal.example_conversation_history %}\n=== Example Conversation With These Tools ===\nUse this example to understand how tools are invoked and arguments are gathered.\nBEGIN EXAMPLE\n{{ agent_goal.example_conversation_history }}\nEND EXAMPLE\n\n{% endif %}\n=== Tools Definitions ===\nThere are {{ agent_goal.tools|length }} available tools:\n{{ agent_goal.tools|map(attribute='name')|join(', ') }}\nGoal: {{ agent_goal.description }}\nGather the necessary information for each tool in the sequence described above.\nOnly ask for arguments listed below. Do not add extra arguments.\n\n{% for tool in agent_goal.tools %}\nTool name: {{ tool.name }}\n  Description: {{ tool.description }}\n  Required args:\n{% for arg in tool.arguments %}\n    - {{ arg.name }} ({{ arg.type }}): {{ arg.description }}\n{% endfor %}\n\n{% endfor %}\nWhen all required args for a tool are known, you can propose next='confirm' to run it.\n\n=== Instructions for JSON Generation ===\nYour JSON format must be:\n{\n  \"response\": \"&lt;plain text&gt;\",\n  \"next\": \"&lt;question|confirm|done&gt;\",\n  \"tool\": \"&lt;tool_name or null&gt;\",\n  \"args\": {\n    \"&lt;arg1&gt;\": \"&lt;value1 or null&gt;\",\n    \"&lt;arg2&gt;\": \"&lt;value2 or null&gt;\",\n    ...\n  }\n}\n1) If any required argument is missing, set next='question' and ask the user.\n2) If all required arguments are known, set next='confirm' and specify the tool.\n   The user will confirm before the tool is run.\n3) {{ toolchain_complete_guidance }}\n4) response should be short and user-friendly.\n\nGuardrails (always remember!)\n1) If any required argument is missing, set next='question' and ask the user.\n1) ALWAYS ask a question in your response if next='question'.\n2) ALWAYS set next='confirm' if you have arguments\n And respond with \"let's proceed with &lt;tool&gt; (and any other useful info)\" \n DON'T set next='confirm' if you have a question to ask.\nEXAMPLE: If you have a question to ask, set next='question' and ask the user.\n3) You can carry over arguments from one tool to another.\n EXAMPLE: If you asked for an account ID, then use the conversation history to infer that argument going forward.\n4) If ListAgents in the conversation history is force_confirm='False', you MUST check if the current tool contains userConfirmation. If it does, please ask the user to confirm details with the user. userConfirmation overrides force_confirm='False'.\nEXAMPLE: (force_confirm='False' AND userConfirmation exists on tool) Would you like me to &lt;run tool&gt; with the following details: &lt;details&gt;?\n\n{% if raw_json is not none %}\n\n=== Validation Task ===\nValidate and correct the following JSON if needed:\n{{ raw_json_str }}\n\nCheck syntax, 'tool' validity, 'args' completeness, and set 'next' appropriately. Return ONLY corrected JSON.\n{% endif %}\n\n{% if raw_json is not none %}\nBegin by validating the provided JSON if necessary.\n{% else %}\nBegin by producing a valid JSON response for the next tool or question.\n{% endif %}\n\"\"\".strip()\n)\n\nTOOL_COMPLETION_PROMPT = \"\"\"### The '{current_tool}' tool completed successfully \nwith {dynamic_result}. \nINSTRUCTIONS: Parse this tool result as plain text, and use the system prompt \ncontaining the list of tools in sequence and the conversation history (and \nprevious tool_results) to figure out next steps, if any. \nYou will need to use the tool_results to auto-fill arguments for subsequent \ntools and also to figure out if all tools have been run. \n{{\"next\": \"&lt;question|confirm|done&gt;\", \"tool\": \"&lt;tool_name or null&gt;\", \"args\": {{\"&lt;arg1&gt;\": \"&lt;value1 or null&gt;\", \"&lt;arg2&gt;\": \"&lt;value2 or null&gt;\"}}, \"response\": \"&lt;plain text (can include \\\\n line breaks)&gt;\"}}\nONLY return those json keys (next, tool, args, response), nothing else. \nNext should be \"question\" if the tool is not the last one in the sequence. \nNext should be \"done\" if the user is asking to be done with the chat.\"\"\"\n\n\nMISSING_ARGS_PROMPT = \"\"\"### INSTRUCTIONS set next='question', combine \nthis response response='{response}' and following missing arguments for tool \n{current_tool}: {missing_args}. Only provide a valid JSON response without any \ncomments or metadata.\"\"\"\n\nTOOLCHAIN_COMPLETE_GUIDANCE_PROMPT = \"If no more tools are needed (user_confirmed_tool_run has been run for all), set next='done' and tool=''.\"\n</code></pre> <p>Next, you'll build the functions that use these prompt templates to generate the actual prompts.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#building-the-prompt-generation-functions","title":"Building the prompt generation functions","text":"<p>Now that you have the prompt templates built, you need to implement functions the agent can call to render them.</p> <p>First, create <code>prompts/agent_prompt_generators.py</code> and add the following imports:</p> <pre><code>import json\nfrom typing import Optional\n\nfrom models.core import AgentGoal\nfrom models.requests import ConversationHistory, ToolData\nfrom prompts.prompts import (\n    GENAI_PROMPT,\n    MISSING_ARGS_PROMPT,\n    TOOL_COMPLETION_PROMPT,\n    TOOLCHAIN_COMPLETE_GUIDANCE_PROMPT,\n)\n</code></pre> <p>Next, create the function to render the <code>GENAI_PROMPT</code>:</p> <pre><code>def generate_genai_prompt(\n    agent_goal: AgentGoal,\n    conversation_history: ConversationHistory,\n    raw_json: Optional[ToolData] = None,\n) -&gt; str:\n    \"\"\"\n    Generates a concise prompt for producing or validating JSON instructions\n    with the provided tools and conversation history.\n    \"\"\"\n\n    # Prepare template variables\n    template_vars = {\n        \"agent_goal\": agent_goal,\n        \"conversation_history_json\": json.dumps(conversation_history, indent=2),\n        \"toolchain_complete_guidance\": TOOLCHAIN_COMPLETE_GUIDANCE_PROMPT,\n        \"raw_json\": raw_json,\n        \"raw_json_str\": (\n            json.dumps(raw_json, indent=2) if raw_json is not None else None\n        ),\n    }\n\n    return GENAI_PROMPT.render(**template_vars)\n</code></pre> <p>This function creates the <code>template_vars</code> dictionary, assigns the parameters to the appropriate template variables, and then renders the <code>Jinja2</code> template, passing in the dictionary as <code>kwargs</code> to the <code>render</code> function.</p> <p>Next, add the tool completion prompt generator:</p> <pre><code>def generate_tool_completion_prompt(current_tool: str, dynamic_result: dict) -&gt; str:\n    \"\"\"\n    Generates a prompt for handling tool completion and determining next steps.\n\n    Args:\n        current_tool: The name of the tool that just completed\n        dynamic_result: The result data from the tool execution\n\n    Returns:\n        str: A formatted prompt string for the agent to process the tool completion\n    \"\"\"\n    return TOOL_COMPLETION_PROMPT.format(\n        current_tool=current_tool, dynamic_result=dynamic_result\n    )\n</code></pre> <p>This function takes in the current tool, along with the dynamic result system prompt and returns the formatted <code>TOOL_COMPLETION_PROMPT</code> using the <code>.format</code> function.</p> <p>Finally, add the prompt for handling missing arguments:</p> <pre><code>def generate_missing_args_prompt(\n    current_tool: str, tool_data: dict, missing_args: list[str]\n) -&gt; str:\n    \"\"\"\n    Generates a prompt for handling missing arguments for a tool.\n\n    Args:\n        current_tool: The name of the tool that needs arguments\n        tool_data: The current tool data containing the response\n        missing_args: List of argument names that are missing\n\n    Returns:\n        str: A formatted prompt string for requesting missing arguments\n    \"\"\"\n    return MISSING_ARGS_PROMPT.format(\n        response=tool_data.get(\"response\"),\n        current_tool=current_tool,\n        missing_args=missing_args,\n    )\n</code></pre> <p>This function gets the response from the current tool, and the arguments missing, then returns a the formatted <code>MISSING_ARGS_PROMPT</code>.</p>  The <code>prompts/agent_prompt_generators.py</code> is complete and will need no more revisions. You can review the complete file and copy the code here.   Hover your cursor over the code block to reveal the copy-code option.    [prompts/agent_prompt_generators.py](https://github.com/temporal-community/tutorial-temporal-ai-agent/blob/main/prompts/agent_prompt_generators.py)  <pre><code>import json\nfrom typing import Optional\n\nfrom models.core import AgentGoal\nfrom models.requests import ConversationHistory, ToolData\nfrom prompts.prompts import (\n    GENAI_PROMPT,\n    MISSING_ARGS_PROMPT,\n    TOOL_COMPLETION_PROMPT,\n    TOOLCHAIN_COMPLETE_GUIDANCE_PROMPT,\n)\n\n\ndef generate_genai_prompt(\n    agent_goal: AgentGoal,\n    conversation_history: ConversationHistory,\n    raw_json: Optional[ToolData] = None,\n) -&gt; str:\n    \"\"\"\n    Generates a concise prompt for producing or validating JSON instructions\n    with the provided tools and conversation history.\n    \"\"\"\n\n    # Prepare template variables\n    template_vars = {\n        \"agent_goal\": agent_goal,\n        \"conversation_history_json\": json.dumps(conversation_history, indent=2),\n        \"toolchain_complete_guidance\": TOOLCHAIN_COMPLETE_GUIDANCE_PROMPT,\n        \"raw_json\": raw_json,\n        \"raw_json_str\": (\n            json.dumps(raw_json, indent=2) if raw_json is not None else None\n        ),\n    }\n\n    return GENAI_PROMPT.render(**template_vars)\n\n\ndef generate_tool_completion_prompt(current_tool: str, dynamic_result: dict) -&gt; str:\n    \"\"\"\n    Generates a prompt for handling tool completion and determining next steps.\n\n    Args:\n        current_tool: The name of the tool that just completed\n        dynamic_result: The result data from the tool execution\n\n    Returns:\n        str: A formatted prompt string for the agent to process the tool completion\n    \"\"\"\n    return TOOL_COMPLETION_PROMPT.format(\n        current_tool=current_tool, dynamic_result=dynamic_result\n    )\n\n\ndef generate_missing_args_prompt(\n    current_tool: str, tool_data: dict, missing_args: list[str]\n) -&gt; str:\n    \"\"\"\n    Generates a prompt for handling missing arguments for a tool.\n\n    Args:\n        current_tool: The name of the tool that needs arguments\n        tool_data: The current tool data containing the response\n        missing_args: List of argument names that are missing\n\n    Returns:\n        str: A formatted prompt string for requesting missing arguments\n    \"\"\"\n    return MISSING_ARGS_PROMPT.format(\n        response=tool_data.get(\"response\"),\n        current_tool=current_tool,\n        missing_args=missing_args,\n    )\n</code></pre>  Before moving on to the next section, verify your files and directory structure is correct.  <pre><code>temporal-ai-agent/\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .python-version\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 uv.lock\n\u251c\u2500\u2500 activities/\n|   \u251c\u2500\u2500 __init__.py\n|   \u2514\u2500\u2500 activities.py\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 core.py\n\u2502   \u2514\u2500\u2500 requests.py\n\u251c\u2500\u2500 prompts/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 agent_prompt_generators.py\n\u2502   \u2514\u2500\u2500 prompts.py\n\u251c\u2500\u2500 scripts/\n\u2502   \u251c\u2500\u2500 create_invoice_test.py\n\u2502   \u251c\u2500\u2500 find_events_test.py\n\u2502   \u2514\u2500\u2500 search_flights_test.py\n\u2514\u2500\u2500 tools/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 create_invoice.py\n    \u251c\u2500\u2500 find_events.py\n    \u251c\u2500\u2500 goal_registry.py\n    \u251c\u2500\u2500 search_flights.py\n    \u251c\u2500\u2500 tool_registry.py\n    \u2514\u2500\u2500 data/\n        \u2514\u2500\u2500 find_events_data.json\n</code></pre> <p>Now that you have the prompt rendering submodule implemented, you can implement the main agent Workflow.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#building-the-agent-workflow","title":"Building the agent Workflow","text":"<p>Agents need to manage conversations that involve multiple turns including user interaction, tool execution, and state management.  The challenge is maintaining coherence across these sessions while handling failures, retries, and long-running interactions. Your agent must coordinate several concurrent concerns such as validating user input against conversation context, determining when to execute tools, managing user input for tool execution, and maintaining conversation history that persists in the event of system failures.  A traditional application would lose conversation state during failures, but Temporal Workflows provide durable execution that preserves context through any system interruption.</p> <p>In this step, you will create the Temporal Workflow that orchestrates your agent's conversation loop.  This Workflow handles user interactions, validates prompts, manages tool execution, and maintains conversation state, all while providing durability to the agent.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#creating-the-workflows-submodule","title":"Creating the workflows submodule","text":"<p>First, create the directory structure for your Workflow implementations:</p> <pre><code>mkdir workflows\n</code></pre> <p>Next, create an empty <code>__init__.py</code> file in the directory to enable it as a submodule:</p> <pre><code>touch workflows/__init__.py\n</code></pre> <p>Now that your <code>workflows</code> directory is a submodule, you will create a few helper functions for your Workflow.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#implementing-a-few-workflow-helper-functions","title":"Implementing a few Workflow helper functions","text":"<p>Before implementing the Workflow, you will implement a few helper functions that perform repetitive operations like tool execution, argument validation, and conversation continuation.</p> <p>First, create <code>workflows/workflow_helpers.py</code> and add the following import statements:</p> <pre><code>from datetime import timedelta\nfrom typing import Any, Callable, Deque, Dict\n\nfrom temporalio import workflow\nfrom temporalio.common import RetryPolicy\nfrom temporalio.exceptions import ActivityError\n\nwith workflow.unsafe.imports_passed_through():\n    from activities.activities import AgentActivities\n    from models.requests import ConversationHistory, ToolData, ToolPromptInput\n    from prompts.agent_prompt_generators import (\n        generate_missing_args_prompt,\n        generate_tool_completion_prompt,\n    )\n</code></pre> <p>Like previous <code>import</code> statements, this section includes libraries from the Python standard library and Temporal libraries.  However, there are also libraries being imported with the <code>with workflow.unsafe.imports_passed_through()</code> statement. This statement is necessary when importing third-party libraries, including ones you implement, into a Workflow (or in this case, imported into a file that will be imported by the Workflow). This is done for performance and determinism safety reasons, which you can read more about in the Temporal documentation.</p> <p>Next, declare the following timeout constants:</p> <pre><code>TOOL_ACTIVITY_START_TO_CLOSE_TIMEOUT = timedelta(seconds=30)\nTOOL_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT = timedelta(minutes=30)\nLLM_ACTIVITY_START_TO_CLOSE_TIMEOUT = timedelta(seconds=30)\nLLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT = timedelta(minutes=30)\n</code></pre> <p>These timeout constants set sensible limits for tool execution and LLM calls, ensuring the calls have enough time to respond, but that the Workflow detects a failure within a reasonable amount of time.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#defining-the-tool-execution-activity-invocation-function","title":"Defining the tool execution Activity invocation function","text":"<p>The first function you'll implement is the <code>handle_tool_execution</code> function. Add the method header to the file:</p> <pre><code>async def handle_tool_execution(\n    current_tool: str,\n    tool_data: ToolData,\n    add_message_callback: Callable[..., Any],\n    prompt_queue: Deque[str],\n) -&gt; None:\n</code></pre> <p>This function takes in the current tool to execute, the tool data, a callback that stores the conversation history, and a queue for prompts that the agent will execute later to continue its goal. The function executes the tool as a dynamic Activity, and processes the results for the LLM to handle.</p> <p>Add the code to invoke the Activity and process the results:</p> <p><pre><code>    \"\"\"Execute a tool after confirmation and handle its result.\"\"\"\n    workflow.logger.info(f\"Confirmed. Proceeding with tool: {current_tool}\")\n    try:\n        dynamic_result = await workflow.execute_activity(\n            current_tool,\n            tool_data[\"args\"],\n            schedule_to_close_timeout=TOOL_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n            start_to_close_timeout=TOOL_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n            retry_policy=RetryPolicy(\n                initial_interval=timedelta(seconds=5), backoff_coefficient=1\n            ),\n        )\n        dynamic_result[\"tool\"] = current_tool\n    except ActivityError as e:\n        workflow.logger.error(f\"Tool execution failed: {str(e)}\")\n        dynamic_result = {\"error\": str(e), \"tool\": current_tool}\n\n    add_message_callback(\"tool_result\", dynamic_result)\n    prompt_queue.append(generate_tool_completion_prompt(current_tool, dynamic_result))\n</code></pre> It executes the tool by calling the name of the tool, which gets handled by the dynamic Activity you implemented. When calling the Activity, you specify the Activity timeouts using the constants you defined earlier. Whether the Activity succeeds or fails, the result is stored to the conversation history using the <code>add_message_callback</code> that was passed in. Then, the method invokes the <code>generate_tool_completion_prompt</code> function with the <code>current_tool</code> and result of the tool execution to create a prompt and add it to the <code>prompt_queue</code>, which the agent will handle on its next iteration.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#defining-the-missing-argument-handler-function","title":"Defining the missing argument handler function","text":"<p>Next you'll create the function that checks and handles missing tool arguments. Add the function header with the following arguments:</p> <pre><code>async def handle_missing_args(\n    current_tool: str,\n    args: Dict[str, Any],\n    tool_data: Dict[str, Any],\n    prompt_queue: Deque[str],\n) -&gt; bool:\n</code></pre> <p>This function takes in the <code>current_tool</code>, the <code>args</code> that were passed to the tool, the <code>tool_data</code> containing all data related to the tool, and the <code>prompt_queue</code> containing prompts the LLM still needs to act on.</p> <p>Add the remaining code to check for any missing arguments:</p> <pre><code>    \"\"\"Check for missing arguments and handle them if found.\"\"\"\n    missing_args = [key for key, value in args.items() if value is None]\n\n    if missing_args:\n        prompt_queue.append(\n            generate_missing_args_prompt(current_tool, tool_data, missing_args)\n        )\n        workflow.logger.info(\n            f\"Missing arguments for tool: {current_tool}: {' '.join(missing_args)}\"\n        )\n        return True\n    return False\n</code></pre> <p>The tool arguments are checked, and if any are missing, the <code>generate_missing_args_prompt</code> is invoked and the result is added to the <code>prompt_queue</code> for the agent to execute on its next turn. The function then returns <code>True</code>. Otherwise, no arguments were missing and the function returns <code>False</code>.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#defining-the-history-formatting-function","title":"Defining the history formatting function","text":"<p>Next you'll define functions for formatting the conversation history.</p> <p>Add the following function to your code:</p> <pre><code>def format_history(conversation_history: ConversationHistory) -&gt; str:\n    \"\"\"Format the conversation history into a single string.\"\"\"\n    return \" \".join(str(msg[\"response\"]) for msg in conversation_history[\"messages\"])\n</code></pre> <p>This function compacts responses from every message in the conversation history and returns it as a single string.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#defining-the-history-summarization-prompt-function","title":"Defining the history summarization prompt function","text":"<p>Now you'll use the previous function to generate a prompt for the LLM to summarize the conversation.</p> <p>Add the following function to your code:</p> <pre><code>def prompt_summary_with_history(\n    conversation_history: ConversationHistory,\n) -&gt; tuple[str, str]:\n    \"\"\"Generate a prompt for summarizing the conversation.\n    Used only for continue as new of the workflow.\"\"\"\n    history_string = format_history(conversation_history)\n    context_instructions = f\"Here is the conversation history between a user and a chatbot: {history_string}\"\n    actual_prompt = (\n        \"Please produce a two sentence summary of this conversation. \"\n        'Put the summary in the format { \"summary\": \"&lt;plain text&gt;\" }'\n    )\n    return (context_instructions, actual_prompt)\n</code></pre> <p>The code calls the <code>format_history</code> function, then creates two variables, one containing the history and another containing the prompt. It then returns both variables as a tuple.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#defining-the-function-to-handle-long-event-histories","title":"Defining the function to handle long Event Histories","text":"<p>Temporal Workflows have a limit on the length and size of a single Workflow Execution's Event History. A Temporal Workflow will <code>Continue-As-New</code> when the Event History reaches this limits, and will continue the execution in a new Workflow Execution, which in turn creates new Event History. Due to the length of LLM responses, you will implement a function to determine if a <code>Continue-As-New</code> is needed.</p> <p>First, define the function header:</p> <pre><code>async def continue_as_new_if_needed(\n    conversation_history: ConversationHistory,\n    prompt_queue: Deque[str],\n    agent_goal: Any,\n    max_turns: int,\n    add_message_callback: Callable[..., Any],\n) -&gt; None:\n</code></pre> <p>The function receives the <code>conversation_history</code> as your custom type, the <code>prompt_queue</code> as the pass-by-object <code>Deque</code> used to control the flow of prompts, the agent's goal, how many turns the conversation should last for, and a function callback to add this interaction to the conversation history.</p> <p>Next, add the function implementation:</p> <pre><code>    \"\"\"Handle workflow continuation if message limit is reached.\"\"\"\n    if len(conversation_history[\"messages\"]) &gt;= max_turns:\n        summary_context, summary_prompt = prompt_summary_with_history(\n            conversation_history\n        )\n        summary_input = ToolPromptInput(\n            prompt=summary_prompt, context_instructions=summary_context\n        )\n        conversation_summary = await workflow.start_activity_method(\n            AgentActivities.agent_toolPlanner,\n            summary_input,\n            schedule_to_close_timeout=LLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n        )\n        workflow.logger.info(f\"Continuing as new after {max_turns} turns.\")\n        add_message_callback(\"conversation_summary\", conversation_summary)\n        workflow.continue_as_new(\n            args=[\n                {\n                    \"tool_params\": {\n                        \"conversation_summary\": conversation_summary,\n                        \"prompt_queue\": prompt_queue,\n                    },\n                    \"agent_goal\": agent_goal,\n                }\n            ]\n        )\n</code></pre> <p>The function first checks if the conversation history's length is greater than or equal to the maximum number of turns specified. If this evaluates to <code>true</code>, the function proceeds with its <code>Continue-As-New</code> process. First it calls <code>prompt_summary_with_history</code> to create a summary and prompt context using the current history. It then uses this output to create an input type, <code>ToolPromptInput</code>, based off of this summary for the agent to process. Next it calls the <code>agent_toolPlanner</code> Activity with this input to invoke the LLM with this summarized context. It then calls the <code>add_message_callback</code> function, which adds this event to the conversation history. Finally, it invokes <code>workflow.continue_as_new</code> to perform the <code>Continue-As-New</code> operation, which results in a new Workflow Execution starting at this point in the Event History, and the current Workflow Execution closing.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#defining-the-prompt-entity-identification-function","title":"Defining the prompt entity identification function","text":"<p>Finally, add a function that returns a boolean it the prompt came from a user or not:</p> <pre><code># LLM-tagged prompts start with \"###\"\n# all others are from the user\ndef is_user_prompt(prompt) -&gt; bool:\n    if prompt.startswith(\"###\"):\n        return False\n    else:\n        return True\n</code></pre> <p>LLM prompts start with <code>###</code>, so any prompt that doesn't begin with that character sequence is a user prompt.</p>  The <code>workflows/workflow_helpers.py</code> is complete and will need no more revisions. You can review the complete file and copy the code here.   Hover your cursor over the code block to reveal the copy-code option.    [workflows/workflow_helpers.py](https://github.com/temporal-community/tutorial-temporal-ai-agent/blob/main/workflows/workflow_helpers.py)  <pre><code>from datetime import timedelta\nfrom typing import Any, Callable, Deque, Dict\n\nfrom temporalio import workflow\nfrom temporalio.common import RetryPolicy\nfrom temporalio.exceptions import ActivityError\n\nwith workflow.unsafe.imports_passed_through():\n    from activities.activities import AgentActivities\n    from models.requests import ConversationHistory, ToolData, ToolPromptInput\n    from prompts.agent_prompt_generators import (\n        generate_missing_args_prompt,\n        generate_tool_completion_prompt,\n    )\n\n\nTOOL_ACTIVITY_START_TO_CLOSE_TIMEOUT = timedelta(seconds=30)\nTOOL_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT = timedelta(minutes=30)\nLLM_ACTIVITY_START_TO_CLOSE_TIMEOUT = timedelta(seconds=30)\nLLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT = timedelta(minutes=30)\n\n\nasync def handle_tool_execution(\n    current_tool: str,\n    tool_data: ToolData,\n    add_message_callback: Callable[..., Any],\n    prompt_queue: Deque[str],\n) -&gt; None:\n    \"\"\"Execute a tool after confirmation and handle its result.\"\"\"\n    workflow.logger.info(f\"Confirmed. Proceeding with tool: {current_tool}\")\n\n    try:\n        dynamic_result = await workflow.execute_activity(\n            current_tool,\n            tool_data[\"args\"],\n            schedule_to_close_timeout=TOOL_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n            start_to_close_timeout=TOOL_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n            retry_policy=RetryPolicy(\n                initial_interval=timedelta(seconds=5), backoff_coefficient=1\n            ),\n        )\n        dynamic_result[\"tool\"] = current_tool\n    except ActivityError as e:\n        workflow.logger.error(f\"Tool execution failed: {str(e)}\")\n        dynamic_result = {\"error\": str(e), \"tool\": current_tool}\n\n    add_message_callback(\"tool_result\", dynamic_result)\n    prompt_queue.append(generate_tool_completion_prompt(current_tool, dynamic_result))\n\n\nasync def handle_missing_args(\n    current_tool: str,\n    args: Dict[str, Any],\n    tool_data: Dict[str, Any],\n    prompt_queue: Deque[str],\n) -&gt; bool:\n    \"\"\"Check for missing arguments and handle them if found.\"\"\"\n    missing_args = [key for key, value in args.items() if value is None]\n\n    if missing_args:\n        prompt_queue.append(\n            generate_missing_args_prompt(current_tool, tool_data, missing_args)\n        )\n        workflow.logger.info(\n            f\"Missing arguments for tool: {current_tool}: {' '.join(missing_args)}\"\n        )\n        return True\n    return False\n\n\ndef format_history(conversation_history: ConversationHistory) -&gt; str:\n    \"\"\"Format the conversation history into a single string.\"\"\"\n    return \" \".join(str(msg[\"response\"]) for msg in conversation_history[\"messages\"])\n\n\ndef prompt_summary_with_history(\n    conversation_history: ConversationHistory,\n) -&gt; tuple[str, str]:\n    \"\"\"Generate a prompt for summarizing the conversation.\n    Used only for continue as new of the workflow.\"\"\"\n    history_string = format_history(conversation_history)\n    context_instructions = f\"Here is the conversation history between a user and a chatbot: {history_string}\"\n    actual_prompt = (\n        \"Please produce a two sentence summary of this conversation. \"\n        'Put the summary in the format { \"summary\": \"&lt;plain text&gt;\" }'\n    )\n    return (context_instructions, actual_prompt)\n\n\nasync def continue_as_new_if_needed(\n    conversation_history: ConversationHistory,\n    prompt_queue: Deque[str],\n    agent_goal: Any,\n    max_turns: int,\n    add_message_callback: Callable[..., Any],\n) -&gt; None:\n    \"\"\"Handle workflow continuation if message limit is reached.\"\"\"\n    if len(conversation_history[\"messages\"]) &gt;= max_turns:\n        summary_context, summary_prompt = prompt_summary_with_history(\n            conversation_history\n        )\n        summary_input = ToolPromptInput(\n            prompt=summary_prompt, context_instructions=summary_context\n        )\n        conversation_summary = await workflow.start_activity_method(\n            AgentActivities.agent_toolPlanner,\n            summary_input,\n            schedule_to_close_timeout=LLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n        )\n        workflow.logger.info(f\"Continuing as new after {max_turns} turns.\")\n        add_message_callback(\"conversation_summary\", conversation_summary)\n        workflow.continue_as_new(\n            args=[\n                {\n                    \"tool_params\": {\n                        \"conversation_summary\": conversation_summary,\n                        \"prompt_queue\": prompt_queue,\n                    },\n                    \"agent_goal\": agent_goal,\n                }\n            ]\n        )\n\n\n# LLM-tagged prompts start with \"###\"\n# all others are from the user\ndef is_user_prompt(prompt) -&gt; bool:\n    if prompt.startswith(\"###\"):\n        return False\n    else:\n        return True\n</code></pre> <p>Now that you have built out the supporting functions, you can build the agent Workflow.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#preparing-the-core-agent-workflow","title":"Preparing the core agent Workflow","text":"<p>The core agent Workflow is the primary driver of your agent. It orchestrates LLM and tool execution, maintains conversation state, and makes decisions about what step to take next. The Workflow will consist of the primary Workflow class and method, as well as a few Signals, Queries, and class methods.</p> <p>First, create <code>workflows/agent_goal_workflow.py</code>, and add the necessary imports:</p> <pre><code>from collections import deque\nfrom datetime import timedelta\nfrom typing import Any, Deque, Dict, Optional, Union\n\nfrom temporalio import workflow\nfrom temporalio.common import RetryPolicy\n\nfrom models.core import AgentGoal\nfrom models.requests import (\n    ConversationHistory,\n    CurrentTool,\n    EnvLookupInput,\n    EnvLookupOutput,\n    ToolData,\n    ValidationInput,\n)\nfrom workflows import workflow_helpers as helpers\nfrom workflows.workflow_helpers import (\n    LLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n    LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n)\n\nwith workflow.unsafe.imports_passed_through():\n    from activities.activities import AgentActivities\n    from models.requests import CombinedInput, ToolPromptInput\n    from prompts.agent_prompt_generators import generate_genai_prompt\n\n# Constants\nMAX_TURNS_BEFORE_CONTINUE = 250\n</code></pre> <p>These imports bring in the necessary types, helper functions, and constants you have defined so far, as well as libraries from the Temporal and Python standard library.  You also added the <code>MAX_TURNS_BEFORE_CONTINUE</code> constant, and set the value to <code>250</code>. The agent will use this value with the <code>continue_as_new_if_needed</code> helper function you implemented to decide if it should <code>Continue-As-New</code>. For the sake of this agent and its goal, <code>250</code> turns should be an adequate number </p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#defining-the-agent-class-and-constructor","title":"Defining the agent class and constructor","text":"<p>You define a Temporal Workflow by creating a Python class. Create the <code>AgentGoalWorkflow</code> class, decorate it with <code>@workflow.defn</code>, and define the <code>__init__</code> method:</p> <pre><code>@workflow.defn\nclass AgentGoalWorkflow:\n    \"\"\"Workflow that manages tool execution with user confirmation and conversation history.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.conversation_history: ConversationHistory = {\"messages\": []}\n        self.prompt_queue: Deque[str] = deque()\n        self.chat_ended: bool = False\n        self.tool_data: Optional[ToolData] = None\n        self.goal: Optional[AgentGoal] = None\n        self.waiting_for_confirm: bool = False\n        self.show_tool_args_confirmation: bool = (\n            True  # set from env file in activity lookup_wf_env_settings\n        )\n        self.confirmed: bool = (\n            False  # indicates that we have confirmation to proceed to run tool\n        )\n</code></pre> <p>Your Workflow must be decorated with the <code>@workflow.defn</code> decorator. This is what distinguishes it as a Temporal Workflow. While a Workflow isn't required to have a <code>__init__</code> method, your agent will benefit from instance variables.</p> Variable Description <code>conversation_history</code> A record of the entire chat conversation history <code>prompt_queue</code> A queue maintaining tasks left for the agent to process <code>chat_ended</code> A boolean to determine if the chat has ended or not <code>tool_data</code> A record of the current tool data <code>goal</code> The agent's goal <code>waiting_for_confirm</code> A boolean signifying if the agent is ready to execute the tool <code>show_tool_args_confirmation</code> A boolean to determine if extra confirmation is necessary before executing tools <code>confirmed</code> A boolean for determining if the agent is confirmed to proceed <p>Next, you'll begin implementing the main Workflow method.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#defining-the-agent-control-variables","title":"Defining the agent control variables","text":"<p>Every Temporal Workflow has a singular entry point, also known as the Workflow method. This method is decorated with the <code>@workflow.run</code> decorator. Your Workflow method will contain the primary business logic for your agent.</p> <p>Declare the method header for your agent's Workflow method:</p> <pre><code>    @workflow.run\n    async def run(self, combined_input: CombinedInput) -&gt; str:\n</code></pre> <p>The Workflow method must be decorated with the <code>@workflow.run</code> decorator, and must be implemented using Python's <code>asyncio</code> library. This method takes in one argument, a type you defined named <code>CombinedInput</code>, and returns a <code>str</code>. Recall that <code>CombinedInput</code> contains the <code>AgentGoal</code> and <code>AgentGoalWorkflowParams</code> types.</p> <p>Add the next few lines of code to the <code>run</code> method to assign values to a few parameters:</p> <pre><code>        \"\"\"Main workflow execution method.\"\"\"\n        # setup phase, starts with blank tool_params and agent_goal prompt as defined in tools/goal_registry.py\n        params = combined_input.tool_params\n        self.goal = combined_input.agent_goal\n\n        await self.lookup_wf_env_settings()\n</code></pre> <p>The last line calls a method, <code>lookup_wf_env_settings</code>, that hasn't been defined yet, so define that as a method within the <code>AgentGoalWorkflow</code> class but not within the scope of your <code>run</code> method:</p> <pre><code>    # look up env settings in an activity so they're part of history\n    async def lookup_wf_env_settings(self) -&gt; None:\n        env_lookup_input = EnvLookupInput(\n            show_confirm_env_var_name=\"SHOW_CONFIRM\",\n            show_confirm_default=True,\n        )\n        env_output: EnvLookupOutput = await workflow.execute_activity_method(\n            AgentActivities.get_wf_env_vars,\n            env_lookup_input,\n            start_to_close_timeout=LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n            retry_policy=RetryPolicy(\n                initial_interval=timedelta(seconds=5), backoff_coefficient=1\n            ),\n        )\n        self.show_tool_args_confirmation = env_output.show_confirm\n</code></pre> <p>This method invokes the <code>get_wf_env_vars</code> Activity to read the environment variables and store them appropriately.</p>  Checkpoint: Your file should currently look like this:  Hover your cursor over the code block to reveal the copy-code option.  <pre><code>from collections import deque\nfrom datetime import timedelta\nfrom typing import Any, Deque, Dict, Optional, Union\n\nfrom temporalio import workflow\nfrom temporalio.common import RetryPolicy\n\nfrom models.core import AgentGoal, ConversationHistory, CurrentTool\nfrom models.requests import EnvLookupInput, EnvLookupOutput, ToolData, ValidationInput\nfrom workflows import workflow_helpers as helpers\nfrom workflows.workflow_helpers import (\n    LLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n    LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n)\n\nwith workflow.unsafe.imports_passed_through():\n    from activities.activities import AgentActivities\n    from models.requests import CombinedInput, ToolPromptInput\n    from prompts.agent_prompt_generators import generate_genai_prompt\n\n# Constants\nMAX_TURNS_BEFORE_CONTINUE = 250\n\n@workflow.defn\nclass AgentGoalWorkflow:\n    \"\"\"Workflow that manages tool execution with user confirmation and conversation history.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.conversation_history: ConversationHistory = {\"messages\": []}\n        self.prompt_queue: Deque[str] = deque()\n        self.chat_ended: bool = False\n        self.tool_data: Optional[ToolData] = None\n        self.goal: Optional[AgentGoal] = None\n        self.waiting_for_confirm: bool = False\n        self.show_tool_args_confirmation: bool = (\n            True  # set from env file in activity lookup_wf_env_settings\n        )\n        self.confirmed: bool = (\n            False  # indicates that we have confirmation to proceed to run tool\n        )\n\n    @workflow.run\n    async def run(self, combined_input: CombinedInput) -&gt; str:\n        \"\"\"Main workflow execution method.\"\"\"\n        # setup phase, starts with blank tool_params and agent_goal prompt as defined in tools/goal_registry.py\n        params = combined_input.tool_params\n        self.goal = combined_input.agent_goal\n\n        await self.lookup_wf_env_settings()\n\n    # look up env settings in an activity so they're part of history\n    async def lookup_wf_env_settings(self) -&gt; None:\n        env_lookup_input = EnvLookupInput(\n            show_confirm_env_var_name=\"SHOW_CONFIRM\",\n            show_confirm_default=True,\n        )\n        env_output: EnvLookupOutput = await workflow.execute_activity_method(\n            AgentActivities.get_wf_env_vars,\n            env_lookup_input,\n            start_to_close_timeout=LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n            retry_policy=RetryPolicy(\n                initial_interval=timedelta(seconds=5), backoff_coefficient=1\n            ),\n        )\n        self.show_tool_args_confirmation = env_output.show_confirm\n</code></pre> <p>Next, add the final lines of code to finish instantiating the instance and local variables within the <code>run</code> method:</p> <pre><code>        if params and params.prompt_queue:\n            self.prompt_queue.extend(params.prompt_queue)\n\n        waiting_for_confirm: bool = False\n        current_tool: Optional[CurrentTool] = None\n</code></pre> <p>If the parameters include a prompt, they are added to the <code>prompt_queue</code> for the agent to process. The <code>prompt_queue</code> is source of truth for tasks that the agent needs to execute to complete its goal. Tasks will be added throughout the lifecycle, which will drive execution forward.</p> <p>Finally, you set the waiting for confirmation variable to false and the current tool to None. These variables will change as the agent processes the various tasks to complete its goal.</p> <p>Now that you've defined the class and instantiated the control variables, you can build the core agent loop.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#implementing-the-core-agent-loop","title":"Implementing the core agent loop","text":"<p>The core of the agent's logic, processing, and validation takes place within a single main loop. Every iteration of the loop is considered a turn. The agent may perform an action in a turn, or set up an action to be performed on the next turn, and <code>continue</code> the loop to end its turn. This loop will run indefinitely until the agent determines it achieved its goal and returns the final result.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#handling-the-await-conditions-and-exit-condition","title":"Handling the await conditions and exit condition","text":"<p>The first step is to create the loop and handle the await and exit conditions. Add the following lines of code within the run method directly following the <code>await self.lookup_wf_env_settings()</code> line:</p> <pre><code>        while True:\n            # wait indefinitely for input from signals - user_prompt, end_chat, or confirm as defined below\n            await workflow.wait_condition(\n                lambda: bool(self.prompt_queue) or self.chat_ended or self.confirmed\n            )\n\n            # handle chat should end. When chat ends, push conversation history to workflow results.\n            if self.chat_ended:\n                return f\"{self.conversation_history}\"\n</code></pre> <p>This section creates the loop, and then immediately awaits for a condition to become true so it can proceed. The conditions it's waiting on is for either something to be added to the <code>prompt_queue</code> so the agent has something to process, the chat end either later in the loop or via Signal, or for the user to confirm execution. Once any of these three conditions is met, it continues execution.  The agent then checks to see if the <code>self.chat_ended</code> instance variable is <code>True</code>, indicating that the agent can halt execution. If so, the agent will return the conversation history stored in the <code>self.conversation</code> instance variable, and the Workflow Execution will close.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#executing-the-tool","title":"Executing the tool","text":"<p>Next, your agent will determine if it is appropriate to execute a the tool, and if it is, invoke an Activity to do so.</p> <p>Continue by adding the following code to execute the tool:</p> <pre><code>            # Execute the tool\n            if self.ready_for_tool_execution() and current_tool is not None:\n                await self.execute_tool(current_tool)\n                continue\n</code></pre> <p>Before the agent executes a tool, the agent confirms that the tool meets the requirements for execution and that the current tool is not <code>None</code>. If both of these checks evaluate to <code>True</code>, the agent executes the tool. Once the tool has completed execution, it <code>continue</code>s the loop, meaning it skips all further execution and returns to the top of the loop, ready to begin another iteration.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#adding-in-a-few-more-helper-methods","title":"Adding in a few more helper methods","text":"<p>Next, implement three helper method that the tool execution code block called, but had not yet implemented.</p> <p>The first checks if the tool is ready for execution. Leave the <code>run</code> and append this new method to your class:</p> <pre><code>    # define if we're ready for tool execution\n    def ready_for_tool_execution(self) -&gt; bool:\n\n        return (\n            self.confirmed and self.waiting_for_confirm and self.tool_data is not None\n        )\n</code></pre> <p>This method checks if the user confirmed execution via <code>self.confirmed</code>, if the agent has confirmed it has the data it needs to execute via <code>self.waiting_for_confirm</code>, and if <code>self.tool_data</code> is set. If this evaluates to <code>True</code>, the tool is ready for execution and the method returns <code>True</code>.</p> <p>The second method executes the tool. Leave the <code>run</code> and append this new method to your class:</p> <pre><code>    # execute the tool - set self.waiting_for_confirm to False if we're not waiting for confirm anymore\n    # (always the case if it works successfully)\n    async def execute_tool(self, current_tool: CurrentTool) -&gt; None:\n        workflow.logger.info(\n            f\"workflow step: user has confirmed, executing the tool {current_tool}\"\n        )\n        self.confirmed = False\n        confirmed_tool_data = self.tool_data.copy()\n        confirmed_tool_data[\"next\"] = \"confirm\"\n        self.add_message(\"user_confirmed_tool_run\", confirmed_tool_data)\n\n        # execute the tool by key as defined in tools/__init__.py\n        await helpers.handle_tool_execution(\n            current_tool,\n            self.tool_data,\n            self.add_message,\n            self.prompt_queue,\n        )\n\n        self.waiting_for_confirm = False\n</code></pre> <p>This method resets the <code>self.confirmed</code> variable, makes a copy of the tool data to then modify, and adds a message to the conversation history with this modified tool data. It then uses the <code>handle_tool_execution</code> function to invoke the tool as an Activity. Once the Activity has completed, it returns the <code>waiting_for_confirm</code> variable. On a successful execution, the <code>self.waiting_for_confirm</code> instance variable is set to <code>False</code>, resetting it and preparing the agent for its next turn in the conversation.</p> <p>And finally, the <code>execute_tool</code> helper method called yet another helper method, the <code>add_message</code> method. This method adds messages to the conversation history.</p> <pre><code>    def add_message(self, actor: str, response: Union[str, Dict[str, Any]]) -&gt; None:\n        \"\"\"Add a message to the conversation history.\n\n        Args:\n            actor: The entity that generated the message (e.g., \"user\", \"agent\")\n            response: The message content, either as a string or structured data\n        \"\"\"\n        if isinstance(response, dict):\n            response_str = str(response)\n            workflow.logger.debug(f\"Adding {actor} message: {response_str[:100]}...\")\n        else:\n            workflow.logger.debug(f\"Adding {actor} message: {response[:100]}...\")\n\n        self.conversation_history[\"messages\"].append(\n            {\"actor\": actor, \"response\": response}\n        )\n</code></pre> <p>The method checks to see if the <code>response</code> parameter passed in is a <code>dict</code> or <code>str</code>. It then removes the first 100 characters, which contain boilerplate LLM response, and adds the message to the <code>self.conversation_history</code> instance variable.</p>  Checkpoint: Your file should currently look like this:  Hover your cursor over the code block to reveal the copy-code option.  <pre><code>from collections import deque\nfrom datetime import timedelta\nfrom typing import Any, Deque, Dict, Optional, Union\n\nfrom temporalio import workflow\nfrom temporalio.common import RetryPolicy\n\nfrom models.core import AgentGoal, ConversationHistory, CurrentTool\nfrom models.requests import EnvLookupInput, EnvLookupOutput, ToolData, ValidationInput\nfrom workflows import workflow_helpers as helpers\nfrom workflows.workflow_helpers import (\n    LLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n    LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n)\n\nwith workflow.unsafe.imports_passed_through():\n    from activities.activities import AgentActivities\n    from models.requests import CombinedInput, ToolPromptInput\n    from prompts.agent_prompt_generators import generate_genai_prompt\n\n# Constants\nMAX_TURNS_BEFORE_CONTINUE = 250\n\n@workflow.defn\nclass AgentGoalWorkflow:\n    \"\"\"Workflow that manages tool execution with user confirmation and conversation history.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.conversation_history: ConversationHistory = {\"messages\": []}\n        self.prompt_queue: Deque[str] = deque()\n        self.chat_ended: bool = False\n        self.tool_data: Optional[ToolData] = None\n        self.goal: Optional[AgentGoal] = None\n        self.waiting_for_confirm: bool = False\n        self.show_tool_args_confirmation: bool = (\n            True  # set from env file in activity lookup_wf_env_settings\n        )\n        self.confirmed: bool = (\n            False  # indicates that we have confirmation to proceed to run tool\n        )\n\n    @workflow.run\n    async def run(self, combined_input: CombinedInput) -&gt; str:\n        \"\"\"Main workflow execution method.\"\"\"\n        # setup phase, starts with blank tool_params and agent_goal prompt as defined in tools/goal_registry.py\n        params = combined_input.tool_params\n        self.goal = combined_input.agent_goal\n\n        await self.lookup_wf_env_settings() \n\n        if params and params.prompt_queue:\n            self.prompt_queue.extend(params.prompt_queue)\n\n        current_tool: Optional[CurrentTool] = None\n\n        while True:\n            # wait indefinitely for input from signals - user_prompt, end_chat, or confirm as defined below\n            await workflow.wait_condition(\n                lambda: bool(self.prompt_queue) or self.chat_ended or self.confirmed\n            )\n\n            # handle chat should end. When chat ends, push conversation history to workflow results.\n            if self.chat_ended:\n                workflow.logger.info(\"Chat-end signal received. Chat ending.\")\n                return f\"{self.conversation_history}\"\n\n            # Execute the tool\n            if self.ready_for_tool_execution() and current_tool is not None:\n                await self.execute_tool(current_tool)\n                continue\n\n    # look up env settings in an activity so they're part of history\n    async def lookup_wf_env_settings(self) -&gt; None:\n        env_lookup_input = EnvLookupInput(\n            show_confirm_env_var_name=\"SHOW_CONFIRM\",\n            show_confirm_default=True,\n        )\n        env_output: EnvLookupOutput = await workflow.execute_activity_method(\n            AgentActivities.get_wf_env_vars,\n            env_lookup_input,\n            start_to_close_timeout=LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n            retry_policy=RetryPolicy(\n                initial_interval=timedelta(seconds=5), backoff_coefficient=1\n            ),\n        )\n        self.show_tool_args_confirmation = env_output.show_confirm\n\n    # define if we're ready for tool execution\n    def ready_for_tool_execution(self) -&gt; bool:\n\n        return (\n            self.confirmed and self.waiting_for_confirm and self.tool_data is not None\n        )\n\n    # execute the tool - set self.waiting_for_confirm to False if we're not waiting for confirm anymore\n    # (always the case if it works successfully)\n    async def execute_tool(self, current_tool: CurrentTool) -&gt; None:\n        workflow.logger.info(\n            f\"workflow step: user has confirmed, executing the tool {current_tool}\"\n        )\n        self.confirmed = False\n        confirmed_tool_data = self.tool_data.copy()\n        confirmed_tool_data[\"next\"] = \"confirm\"\n        self.add_message(\"user_confirmed_tool_run\", confirmed_tool_data)\n\n        # execute the tool by key as defined in tools/__init__.py\n        await helpers.handle_tool_execution(\n            current_tool,\n            self.tool_data,\n            self.add_message,\n            self.prompt_queue,\n        )\n\n        self.waiting_for_confirm = False\n\n    def add_message(self, actor: str, response: Union[str, Dict[str, Any]]) -&gt; None:\n        \"\"\"Add a message to the conversation history.\n\n        Args:\n            actor: The entity that generated the message (e.g., \"user\", \"agent\")\n            response: The message content, either as a string or structured data\n        \"\"\"\n        if isinstance(response, dict):\n            response_str = str(response)\n            workflow.logger.debug(f\"Adding {actor} message: {response_str[:100]}...\")\n        else:\n            workflow.logger.debug(f\"Adding {actor} message: {response[:100]}...\")\n\n        self.conversation_history[\"messages\"].append(\n            {\"actor\": actor, \"response\": response}\n        )\n</code></pre>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#validating-user-prompts","title":"Validating user prompts","text":"<p>Before processing any input from the user, the agent needs to validate it. You defined Activities in a prior section to validate the data, and now your Workflow will invoke them.</p> <p>Continue by adding the prompt processing logic within the core agent loop:</p> <pre><code>            # process forward on the prompt queue if any\n            if self.prompt_queue:\n                # get most recent prompt\n                prompt = self.prompt_queue.popleft()\n                workflow.logger.info(\n                    f\"workflow step: processing message on the prompt queue, message is {prompt}\"\n                )\n\n                # Validate user-provided prompts\n                if helpers.is_user_prompt(prompt):\n                    self.add_message(\"user\", prompt)\n\n                    # Validate the prompt before proceeding\n                    validation_input = ValidationInput(\n                        prompt=prompt,\n                        conversation_history=self.conversation_history,\n                        agent_goal=self.goal,\n                    )\n                    validation_result = await workflow.execute_activity_method(\n                        AgentActivities.agent_validatePrompt,\n                        args=[validation_input],\n                        schedule_to_close_timeout=LLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n                        start_to_close_timeout=LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n                        retry_policy=RetryPolicy(\n                            initial_interval=timedelta(seconds=5), backoff_coefficient=1\n                        ),\n                    )\n\n                    # If validation fails, provide that feedback to the user - i.e., \"your words make no sense, puny human\" end this iteration of processing\n                    if not validation_result.validationResult:\n                        workflow.logger.warning(\n                            f\"Prompt validation failed: {validation_result.validationFailedReason}\"\n                        )\n                        self.add_message(\n                            \"agent\", validation_result.validationFailedReason\n                        )\n                        continue\n</code></pre> <p>The validation code first checks to see if there are any prompts in the queue. If so, it removes the most recent prompt for processing. Next is calls the <code>is_user_prompt</code> helper function you defined earlier to determine who the author of the prompt is. If the prompt is from the agent, the validation step is skipped. However, if the prompt is from a user, it is validated. The agent creates a <code>ValidationInput</code> variable containing the prompt, the conversation history, and the agent's goal. The agent then executes the <code>agent_validatePrompt</code> Activity, passing the <code>ValidationInput</code> variable as input. If the validation passes, the Workflow proceeds execution. However, if the validation fails, the agent logs the error, adds it to conversation history and, resets to the beginning using <code>continue</code>, where it will inform the user of the error and await a response.</p> <p>It's important to recall that within <code>agent_validatePrompt</code>, regardless of success the Activity calls the <code>agent_toolPlanner</code> method. This provides a reason why the validation failed, if necessary.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#generating-a-context-aware-prompt","title":"Generating a context-aware prompt","text":"<p>Upon successful validation, the Workflow invokes another Activity to generate a context-aware prompt for the LLM to use.</p> <p>Continue by adding the call to the <code>generate_genai_prompt</code> function you implemented in the <code>prompts</code> submodule to your code:</p> <pre><code>                # If valid, proceed with generating the context and prompt\n                context_instructions = generate_genai_prompt(\n                    agent_goal=self.goal,\n                    conversation_history=self.conversation_history,\n                    raw_json=self.tool_data,\n                )\n</code></pre> <p>This function call takes the agent's goal, the current conversation history, and the tool's data as input to generate the prompt. Recall that the tool data may be blank, for example, on the first iteration as a tool hasn't been selected. The prompt template handles this and only renders the data if it exists.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#executing-the-tool-planner","title":"Executing the tool planner","text":"<p>Now that the prompt is constructed, you can use the LLM to plan which tool to use.</p> <p>Add the following code call the <code>agent_toolPlanner</code> Activity and process the results:</p> <pre><code>                prompt_input = ToolPromptInput(\n                    prompt=prompt, context_instructions=context_instructions\n                )\n\n                # connect to LLM and execute to get next steps\n                tool_data = await workflow.execute_activity_method(\n                    AgentActivities.agent_toolPlanner,\n                    prompt_input,\n                    schedule_to_close_timeout=LLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n                    start_to_close_timeout=LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n                    retry_policy=RetryPolicy(\n                        initial_interval=timedelta(seconds=5), backoff_coefficient=1\n                    ),\n                )\n\n                tool_data[\"force_confirm\"] = self.show_tool_args_confirmation\n                self.tool_data = ToolData(**tool_data)\n\n                # process the tool as dictated by the prompt response - what to do next, and with which tool\n                next_step = tool_data.get(\"next\")\n                current_tool: Optional[CurrentTool] = tool_data.get(\"tool\")\n\n                workflow.logger.info(\n                    f\"next_step: {next_step}, current tool is {current_tool}\"\n                )\n</code></pre> <p>Before the agent executes the Activity, it creates a variable using your type <code>ToolPromptInput</code> that contains the prompt and context. It then invokes the <code>agent_toolPlanner</code> Activity, passing in this variable. The Activity makes a call to the LLM with the prompt to determine what tool the agent should use to proceed with the next step of its goal, and returns the response as a <code>dict</code>. If the <code>SHOW_CONFIRM</code> environment variable was set to <code>True</code>, then the <code>force_confirm</code> key is also set to <code>True</code>. Next, the <code>self.tool_data</code> instance variable is updated with the data returned from the Activity execution. It then sets the <code>next_step</code> and <code>current_tool</code> variables to prepare for the next phase of execution.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#determining-the-next_step","title":"Determining the <code>next_step</code>","text":"<p>The <code>next_step</code> variable contains the next action the LLM decided the agent should take to achieve its goal. This variable can only contain the value <code>question</code>, <code>confirm</code>, and <code>done</code>, which the agent interprets and acts on. When the value is <code>question</code>, the agent asks a clarifying question of the user, such as requesting a missing parameter. This is handled automatically via the prompt. However, <code>confirm</code> and <code>done</code> require custom logic.</p> <p>Add the following code to implement the path for these options:</p> <pre><code>                # make sure we're ready to run the tool &amp; have everything we need\n                if next_step == \"confirm\" and current_tool:\n                    args = tool_data.get(\"args\", {})\n                    # if we're missing arguments, ask for them\n                    if await helpers.handle_missing_args(\n                        current_tool, args, tool_data, self.prompt_queue\n                    ):\n                        continue\n\n                    self.waiting_for_confirm = True\n\n                    # We have needed arguments, if we want to force the user to confirm, set that up\n                    if self.show_tool_args_confirmation:\n                        self.confirmed = False  # set that we're not confirmed\n                        workflow.logger.info(\"Waiting for user confirm signal...\")\n                    # if we have all needed arguments (handled above) and not holding for a debugging confirm, proceed:\n                    else:\n                        self.confirmed = True\n\n                # else if the next step is to be done with the conversation such as if the user requests it via asking to \"end conversation\"\n                elif next_step == \"done\":\n                    self.add_message(\"agent\", tool_data)\n\n                    # here we could send conversation to AI for analysis\n\n                    # end the workflow\n                    return str(self.conversation_history)\n</code></pre> <p>If <code>next_step</code> is set to <code>confirm</code>, then the user confirmed their choice and the LLM has chosen to continue executing. If both <code>confirm</code> and <code>current_tool</code> have something assigned to them, the agent checks for missing arguments using the <code>handle_missing_args</code> function. Remember that if the <code>handle_missing_args</code> function determines an argument is missing, it adds a new prompt to the <code>prompt_queue</code> so the agent asks the user on the next turn. If an argument is missing, the prompt is added and the agent <code>continue</code>s, leading to the user being asked for the missing argument. If no argument is missing, then <code>self.waiting_for_confirm</code> is set to <code>True</code>, which indicates that the agent is ready to execute the tool.</p> <p>It then checks if <code>self.show_tools_args_confirmation</code> was set. If so, <code>self.confirmed</code> is set to <code>False</code>, forcing the user to confirm again on the next turn. Otherwise, <code>self.confirmed</code> is set to <code>True</code>, and the user approved the tool execution on the next turn.</p> <p>However, if <code>next_step</code> is set to <code>done</code>, the LLM determined that the goal is complete, and no more work is necessary. The agent wraps up by adding a final message to the conversation history, and then returns the conversation history, closing the Workflow Execution.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#handling-a-long-running-execution","title":"Handling a long running execution","text":"<p>The final segment of the agent loop handles long running execution. Temporal Workflows have a limit on the size of a single Workflow Execution's Event History. If the Event History is too long, then the agent should perform a <code>Continue-As-New</code> operation to prevent a potential failure.</p> <p>Add the following code to check and execute a <code>Continue-As-New</code> if necessary:</p> <pre><code>                self.add_message(\"agent\", tool_data)\n                await helpers.continue_as_new_if_needed(\n                    self.conversation_history,\n                    self.prompt_queue,\n                    self.goal,\n                    MAX_TURNS_BEFORE_CONTINUE,\n                    self.add_message,\n                )\n</code></pre> <p>First, the current tool data is added to the conversation history. Before, you defined a helper function <code>continue_as_new_if_needed</code> to determine if the Workflow should perform the <code>Continue-As-New</code> operation. This function makes its decision based on the number of turns the agent completed prior to calling the function. If it is greater, then the agent performs the <code>Continue-As-New</code> operation.</p>  Checkpoint: Your file should currently look like this:  Hover your cursor over the code block to reveal the copy-code option.  <pre><code>from collections import deque\nfrom datetime import timedelta\nfrom typing import Any, Deque, Dict, Optional, Union\n\nfrom temporalio import workflow\nfrom temporalio.common import RetryPolicy\n\nfrom models.core import AgentGoal\nfrom models.requests import (\n    ConversationHistory,\n    CurrentTool,\n    EnvLookupInput,\n    EnvLookupOutput,\n    ToolData,\n    ValidationInput,\n)\nfrom workflows import workflow_helpers as helpers\nfrom workflows.workflow_helpers import (\n    LLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n    LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n)\n\nwith workflow.unsafe.imports_passed_through():\n    from activities.activities import AgentActivities\n    from models.requests import CombinedInput, ToolPromptInput\n    from prompts.agent_prompt_generators import generate_genai_prompt\n\n# Constants\nMAX_TURNS_BEFORE_CONTINUE = 250\n\n\n@workflow.defn\nclass AgentGoalWorkflow:\n    \"\"\"Workflow that manages tool execution with user confirmation and conversation history.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.conversation_history: ConversationHistory = {\"messages\": []}\n        self.prompt_queue: Deque[str] = deque()\n        self.chat_ended: bool = False\n        self.tool_data: Optional[ToolData] = None\n        self.goal: Optional[AgentGoal] = None\n        self.waiting_for_confirm: bool = False\n        self.show_tool_args_confirmation: bool = (\n            True  # set from env file in activity lookup_wf_env_settings\n        )\n        self.confirmed: bool = (\n            False  # indicates that we have confirmation to proceed to run tool\n        )\n\n    # see ../api/main.py#temporal_client.start_workflow() for how the input parameters are set\n    @workflow.run\n    async def run(self, combined_input: CombinedInput) -&gt; str:\n        \"\"\"Main workflow execution method.\"\"\"\n        # setup phase, starts with blank tool_params and agent_goal prompt as defined in tools/goal_registry.py\n        params = combined_input.tool_params\n        self.goal = combined_input.agent_goal\n\n        await self.lookup_wf_env_settings()\n\n        if params and params.prompt_queue:\n            self.prompt_queue.extend(params.prompt_queue)\n\n        current_tool: Optional[CurrentTool] = None\n\n        # This is the main interactive loop. Main responsibilities:\n        #   - reacting to user input (from signals)\n        #   - validating user input to make sure it makes sense with the current goal and tools\n        #   - calling the LLM through activities to determine next steps and prompts\n        #   - executing the selected tools via Activities\n        while True:\n            # wait indefinitely for input from signals - user_prompt, end_chat, or confirm as defined below\n            await workflow.wait_condition(\n                lambda: bool(self.prompt_queue) or self.chat_ended or self.confirmed\n            )\n\n            # handle chat should end. When chat ends, push conversation history to workflow results.\n            if self.chat_ended:\n                workflow.logger.info(\"Chat-end signal received. Chat ending.\")\n                return f\"{self.conversation_history}\"\n\n            # Execute the tool\n            if self.ready_for_tool_execution() and current_tool is not None:\n                await self.execute_tool(current_tool)\n                continue\n\n            # process forward on the prompt queue if any\n            if self.prompt_queue:\n                # get most recent prompt\n                prompt = self.prompt_queue.popleft()\n                workflow.logger.info(\n                    f\"workflow step: processing message on the prompt queue, message is {prompt}\"\n                )\n\n                # Validate user-provided prompts\n                if helpers.is_user_prompt(prompt):\n                    self.add_message(\"user\", prompt)\n\n                    # Validate the prompt before proceeding\n                    validation_input = ValidationInput(\n                        prompt=prompt,\n                        conversation_history=self.conversation_history,\n                        agent_goal=self.goal,\n                    )\n                    validation_result = await workflow.execute_activity_method(\n                        AgentActivities.agent_validatePrompt,\n                        args=[validation_input],\n                        schedule_to_close_timeout=LLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n                        start_to_close_timeout=LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n                        retry_policy=RetryPolicy(\n                            initial_interval=timedelta(seconds=5), backoff_coefficient=1\n                        ),\n                    )\n\n                    # If validation fails, provide that feedback to the user - i.e., \"your words make no sense, puny human\" end this iteration of processing\n                    if not validation_result.validationResult:\n                        workflow.logger.warning(\n                            f\"Prompt validation failed: {validation_result.validationFailedReason}\"\n                        )\n                        self.add_message(\n                            \"agent\", validation_result.validationFailedReason\n                        )\n                        continue\n\n                # If valid, proceed with generating the context and prompt\n                context_instructions = generate_genai_prompt(\n                    agent_goal=self.goal,\n                    conversation_history=self.conversation_history,\n                    raw_json=self.tool_data,\n                )\n\n                prompt_input = ToolPromptInput(\n                    prompt=prompt, context_instructions=context_instructions\n                )\n\n                # connect to LLM and execute to get next steps\n                tool_data = await workflow.execute_activity_method(\n                    AgentActivities.agent_toolPlanner,\n                    prompt_input,\n                    schedule_to_close_timeout=LLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n                    start_to_close_timeout=LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n                    retry_policy=RetryPolicy(\n                        initial_interval=timedelta(seconds=5), backoff_coefficient=1\n                    ),\n                )\n\n                tool_data[\"force_confirm\"] = self.show_tool_args_confirmation\n                self.tool_data = ToolData(**tool_data)\n\n                # process the tool as dictated by the prompt response - what to do next, and with which tool\n                next_step = tool_data.get(\"next\")\n                current_tool: Optional[CurrentTool] = tool_data.get(\"tool\")\n\n                workflow.logger.info(\n                    f\"next_step: {next_step}, current tool is {current_tool}\"\n                )\n\n                # make sure we're ready to run the tool &amp; have everything we need\n                if next_step == \"confirm\" and current_tool:\n                    args = tool_data.get(\"args\", {})\n                    # if we're missing arguments, ask for them\n                    if await helpers.handle_missing_args(\n                        current_tool, args, tool_data, self.prompt_queue\n                    ):\n                        continue\n\n                    self.waiting_for_confirm = True\n\n                    # We have needed arguments, if we want to force the user to confirm, set that up\n                    if self.show_tool_args_confirmation:\n                        self.confirmed = False  # set that we're not confirmed\n                        workflow.logger.info(\"Waiting for user confirm signal...\")\n                    # if we have all needed arguments (handled above) and not holding for a debugging confirm, proceed:\n                    else:\n                        self.confirmed = True\n\n                # else if the next step is to be done with the conversation such as if the user requests it via asking to \"end conversation\"\n                elif next_step == \"done\":\n                    self.add_message(\"agent\", tool_data)\n\n                    # here we could send conversation to AI for analysis\n\n                    # end the workflow\n                    return str(self.conversation_history)\n\n                self.add_message(\"agent\", tool_data)\n                await helpers.continue_as_new_if_needed(\n                    self.conversation_history,\n                    self.prompt_queue,\n                    self.goal,\n                    MAX_TURNS_BEFORE_CONTINUE,\n                    self.add_message,\n                )\n\n    # look up env settings in an activity so they're part of history\n    async def lookup_wf_env_settings(self) -&gt; None:\n        env_lookup_input = EnvLookupInput(\n            show_confirm_env_var_name=\"SHOW_CONFIRM\",\n            show_confirm_default=True,\n        )\n        env_output: EnvLookupOutput = await workflow.execute_activity_method(\n            AgentActivities.get_wf_env_vars,\n            env_lookup_input,\n            start_to_close_timeout=LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n            retry_policy=RetryPolicy(\n                initial_interval=timedelta(seconds=5), backoff_coefficient=1\n            ),\n        )\n        self.show_tool_args_confirmation = env_output.show_confirm\n\n    # define if we're ready for tool execution\n    def ready_for_tool_execution(self) -&gt; bool:\n\n        return (\n            self.confirmed and self.waiting_for_confirm and self.tool_data is not None\n        )\n\n    # execute the tool - set self.waiting_for_confirm to False if we're not waiting for confirm anymore\n    # (always the case if it works successfully)\n    async def execute_tool(self, current_tool: CurrentTool) -&gt; None:\n        workflow.logger.info(\n            f\"workflow step: user has confirmed, executing the tool {current_tool}\"\n        )\n        self.confirmed = False\n        confirmed_tool_data = self.tool_data.copy()\n        confirmed_tool_data[\"next\"] = \"confirm\"\n        self.add_message(\"user_confirmed_tool_run\", confirmed_tool_data)\n\n        # execute the tool by key as defined in tools/__init__.py\n        await helpers.handle_tool_execution(\n            current_tool,\n            self.tool_data,\n            self.add_message,\n            self.prompt_queue,\n        )\n\n        self.waiting_for_confirm = False\n\n    def add_message(self, actor: str, response: Union[str, Dict[str, Any]]) -&gt; None:\n        \"\"\"Add a message to the conversation history.\n\n        Args:\n            actor: The entity that generated the message (e.g., \"user\", \"agent\")\n            response: The message content, either as a string or structured data\n        \"\"\"\n        if isinstance(response, dict):\n            response_str = str(response)\n            workflow.logger.debug(f\"Adding {actor} message: {response_str[:100]}...\")\n        else:\n            workflow.logger.debug(f\"Adding {actor} message: {response[:100]}...\")\n\n        self.conversation_history[\"messages\"].append(\n            {\"actor\": actor, \"response\": response}\n        )\n\n    # Signal that comes from api/main.py via a post to /send-prompt\n    @workflow.signal\n    async def user_prompt(self, prompt: str) -&gt; None:\n        \"\"\"Signal handler for receiving user prompts.\"\"\"\n        workflow.logger.info(f\"signal received: user_prompt, prompt is {prompt}\")\n        if self.chat_ended:\n            workflow.logger.info(f\"Message dropped due to chat closed: {prompt}\")\n            return\n        self.prompt_queue.append(prompt)\n</code></pre> <p>Finally, you are going to implement a method for external Temporal Clients to send and retrieve information to and from the Workflow Execution while it's running.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#communicating-with-the-workflow","title":"Communicating with the Workflow","text":"<p>Temporal Workflows allow data to be sent and retrieved during a running execution. These features are known as Signals and Queries.</p> <p>Look back at the core event loop in the Workflow, specifically the <code>await</code> line at the very top of the loop:</p> <pre><code>        while True:\n            # wait indefinitely for input from signals - user_prompt, end_chat, or confirm as defined below\n            await workflow.wait_condition(\n                lambda: bool(self.prompt_queue) or self.chat_ended or self.confirmed\n            )\n</code></pre> <p>You may have noticed the <code>chat_ended</code> variable was never changed, or the user's input was never added to the <code>prompt_queue</code>. This is done via sending Signals to your running Workflow Execution.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#accepting-the-users-input","title":"Accepting the users input","text":"<p>To accept user input and add it to the <code>prompt_queue</code>, define a Signal handler as a method within your <code>agent_goal_workflow.py</code> file, outside of the <code>run</code> function, and underneath your other helper functions.</p> <p>Add the Signal handler to your code:</p> <pre><code>    # Signal that comes from api/main.py via a post to /send-prompt\n    @workflow.signal\n    async def user_prompt(self, prompt: str) -&gt; None:\n        \"\"\"Signal handler for receiving user prompts.\"\"\"\n        workflow.logger.info(f\"signal received: user_prompt, prompt is {prompt}\")\n        if self.chat_ended:\n            workflow.logger.info(f\"Message dropped due to chat closed: {prompt}\")\n            return\n        self.prompt_queue.append(prompt)\n</code></pre> <p>A Signal handler is an <code>async</code> method that is decorated with the <code>@workflow.signal</code> decorator. When the Signal is received, it is logged, and then the agent checks to see if the chat has ended. If it has, the Signal is dropped as no more processing work should take place.  This is important, as it handles the edge case of the small amount of time between when the agent finishes, but prior to the Workflow Execution closing. Then the prompt is added to the end of the <code>prompt_queue</code> for the agent to eventually process.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#confirming-the-users-request","title":"Confirming the users request","text":"<p>Another Signal to implement is the user confirming the use of a tool, specifically when <code>SHOW_CONFIRM</code> is set to <code>True</code>.</p> <p>Add the following Signal handler to the bottom of your file:</p> <pre><code>    # Signal that comes from api/main.py via a post to /confirm\n    @workflow.signal\n    async def confirm(self) -&gt; None:\n        \"\"\"Signal handler for user confirmation of tool execution.\"\"\"\n        workflow.logger.info(\"Received user signal: confirmation\")\n        self.confirmed = True\n</code></pre> <p>This code implements the Signal handler method, decorates it with <code>@workflow.signal</code>, and logs that the Signal was received.  It then sets the <code>self.confirmed</code> instance variable to <code>True</code>, which will unblock the main agent loop.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#ending-the-chat","title":"Ending the chat","text":"<p>The last Signal handler your agent needs is to allow the user to end the chat.</p> <p>Add the following Signal handler to the bottom of your file:</p> <pre><code>    # Signal that comes from api/main.py via a post to /end-chat\n    @workflow.signal\n    async def end_chat(self) -&gt; None:\n        \"\"\"Signal handler for ending the chat session.\"\"\"\n        workflow.logger.info(\"signal received: end_chat\")\n        self.chat_ended = True\n</code></pre> <p>Similar to the previous Signal handler, this is a decorated method that sets an instance variable to <code>True</code>, in this case the <code>self.chat_ended</code> variable.</p> <p>Sending information to a Workflow may not be the only action you want to do. You may also want to retrieve some information during its execution. Temporal provides this capability with <code>Queries</code>.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#retrieving-the-conversing-history","title":"Retrieving the conversing history","text":"<p>Implementing a Query is similar to implementing a Signal: You define a method and decorate it. However, the method can't be <code>async</code>, and the decorator is <code>@workflow.query</code>.</p> <p>Add the following Query to the bottom of your file, to retrieve the conversation history:</p> <pre><code>    @workflow.query\n    def get_conversation_history(self) -&gt; ConversationHistory:\n        \"\"\"Query handler to retrieve the full conversation history.\"\"\"\n        return self.conversation_history\n</code></pre> <p>This Query returns the current conversation history that is stored in the <code>self.conversation_history</code> instance variable.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#retrieving-the-latest-tool-data","title":"Retrieving the latest tool data","text":"<p>The final Query returns the latest tool data.</p> <p>Add the following code to the bottom of your file to implement it:</p> <pre><code>    @workflow.query\n    def get_latest_tool_data(self) -&gt; Optional[ToolData]:\n        \"\"\"Query handler to retrieve the latest tool data response if available.\"\"\"\n        return self.tool_data\n</code></pre> <p>This Query returns the current tool data, if available, that is stored in the <code>self.tool_data</code> instance variable.</p> <p>Your Workflow now has the necessary Signals and Queries for a client API to properly communicate with it and implement a user interface on top of it.</p>  The <code>workflows/agent_goal_workflow.py</code> is complete and will need no more revisions. You can review the complete file and copy the code here.   Hover your cursor over the code block to reveal the copy-code option.    [workflows/agent_goal_workflow.py](https://github.com/temporal-community/tutorial-temporal-ai-agent/blob/main/workflows/agent_goal_workflow.py)  <pre><code>from collections import deque\nfrom datetime import timedelta\nfrom typing import Any, Deque, Dict, Optional, Union\n\nfrom temporalio import workflow\nfrom temporalio.common import RetryPolicy\n\nfrom models.core import AgentGoal\nfrom models.requests import (\n    ConversationHistory,\n    CurrentTool,\n    EnvLookupInput,\n    EnvLookupOutput,\n    ToolData,\n    ValidationInput,\n)\nfrom workflows import workflow_helpers as helpers\nfrom workflows.workflow_helpers import (\n    LLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n    LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n)\n\nwith workflow.unsafe.imports_passed_through():\n    from activities.activities import AgentActivities\n    from models.requests import CombinedInput, ToolPromptInput\n    from prompts.agent_prompt_generators import generate_genai_prompt\n\n# Constants\nMAX_TURNS_BEFORE_CONTINUE = 250\n\n\n@workflow.defn\nclass AgentGoalWorkflow:\n    \"\"\"Workflow that manages tool execution with user confirmation and conversation history.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.conversation_history: ConversationHistory = {\"messages\": []}\n        self.prompt_queue: Deque[str] = deque()\n        self.chat_ended: bool = False\n        self.tool_data: Optional[ToolData] = None\n        self.goal: Optional[AgentGoal] = None\n        self.waiting_for_confirm: bool = False\n        self.show_tool_args_confirmation: bool = (\n            True  # set from env file in activity lookup_wf_env_settings\n        )\n        self.confirmed: bool = (\n            False  # indicates that we have confirmation to proceed to run tool\n        )\n\n    # see ../api/main.py#temporal_client.start_workflow() for how the input parameters are set\n    @workflow.run\n    async def run(self, combined_input: CombinedInput) -&gt; str:\n        \"\"\"Main workflow execution method.\"\"\"\n        # setup phase, starts with blank tool_params and agent_goal prompt as defined in tools/goal_registry.py\n        params = combined_input.tool_params\n        self.goal = combined_input.agent_goal\n\n        await self.lookup_wf_env_settings()\n\n        if params and params.prompt_queue:\n            self.prompt_queue.extend(params.prompt_queue)\n\n        current_tool: Optional[CurrentTool] = None\n\n        while True:\n            # wait indefinitely for input from signals - user_prompt, end_chat, or confirm as defined below\n            await workflow.wait_condition(\n                lambda: bool(self.prompt_queue) or self.chat_ended or self.confirmed\n            )\n\n            # handle chat should end. When chat ends, push conversation history to workflow results.\n            if self.chat_ended:\n                workflow.logger.info(\"Chat-end signal received. Chat ending.\")\n                return f\"{self.conversation_history}\"\n\n            # Execute the tool\n            if self.ready_for_tool_execution() and current_tool is not None:\n                await self.execute_tool(current_tool)\n                continue\n\n            # process forward on the prompt queue if any\n            if self.prompt_queue:\n                # get most recent prompt\n                prompt = self.prompt_queue.popleft()\n                workflow.logger.info(\n                    f\"workflow step: processing message on the prompt queue, message is {prompt}\"\n                )\n\n                # Validate user-provided prompts\n                if helpers.is_user_prompt(prompt):\n                    self.add_message(\"user\", prompt)\n\n                    # Validate the prompt before proceeding\n                    validation_input = ValidationInput(\n                        prompt=prompt,\n                        conversation_history=self.conversation_history,\n                        agent_goal=self.goal,\n                    )\n                    validation_result = await workflow.execute_activity_method(\n                        AgentActivities.agent_validatePrompt,\n                        args=[validation_input],\n                        schedule_to_close_timeout=LLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n                        start_to_close_timeout=LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n                        retry_policy=RetryPolicy(\n                            initial_interval=timedelta(seconds=5), backoff_coefficient=1\n                        ),\n                    )\n\n                    # If validation fails, provide that feedback to the user - i.e., \"your words make no sense, puny human\" end this iteration of processing\n                    if not validation_result.validationResult:\n                        workflow.logger.warning(\n                            f\"Prompt validation failed: {validation_result.validationFailedReason}\"\n                        )\n                        self.add_message(\n                            \"agent\", validation_result.validationFailedReason\n                        )\n                        continue\n\n                # If valid, proceed with generating the context and prompt\n                context_instructions = generate_genai_prompt(\n                    agent_goal=self.goal,\n                    conversation_history=self.conversation_history,\n                    raw_json=self.tool_data,\n                )\n\n                prompt_input = ToolPromptInput(\n                    prompt=prompt, context_instructions=context_instructions\n                )\n\n                # connect to LLM and execute to get next steps\n                tool_data = await workflow.execute_activity_method(\n                    AgentActivities.agent_toolPlanner,\n                    prompt_input,\n                    schedule_to_close_timeout=LLM_ACTIVITY_SCHEDULE_TO_CLOSE_TIMEOUT,\n                    start_to_close_timeout=LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n                    retry_policy=RetryPolicy(\n                        initial_interval=timedelta(seconds=5), backoff_coefficient=1\n                    ),\n                )\n\n                tool_data[\"force_confirm\"] = self.show_tool_args_confirmation\n                self.tool_data = ToolData(**tool_data)\n\n                # process the tool as dictated by the prompt response - what to do next, and with which tool\n                next_step = tool_data.get(\"next\")\n                current_tool: Optional[CurrentTool] = tool_data.get(\"tool\")\n\n                workflow.logger.info(\n                    f\"next_step: {next_step}, current tool is {current_tool}\"\n                )\n\n                # make sure we're ready to run the tool &amp; have everything we need\n                if next_step == \"confirm\" and current_tool:\n                    args = tool_data.get(\"args\", {})\n                    # if we're missing arguments, ask for them\n                    if await helpers.handle_missing_args(\n                        current_tool, args, tool_data, self.prompt_queue\n                    ):\n                        continue\n\n                    self.waiting_for_confirm = True\n\n                    # We have needed arguments, if we want to force the user to confirm, set that up\n                    if self.show_tool_args_confirmation:\n                        self.confirmed = False  # set that we're not confirmed\n                        workflow.logger.info(\"Waiting for user confirm signal...\")\n                    # if we have all needed arguments (handled above) and not holding for a debugging confirm, proceed:\n                    else:\n                        self.confirmed = True\n\n                # else if the next step is to be done with the conversation such as if the user requests it via asking to \"end conversation\"\n                elif next_step == \"done\":\n                    self.add_message(\"agent\", tool_data)\n\n                    # here we could send conversation to AI for analysis\n\n                    # end the workflow\n                    return str(self.conversation_history)\n\n                self.add_message(\"agent\", tool_data)\n                await helpers.continue_as_new_if_needed(\n                    self.conversation_history,\n                    self.prompt_queue,\n                    self.goal,\n                    MAX_TURNS_BEFORE_CONTINUE,\n                    self.add_message,\n                )\n\n    # look up env settings in an activity so they're part of history\n    async def lookup_wf_env_settings(self) -&gt; None:\n        env_lookup_input = EnvLookupInput(\n            show_confirm_env_var_name=\"SHOW_CONFIRM\",\n            show_confirm_default=True,\n        )\n        env_output: EnvLookupOutput = await workflow.execute_activity_method(\n            AgentActivities.get_wf_env_vars,\n            env_lookup_input,\n            start_to_close_timeout=LLM_ACTIVITY_START_TO_CLOSE_TIMEOUT,\n            retry_policy=RetryPolicy(\n                initial_interval=timedelta(seconds=5), backoff_coefficient=1\n            ),\n        )\n        self.show_tool_args_confirmation = env_output.show_confirm\n\n    # define if we're ready for tool execution\n    def ready_for_tool_execution(self) -&gt; bool:\n\n        return (\n            self.confirmed and self.waiting_for_confirm and self.tool_data is not None\n        )\n\n    # execute the tool - set self.waiting_for_confirm to False if we're not waiting for confirm anymore\n    # (always the case if it works successfully)\n    async def execute_tool(self, current_tool: CurrentTool) -&gt; None:\n        workflow.logger.info(\n            f\"workflow step: user has confirmed, executing the tool {current_tool}\"\n        )\n        self.confirmed = False\n        confirmed_tool_data = self.tool_data.copy()\n        confirmed_tool_data[\"next\"] = \"confirm\"\n        self.add_message(\"user_confirmed_tool_run\", confirmed_tool_data)\n\n        # execute the tool by key as defined in tools/__init__.py\n        await helpers.handle_tool_execution(\n            current_tool,\n            self.tool_data,\n            self.add_message,\n            self.prompt_queue,\n        )\n\n        self.waiting_for_confirm = False\n\n    def add_message(self, actor: str, response: Union[str, Dict[str, Any]]) -&gt; None:\n        \"\"\"Add a message to the conversation history.\n\n        Args:\n            actor: The entity that generated the message (e.g., \"user\", \"agent\")\n            response: The message content, either as a string or structured data\n        \"\"\"\n        if isinstance(response, dict):\n            response_str = str(response)\n            workflow.logger.debug(f\"Adding {actor} message: {response_str[:100]}...\")\n        else:\n            workflow.logger.debug(f\"Adding {actor} message: {response[:100]}...\")\n\n        self.conversation_history[\"messages\"].append(\n            {\"actor\": actor, \"response\": response}\n        )\n\n    # Signal that comes from api/main.py via a post to /send-prompt\n    @workflow.signal\n    async def user_prompt(self, prompt: str) -&gt; None:\n        \"\"\"Signal handler for receiving user prompts.\"\"\"\n        workflow.logger.info(f\"signal received: user_prompt, prompt is {prompt}\")\n        if self.chat_ended:\n            workflow.logger.info(f\"Message dropped due to chat closed: {prompt}\")\n            return\n        self.prompt_queue.append(prompt)\n\n    # Signal that comes from api/main.py via a post to /confirm\n    @workflow.signal\n    async def confirm(self) -&gt; None:\n        \"\"\"Signal handler for user confirmation of tool execution.\"\"\"\n        workflow.logger.info(\"Received user signal: confirmation\")\n        self.confirmed = True\n\n    # Signal that comes from api/main.py via a post to /end-chat\n    @workflow.signal\n    async def end_chat(self) -&gt; None:\n        \"\"\"Signal handler for ending the chat session.\"\"\"\n        workflow.logger.info(\"signal received: end_chat\")\n        self.chat_ended = True\n\n    @workflow.query\n    def get_conversation_history(self) -&gt; ConversationHistory:\n        \"\"\"Query handler to retrieve the full conversation history.\"\"\"\n        return self.conversation_history\n\n    @workflow.query\n    def get_latest_tool_data(self) -&gt; Optional[ToolData]:\n        \"\"\"Query handler to retrieve the latest tool data response if available.\"\"\"\n        return self.tool_data\n</code></pre> <p>This Workflow demonstrates the key patterns for building durable AI agents. It is event-driven, handling interactions with Signals and Queries, it validates user prompts and implements guardrails, it requires confirmation for tool execution, it maintains state and context across failures, and it's observable.  The duration of the Workflow Execution is irrelevant. Thanks to Temporal, the session could go on for minutes, hours, days, or even weeks.</p>  Before moving on to the next section, verify your files and directory structure is correct.  <pre><code>temporal-ai-agent/\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .python-version\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 uv.lock\n\u251c\u2500\u2500 activities/\n|   \u251c\u2500\u2500 __init__.py\n|   \u2514\u2500\u2500 activities.py\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 core.py\n\u2502   \u2514\u2500\u2500 requests.py\n\u251c\u2500\u2500 prompts/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 agent_prompt_generators.py\n\u2502   \u2514\u2500\u2500 prompts.py\n\u251c\u2500\u2500 scripts/\n\u2502   \u251c\u2500\u2500 create_invoice_test.py\n\u2502   \u251c\u2500\u2500 find_events_test.py\n\u2502   \u2514\u2500\u2500 search_flights_test.py\n\u251c\u2500\u2500 tools/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 create_invoice.py\n\u2502   \u251c\u2500\u2500 find_events.py\n\u2502   \u251c\u2500\u2500 goal_registry.py\n\u2502   \u251c\u2500\u2500 search_flights.py\n\u2502   \u251c\u2500\u2500 tool_registry.py\n\u2502   \u2514\u2500\u2500 data/\n|       \u2514\u2500\u2500 find_events_data.json\n\u2514\u2500\u2500 workflows/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 agent_goal_workflow.py\n    \u2514\u2500\u2500 workflow_helpers.py\n</code></pre> <p>In the next section, you will implement the Temporal Worker, which is responsible for executing your Workflow and Activities.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#building-the-temporal-worker","title":"Building the Temporal Worker","text":"<p>Temporal Workflows are not run by executing the <code>agent_goal_workflow.py</code> file. Workflows, Activities, Signal and Query handling, and all Temporal operations are handled by Temporal Workers.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#creating-the-temporal-client","title":"Creating the Temporal client","text":"<p>A Worker uses a Temporal client to communicate with the Temporal service to coordinate execution. A Temporal client is also used to request execution of Temporal Workflows. Since this application will require multiple Temporal clients, you will implement a <code>shared</code> submodule that others can call to create a Temporal client. This reduces the need for duplicate code and potentially incorrectly setting the Task Queue. </p> <p>First, create the <code>shared</code> directory and a blank <code>__init__.py</code> file to create the submodule:</p> <pre><code>mkdir shared\ntouch shared/__init__.py\n</code></pre> <p>Next, create the file <code>config.py</code> within the <code>shared</code> directory and add the following <code>import</code> statements:</p> <pre><code>import os\n\nfrom dotenv import load_dotenv\nfrom temporalio.client import Client\nfrom temporalio.service import TLSConfig\n</code></pre> <p>You'll then load in the environment variables you specified earlier.  If you are running this tutorial using the local development server, these are commented out in your <code>.env</code> file and will use the default settings.</p> <pre><code>load_dotenv(override=True)\n\n# Temporal connection settings\nTEMPORAL_ADDRESS = os.getenv(\"TEMPORAL_ADDRESS\", \"localhost:7233\")\nTEMPORAL_NAMESPACE = os.getenv(\"TEMPORAL_NAMESPACE\", \"default\")\nTEMPORAL_TASK_QUEUE = os.getenv(\"TEMPORAL_TASK_QUEUE\", \"agent-task-queue\")\n\n# Authentication settings\nTEMPORAL_TLS_CERT = os.getenv(\"TEMPORAL_TLS_CERT\", \"\")\nTEMPORAL_TLS_KEY = os.getenv(\"TEMPORAL_TLS_KEY\", \"\")\nTEMPORAL_API_KEY = os.getenv(\"TEMPORAL_API_KEY\", \"\")\n</code></pre> <p>Finally, add the code to configure a Temporal client:</p> <pre><code>async def get_temporal_client() -&gt; Client:\n    \"\"\"\n    Creates a Temporal client based on environment configuration.\n    Supports local server, mTLS, and API key authentication methods.\n    \"\"\"\n    # Default to no TLS for local development\n    tls_config = False\n    print(f\"Address: {TEMPORAL_ADDRESS}, Namespace {TEMPORAL_NAMESPACE}\")\n    print(\"(If unset, then will try to connect to local server)\")\n\n    # Configure mTLS if certificate and key are provided\n    if TEMPORAL_TLS_CERT and TEMPORAL_TLS_KEY:\n        print(f\"TLS cert: {TEMPORAL_TLS_CERT}\")\n        print(f\"TLS key: {TEMPORAL_TLS_KEY}\")\n        with open(TEMPORAL_TLS_CERT, \"rb\") as f:\n            client_cert = f.read()\n        with open(TEMPORAL_TLS_KEY, \"rb\") as f:\n            client_key = f.read()\n        tls_config = TLSConfig(\n            client_cert=client_cert,\n            client_private_key=client_key,\n        )\n\n    # Use API key authentication if provided\n    if TEMPORAL_API_KEY:\n        print(f\"API key: {TEMPORAL_API_KEY}\")\n        return await Client.connect(\n            TEMPORAL_ADDRESS,\n            namespace=TEMPORAL_NAMESPACE,\n            api_key=TEMPORAL_API_KEY,\n            tls=True,  # Always use TLS with API key\n        )\n\n    # Use mTLS or local connection\n    return await Client.connect(\n        TEMPORAL_ADDRESS,\n        namespace=TEMPORAL_NAMESPACE,\n        tls=tls_config,\n    )\n</code></pre> <p>This code checks whether or not you configured TLS certs for secure connection or a Temporal API key for connection to Temporal Cloud. It then returns a configured Temporal client, ready to communicate with the Temporal service.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#configuring-the-worker","title":"Configuring the Worker","text":"<p>Now that you have a reusable way of creating a Temporal client, you can use that to configure your Temporal Worker.</p> <p>Start by creating the <code>worker</code> directory:</p> <pre><code>mkdir worker\n</code></pre> <p>Then, create the file <code>worker.py</code> in the <code>worker</code> directory and add the following <code>import</code> statements:</p> <pre><code>import asyncio\nimport concurrent.futures\nimport logging\nimport os\n\nfrom dotenv import load_dotenv\nfrom temporalio.worker import Worker\n\nfrom activities.activities import AgentActivities, dynamic_tool_activity\nfrom shared.config import TEMPORAL_TASK_QUEUE, get_temporal_client\nfrom workflows.agent_goal_workflow import AgentGoalWorkflow\n</code></pre> <p>These <code>import</code> statements include libraries from the standard library, third-party packages such as <code>dotenv</code> and the <code>temporalio.worker</code> library, as well as a few of the libraries you implemented. A Worker must register the Workflows and Activities it intends to execute, so it must import them, as well as the function for creating the Temporal client.</p> <p>Next, create the <code>main</code> method and add the code responsible for initializing a few variables, including creating the Temporal client and creating an instance of your <code>AgentActivities</code> class.</p> <pre><code>async def main():\n    # Load environment variables\n    load_dotenv(override=True)\n\n    # Print LLM configuration info\n    llm_model = os.environ.get(\"LLM_MODEL\", \"openai/gpt-4\")\n    print(f\"Worker will use LLM model: {llm_model}\")\n\n    # Create the client\n    client = await get_temporal_client()\n\n    # Initialize the activities class\n    activities = AgentActivities()\n    print(f\"AgentActivities initialized with LLM model: {llm_model}\")\n\n    print(\"Worker ready to process tasks!\")\n    logging.basicConfig(level=logging.WARN)\n</code></pre> <p>This code loads the in the environment variables from your <code>.env</code> file. It uses the <code>LLM_MODEL</code> environment variable to print which model the agent will call, defaulting to OpenAI's GPT-4 if none is set. It then creates a Temporal client, and an instance of your <code>AgentActivities</code> class before setting the log level to <code>WARN</code>.</p> <p>Finally, add the code to configure and start your Worker:</p> <pre><code>    # Run the worker\n    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as activity_executor:\n        worker = Worker(\n            client,\n            task_queue=TEMPORAL_TASK_QUEUE,\n            workflows=[AgentGoalWorkflow],\n            activities=[\n                activities.agent_validatePrompt,\n                activities.agent_toolPlanner,\n                activities.get_wf_env_vars,\n                dynamic_tool_activity,\n            ],\n            activity_executor=activity_executor,\n        )\n\n        print(f\"Starting worker, connecting to task queue: {TEMPORAL_TASK_QUEUE}\")\n        print(\"Ready to begin processing...\")\n        await worker.run()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>The code creates a <code>ThreadPoolExecutor</code> for the Worker to use as the <code>activity_executor</code>. Since an agent's tools can be either <code>async</code> or not, you must use one of the synchronous safe methods for Activity execution. You can read more about this in the Python SDK documentation.</p> <p>Next, the Worker object is created, passing in the <code>client</code>, the <code>task_queue</code>, the <code>activity_executor</code>, and then registering the individual Workflows and Activities the Worker can execute. The Worker is then started with <code>await worker.run()</code>, which creates a long-running process that will poll the Temporal service, executing Workflow and Activities when they are requested.</p> <p>Finally, the standard <code>if __name__ == \"__main__\"</code> calls the main function when you run <code>worker.py</code>, starting the Worker.</p> <p>Now that you have implemented your Worker, verify that it runs.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#testing-the-worker","title":"Testing the Worker","text":"<p>Before starting the Worker, you need to start a Temporal service.  To start the local development server, open a terminal and run the following command:</p> <pre><code>temporal server start-dev\n</code></pre> <p>This starts a local Temporal service running on port 7233 with the web UI running on port 8233. The output of this command should resemble (The exact version numbers may not match):</p> <pre><code>CLI 1.1.1 (Server 1.25.1, UI 2.31.2)\n\nServer:  localhost:7233\nUI:      http://localhost:8233\nMetrics: http://localhost:53697/metrics\n</code></pre> <p>Next, open another terminal and run your Worker:</p> <pre><code>uv run worker/worker.py\n</code></pre> <p>Your Worker should start, and the output should be:</p> <pre><code>Worker will use LLM model: openai/gpt-4o\nAddress: localhost:7233, Namespace default\n(If unset, then will try to connect to local server)\nAgentActivities initialized with LLM model: openai/gpt-4o\nWorker ready to process tasks!\nStarting worker, connecting to task queue: agent-task-queue\nReady to begin processing...\n</code></pre> <p>The command will not exit, but will persist; this is expected. It is waiting for Workflows and Activity tasks to execute. If your Worker is running successfully, that's as much as you can test for the moment. Kill both the worker and Temporal service by pressing <code>CTRL-C</code> in each terminal.</p>  Before moving on to the next section, verify that your files and directory structure are correct.  <pre><code>temporal-ai-agent/\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .python-version\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 uv.lock\n\u251c\u2500\u2500 activities/\n|   \u251c\u2500\u2500 __init__.py\n|   \u2514\u2500\u2500 activities.py\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 core.py\n\u2502   \u2514\u2500\u2500 requests.py\n\u251c\u2500\u2500 prompts/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 agent_prompt_generators.py\n\u2502   \u2514\u2500\u2500 prompts.py\n\u251c\u2500\u2500 scripts/\n\u2502   \u251c\u2500\u2500 create_invoice_test.py\n\u2502   \u251c\u2500\u2500 find_events_test.py\n\u2502   \u2514\u2500\u2500 search_flights_test.py\n\u251c\u2500\u2500 tools/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 create_invoice.py\n\u2502   \u251c\u2500\u2500 find_events.py\n\u2502   \u251c\u2500\u2500 goal_registry.py\n\u2502   \u251c\u2500\u2500 search_flights.py\n\u2502   \u251c\u2500\u2500 tool_registry.py\n\u2502   \u2514\u2500\u2500 data/\n|       \u2514\u2500\u2500 find_events_data.json\n\u251c\u2500\u2500 worker/\n\u2502   \u2514\u2500\u2500 worker.py\n\u2514\u2500\u2500 workflows/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 agent_goal_workflow.py\n    \u2514\u2500\u2500 workflow_helpers.py\n</code></pre> <p>Next, you will implement a REST API that will serve as the backend service for invoking your agent.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#building-a-rest-api-for-interacting-with-your-agent","title":"Building a REST API for interacting with your agent","text":"<p>Now that you have your agent implemented, you need a way for client applications to interact with it.  Temporal provides client libraries, but having an API to manage invoking a Workflow, sending Signals and Queries, and managing various Workflow Executions is a typical pattern for managing Temporal Workflows.</p> <p>In this step, you will create a backend API that will serve as the interface for interacting with your agent.  You'll use the FastAPI framework to build this. FastAPI is a great choice to pair with Temporal, as it's an async Python backend that supports type hints.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#setting-up-the-fastapi-application","title":"Setting up the FastAPI application","text":"<p>First, create the directory structure for your FastAPI application:</p> <pre><code>mkdir api\n</code></pre> <p>Next, create the API file at <code>api/main.py</code> and include the following <code>import</code> statements:</p> <pre><code>import asyncio\nfrom collections import deque\nfrom contextlib import asynccontextmanager\nfrom typing import Dict, Optional\n\nfrom dotenv import load_dotenv\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom temporalio.api.enums.v1 import WorkflowExecutionStatus\nfrom temporalio.client import Client\nfrom temporalio.exceptions import TemporalError\n\nfrom models.requests import AgentGoalWorkflowParams, CombinedInput, ConversationHistory\nfrom shared.config import TEMPORAL_TASK_QUEUE, get_temporal_client\nfrom tools.goal_registry import goal_event_flight_invoice\nfrom workflows.agent_goal_workflow import AgentGoalWorkflow\n</code></pre> <p>This imports various packages from the standard library, third-party libraries including FastAPI and Temporal, and a few of your custom libraries. The API imported the <code>AgentGoalWorkflow</code> so it can invoke it, the <code>goal_event_flight_invoice</code> for specification of the goal, the <code>get_temporal_client</code> function and <code>TEMPORAL_TASK_QUEUE</code> constant for communicating with the Temporal service, and a few of your custom types for proper communication with the Workflow.</p> <p>Next, add the code to configure and instantiate the FastAPI object:</p> <pre><code>temporal_client: Optional[Client] = None\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    global temporal_client\n    # Create the Temporal client\n    temporal_client = await get_temporal_client()\n    yield\n\n\napp = FastAPI(lifespan=lifespan)\n\n# Load environment variables\nload_dotenv()\n\nAGENT_GOAL = goal_event_flight_invoice\n</code></pre> <p>This creates a Temporal client, then uses the <code>lifespan</code> function to call the <code>get_temporal_client</code> function. The <code>lifespan</code> function, paired with the <code>@asynccontextmanager</code> decorator defines a context manager that defines startup and shutdown behavior for your FastAPI app. Next, it creates the FastAPI app, passing in the <code>lifespan</code> as a parameter. Finally, you load in the environment variables and specify the <code>AGENT_GOAL</code> to <code>goal_event_flight_invoice</code>.</p> <p>Next, add the appropriate middleware for handling CORS and define the root handler for your app:</p> <pre><code>app.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:5173\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n\n@app.get(\"/\")\ndef root() -&gt; Dict[str, str]:\n    return {\"message\": \"Temporal AI Agent!\"}\n</code></pre> <p>The CORS settings are set up to allow for access from an origin  Any request to the root of your application will return JSON with a single key and a message.</p> <p>Before moving on, test your FastAPI app by running the following commands:</p> <p>In one terminal, start your Temporal development server:</p> <pre><code>temporal server start-dev\n</code></pre> <p>This starts a local Temporal service running on port 7233 with the web UI running on port 8233. The output of this command should resemble (The exact version numbers may not match):</p> <pre><code>CLI 1.1.1 (Server 1.25.1, UI 2.31.2)\n\nServer:  localhost:7233\nUI:      http://localhost:8233\nMetrics: http://localhost:53697/metrics\n</code></pre> <p>In another terminal, start the API using <code>uv</code> from the root of your project:</p> <pre><code>uv run uvicorn api.main:app --reload\n</code></pre> <p>This uses <code>uvicorn</code>, an ASGI server to run the FastAPI app and auto reload the app if any changes are detected.</p> <p>The output of this command should resemble:</p> <pre><code>INFO:     Will watch for changes in these directories: ['/Users/ziggy/temporal-ai-agent']\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\nINFO:     Started reloader process [31826] using StatReload\nINFO:     Started server process [31828]\nINFO:     Waiting for application startup.\nAddress: localhost:7233, Namespace default\n(If unset, then will try to connect to local server)\nINFO:     Application startup complete.\n</code></pre> <p>Next, test your application is working by sending a request to it:</p> <pre><code>curl localhost:8000\n</code></pre> <p>Your response should be:</p> <pre><code>{\"message\":\"Temporal AI Agent!\"}\n</code></pre> <p>Now that you have the base FastAPI application configured with a Temporal client, you will implement the functions to interact with your agent Workflow.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#implementing-agent-workflow-endpoints","title":"Implementing agent Workflow endpoints","text":"<p>Your API only needs a few endpoints to communicate with the agent. You will implement the functionality to send Signals, get the conversation history, and start the Workflow.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#validating-the-temporal-client","title":"Validating the Temporal client","text":"<p>Every function will use the same Temporal client. First, you will implement a helper function to verify the client is set up correctly.</p> <p>Add the following function to your <code>main.py</code> file:</p> <pre><code>def _ensure_temporal_client() -&gt; Client:\n    \"\"\"Ensure temporal client is initialized and return it.\n\n    Returns:\n        TemporalClient: The initialized temporal client.\n\n    Raises:\n        HTTPException: If client is not initialized.\n    \"\"\"\n    if temporal_client is None:\n        raise HTTPException(status_code=500, detail=\"Temporal client not initialized\")\n    return temporal_client\n</code></pre> <p>This function ensures the global Temporal client is not <code>None</code>. If it isn't, the function returns the client. If it is <code>None</code>, it will raise an exception. This is a type-safe way of validating the client before every function call.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#starting-the-agent-workflow","title":"Starting the agent Workflow","text":"<p>Next, you'll define an endpoint that a client will use to start the agent Workflow. This endpoint is a POST endpoint, and doesn't take any parameters.</p> <p>Add the endpoint to your <code>api.py</code> file:</p> <pre><code>@app.post(\"/start-workflow\")\nasync def start_workflow() -&gt; Dict[str, str]:\n    \"\"\"Start the AgentGoalWorkflow\"\"\"\n    temporal_client = _ensure_temporal_client()\n\n    # Create combined input\n    combined_input = CombinedInput(\n        tool_params=AgentGoalWorkflowParams(\n            None, deque([f\"### {AGENT_GOAL.starter_prompt}\"])\n        ),\n        agent_goal=AGENT_GOAL,\n    )\n\n    workflow_id = \"agent-workflow\"\n\n    # Start the workflow with the starter prompt from the goal\n    await temporal_client.start_workflow(\n        AgentGoalWorkflow.run,\n        combined_input,\n        id=workflow_id,\n        task_queue=TEMPORAL_TASK_QUEUE,\n    )\n\n    return {\n        \"message\": f\"Workflow started with goal's starter prompt: {AGENT_GOAL.starter_prompt}.\"\n    }\n</code></pre> <p>The code verifies the Temporal client, then creates a <code>CombinedInput</code> type containing an <code>AgentGoalWorkflowParams</code> object and the <code>AGENT_GOAL</code>. The <code>AgentGoalWorkflowParams</code> object assigns <code>None</code> to its first attribute, which represents the conversation history. This is fine, as there is currently no conversation history. The second attribute is the first prompt the agent will execute. You then specify the <code>workflow_id</code> that will identify the execution, in this case it is hard coded to <code>agent-workflow</code>. Finally, you start the Workflow asynchronously using <code>temporal.client.start_workflow</code>, specifying the Workflow method <code>AgentGoalWorkflow.run</code>, the parameter <code>combined_input</code>, <code>workflow_id</code>, and <code>task_queue</code>.</p> <p>The function then returns with a message stating that the Workflow has started.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#sending-a-user-prompt-to-the-workflow","title":"Sending a user prompt to the Workflow","text":"<p>Now you'll implement sending the user's prompt to the Workflow. The user will interact with the chatbot interface, sending messages to the agent. The chatbot sends these as Signals to the <code>user_prompt</code> Signal handler you defined in your Workflow.</p> <p>Add the following code to send the user's prompt to the Workflow:</p> <pre><code>@app.post(\"/send-prompt\")\nasync def send_prompt(prompt: str) -&gt; Dict[str, str]:\n    \"\"\"Sends the user prompt to the Workflow\"\"\"\n    temporal_client = _ensure_temporal_client()\n\n    workflow_id = \"agent-workflow\"\n    handle = temporal_client.get_workflow_handle(workflow_id)\n    await handle.signal(\"user_prompt\", prompt)\n\n    return {\"message\": f\"Prompt '{prompt}' sent to workflow {workflow_id}.\"}\n</code></pre> <p>This code identifies the Workflow Execution by its <code>workflow_id</code>, and sends the user's prompts sent to the API as Signals to that Workflow Execution.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#sending-a-confirmation-to-the-workflow","title":"Sending a confirmation to the Workflow","text":"<p>If you have the <code>SHOW_CONFIRM</code> option set in your <code>.env</code> file, then the user must confirm the tool before it is executed. This choice is sent to the workflow via a Signal. You already implemented the Signal handler in the Workflow, now you will implement sending the Signal.</p> <p>Add the following code to send the <code>confirm</code> Signal:</p> <pre><code>@app.post(\"/confirm\")\nasync def send_confirm() -&gt; Dict[str, str]:\n    \"\"\"Sends a 'confirm' signal to the workflow.\"\"\"\n    temporal_client = _ensure_temporal_client()\n\n    workflow_id = \"agent-workflow\"\n    handle = temporal_client.get_workflow_handle(workflow_id)\n    await handle.signal(\"confirm\")\n    return {\"message\": \"Confirm signal sent.\"}\n</code></pre> <p>This code identifies the Workflow Execution by its <code>workflow_id</code>, and sends the Signals sent to the API to that Workflow Execution.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#ending-the-chat_1","title":"Ending the chat","text":"<p>Finally, the user can choose to end the chat at any time by saying something along the lines of \"end conversation.\" You also implemented this Signal handler in your Workflow, so now you'll implement the sending of the Signal.</p> <p>Add the following code:</p> <pre><code>@app.post(\"/end-chat\")\nasync def end_chat() -&gt; Dict[str, str]:\n    \"\"\"Sends a 'end_chat' signal to the workflow.\"\"\"\n    temporal_client = _ensure_temporal_client()\n\n    workflow_id = \"agent-workflow\"\n    handle = temporal_client.get_workflow_handle(workflow_id)\n    await handle.signal(\"end_chat\")\n    return {\"message\": \"End chat signal sent.\"}\n</code></pre> <p>This code identifies the Workflow Execution by its <code>workflow_id</code>, and sends the Signals sent to the API to that Workflow Execution.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#retrieving-the-conversation-history","title":"Retrieving the conversation history","text":"<p>The last API endpoint you must implement retrieves the conversation history. The UI uses this to populate the interface for the user to read. This API will perform a Query and retrieve the information from the running Workflow Execution.</p> <p>Add the following code to implement the endpoint:</p> <pre><code>@app.get(\"/get-conversation-history\")\nasync def get_conversation_history() -&gt; ConversationHistory:\n    \"\"\"Calls the workflow's 'get_conversation_history' query.\"\"\"\n\n    temporal_client = _ensure_temporal_client()\n\n    try:\n        handle = temporal_client.get_workflow_handle(\"agent-workflow\")\n\n        failed_states = [\n            WorkflowExecutionStatus.WORKFLOW_EXECUTION_STATUS_TERMINATED,\n            WorkflowExecutionStatus.WORKFLOW_EXECUTION_STATUS_CANCELED,\n            WorkflowExecutionStatus.WORKFLOW_EXECUTION_STATUS_FAILED,\n        ]\n\n        description = await handle.describe()\n        if description.status in failed_states:\n            print(\"Workflow is in a failed state. Returning empty history.\")\n            return []\n\n        # Set a timeout for the query\n        try:\n            conversation_history = await asyncio.wait_for(\n                handle.query(\"get_conversation_history\"),\n                timeout=5,  # Timeout after 5 seconds\n            )\n            return conversation_history\n        except asyncio.TimeoutError:\n            raise HTTPException(\n                status_code=404,\n                detail=\"Temporal query timed out (worker may be unavailable).\",\n            )\n\n    except TemporalError as e:\n        error_message = str(e)\n        print(f\"Temporal error: {error_message}\")\n\n        # If worker is down or no poller is available, return a 404\n        if \"no poller seen for task queue recently\" in error_message:\n            raise HTTPException(\n                status_code=404, detail=\"Workflow worker unavailable or not found.\"\n            )\n\n        if \"workflow not found\" in error_message:\n            await start_workflow()\n            return []\n        else:\n            # For other Temporal errors, return a 500\n            raise HTTPException(\n                status_code=500, detail=\"Internal server error while querying workflow.\"\n            )\n</code></pre> <p>This function identifies the Workflow by its Workflow ID, then checks the Workflow Execution's status, making sure it isn't in a failed state. It then performs the Query, setting a timeout of five seconds, handling various errors as they may occur. If the Workflow Execution isn't found however, the endpoint will actually kick it off.</p>  The <code>api/main.py</code> is complete and will need no more revisions. You can review the complete file and copy the code here   [api/main.py](https://github.com/temporal-community/tutorial-temporal-ai-agent/blob/main/api/main.py)  <pre><code>import asyncio\nfrom collections import deque\nfrom contextlib import asynccontextmanager\nfrom typing import Dict, Optional\n\nfrom dotenv import load_dotenv\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom temporalio.api.enums.v1 import WorkflowExecutionStatus\nfrom temporalio.client import Client\nfrom temporalio.exceptions import TemporalError\n\nfrom models.requests import AgentGoalWorkflowParams, CombinedInput, ConversationHistory\nfrom shared.config import TEMPORAL_TASK_QUEUE, get_temporal_client\nfrom tools.goal_registry import goal_event_flight_invoice\nfrom workflows.agent_goal_workflow import AgentGoalWorkflow\n\ntemporal_client: Optional[Client] = None\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    global temporal_client\n    # Create the Temporal client\n    temporal_client = await get_temporal_client()\n    yield\n\n\napp = FastAPI(lifespan=lifespan)\n\n# Load environment variables\nload_dotenv()\n\nAGENT_GOAL = goal_event_flight_invoice\n\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:5173\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n\n@app.get(\"/\")\ndef root() -&gt; Dict[str, str]:\n    return {\"message\": \"Temporal AI Agent!\"}\n\n\ndef _ensure_temporal_client() -&gt; Client:\n    \"\"\"Ensure temporal client is initialized and return it.\n\n    Returns:\n        TemporalClient: The initialized temporal client.\n\n    Raises:\n        HTTPException: If client is not initialized.\n    \"\"\"\n    if temporal_client is None:\n        raise HTTPException(status_code=500, detail=\"Temporal client not initialized\")\n    return temporal_client\n\n\n@app.post(\"/start-workflow\")\nasync def start_workflow() -&gt; Dict[str, str]:\n    \"\"\"Start the AgentGoalWorkflow\"\"\"\n    temporal_client = _ensure_temporal_client()\n\n    # Create combined input\n    combined_input = CombinedInput(\n        tool_params=AgentGoalWorkflowParams(\n            None, deque([f\"### {AGENT_GOAL.starter_prompt}\"])\n        ),\n        agent_goal=AGENT_GOAL,\n    )\n\n    workflow_id = \"agent-workflow\"\n\n    # Start the workflow with the starter prompt from the goal\n    await temporal_client.start_workflow(\n        AgentGoalWorkflow.run,\n        combined_input,\n        id=workflow_id,\n        task_queue=TEMPORAL_TASK_QUEUE,\n    )\n\n    return {\n        \"message\": f\"Workflow started with goal's starter prompt: {AGENT_GOAL.starter_prompt}.\"\n    }\n\n\n@app.post(\"/send-prompt\")\nasync def send_prompt(prompt: str) -&gt; Dict[str, str]:\n    \"\"\"Sends the user prompt to the Workflow\"\"\"\n    temporal_client = _ensure_temporal_client()\n\n    workflow_id = \"agent-workflow\"\n    handle = temporal_client.get_workflow_handle(workflow_id)\n    await handle.signal(\"user_prompt\", prompt)\n\n    return {\"message\": f\"Prompt '{prompt}' sent to workflow {workflow_id}.\"}\n\n\n@app.post(\"/confirm\")\nasync def send_confirm() -&gt; Dict[str, str]:\n    \"\"\"Sends a 'confirm' signal to the workflow.\"\"\"\n    temporal_client = _ensure_temporal_client()\n\n    workflow_id = \"agent-workflow\"\n    handle = temporal_client.get_workflow_handle(workflow_id)\n    await handle.signal(\"confirm\")\n    return {\"message\": \"Confirm signal sent.\"}\n\n\n@app.post(\"/end-chat\")\nasync def end_chat() -&gt; Dict[str, str]:\n    \"\"\"Sends a 'end_chat' signal to the workflow.\"\"\"\n    temporal_client = _ensure_temporal_client()\n\n    workflow_id = \"agent-workflow\"\n    handle = temporal_client.get_workflow_handle(workflow_id)\n    await handle.signal(\"end_chat\")\n    return {\"message\": \"End chat signal sent.\"}\n\n\n@app.get(\"/get-conversation-history\")\nasync def get_conversation_history() -&gt; ConversationHistory:\n    \"\"\"Calls the workflow's 'get_conversation_history' query.\"\"\"\n\n    temporal_client = _ensure_temporal_client()\n\n    try:\n        handle = temporal_client.get_workflow_handle(\"agent-workflow\")\n\n        failed_states = [\n            WorkflowExecutionStatus.WORKFLOW_EXECUTION_STATUS_TERMINATED,\n            WorkflowExecutionStatus.WORKFLOW_EXECUTION_STATUS_CANCELED,\n            WorkflowExecutionStatus.WORKFLOW_EXECUTION_STATUS_FAILED,\n        ]\n\n        description = await handle.describe()\n        if description.status in failed_states:\n            print(\"Workflow is in a failed state. Returning empty history.\")\n            return []\n\n        # Set a timeout for the query\n        try:\n            conversation_history = await asyncio.wait_for(\n                handle.query(\"get_conversation_history\"),\n                timeout=5,  # Timeout after 5 seconds\n            )\n            return conversation_history\n        except asyncio.TimeoutError:\n            raise HTTPException(\n                status_code=404,\n                detail=\"Temporal query timed out (worker may be unavailable).\",\n            )\n\n    except TemporalError as e:\n        error_message = str(e)\n        print(f\"Temporal error: {error_message}\")\n\n        # If worker is down or no poller is available, return a 404\n        if \"no poller seen for task queue recently\" in error_message:\n            raise HTTPException(\n                status_code=404, detail=\"Workflow worker unavailable or not found.\"\n            )\n\n        if \"workflow not found\" in error_message:\n            await start_workflow()\n            return []\n        else:\n            # For other Temporal errors, return a 500\n            raise HTTPException(\n                status_code=500, detail=\"Internal server error while querying workflow.\"\n            )\n</code></pre> <p>You just implemented an API allowing client programs to interact with your agent.</p>  Before moving on to the next section, verify your files and directory structure is correct.  <pre><code>temporal-ai-agent/\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .python-version\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 uv.lock\n\u251c\u2500\u2500 activities/\n|   \u251c\u2500\u2500 __init__.py\n|   \u2514\u2500\u2500 activities.py\n\u251c\u2500\u2500 api/\n\u2502   \u2514\u2500\u2500 main.py\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 core.py\n\u2502   \u2514\u2500\u2500 requests.py\n\u251c\u2500\u2500 prompts/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 agent_prompt_generators.py\n\u2502   \u2514\u2500\u2500 prompts.py\n\u251c\u2500\u2500 scripts/\n\u2502   \u251c\u2500\u2500 create_invoice_test.py\n\u2502   \u251c\u2500\u2500 find_events_test.py\n\u2502   \u2514\u2500\u2500 search_flights_test.py\n\u251c\u2500\u2500 tools/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 create_invoice.py\n\u2502   \u251c\u2500\u2500 find_events.py\n\u2502   \u251c\u2500\u2500 goal_registry.py\n\u2502   \u251c\u2500\u2500 search_flights.py\n\u2502   \u251c\u2500\u2500 tool_registry.py\n\u2502   \u2514\u2500\u2500 data/\n|       \u2514\u2500\u2500 find_events_data.json\n\u251c\u2500\u2500 worker/\n\u2502   \u2514\u2500\u2500 worker.py\n\u2514\u2500\u2500 workflows/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 agent_goal_workflow.py\n    \u2514\u2500\u2500 workflow_helpers.py\n</code></pre> <p>In the next step, you will test your agent using a chatbot web interface.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#running-your-agent","title":"Running your agent","text":"<p>Now that you have implemented a mechanism of communication for your agent, it's time to test it. You will now download a React frontend that implements a chatbot UI to interact with your agent. The UI will open in a terminal window and prompt the user with a message stating their purpose and instructing the user what to do next. Throughout the conversation, the user will interact with the agent, responding to questions from the agent as the agent tries to accomplish its goal.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#adding-a-chatbot-web-ui","title":"Adding a Chatbot Web UI","text":"<p>To get started, download the pre-built React based web UI:</p> <pre><code>curl -o frontend.zip https://raw.githubusercontent.com/temporal-community/tutorial-temporal-ai-agent/main/frontend.zip\n</code></pre> <p>Once downloaded, extract the files from the zip to your root directory. You can do this with your OS's tool, or with a command line tool like <code>unzip</code>:</p> <pre><code>unzip frontend.zip\n</code></pre> <p>Next, change directories into the <code>frontend</code> directory that was just extracted and install the packages to run the UI:</p> <pre><code>cd frontend\nnpm install\n</code></pre> <p>Once the packages are finished installing, the web UI is ready to interact with your API.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#starting-your-agent","title":"Starting Your Agent","text":"<p>You now have assembled all the pieces to run the agent to completion. Running the agent requires a minimum of four different terminals, however there will only be one Worker process running. You can either open multiple terminals, or use a terminal multiplexer like <code>screen</code> or <code>tmux</code>. This tutorial can function with a single Worker. However, as with all real-world Temporal deployments, it is always better to run multiple Workers for scaling and redundancy.\"</p> <p>The first requirement is running a local Temporal server that coordinates workflow execution and provides durability guarantees.</p> <p>In the first terminal, start the development server:</p> <pre><code>temporal server start-dev\n</code></pre> <p>This starts a local Temporal service running on port 7233 with the web UI running on port 8233. The output of this command should resemble (The exact version numbers may not match):</p> <pre><code>CLI 1.1.1 (Server 1.25.1, UI 2.31.2)\n\nServer:  localhost:7233\nUI:      http://localhost:8233\nMetrics: http://localhost:53697/metrics\n</code></pre> <p>In the second terminal, start your Worker:</p> <pre><code>uv run worker/worker.py\n</code></pre> <p>You should see the following output output:</p> <pre><code>Worker will use LLM model: openai/gpt-4o\nAddress: localhost:7233, Namespace default\n(If unset, then will try to connect to local server)\nAgentActivities initialized with LLM model: openai/gpt-4o\nWorker ready to process tasks!\nStarting worker, connecting to task queue: agent-task-queue\nReady to begin processing...\n</code></pre> <p>If you are able, running a second Worker in another terminal is recommended using the steps above.</p> <p>Next, open another terminal and run the FastAPI application:</p> <pre><code>uv run uvicorn api.main:app --reload\n</code></pre> <p>This uses <code>uvicorn</code>, an ASGI server to run the FastAPI app and auto-reload the app if any changes are detected.</p> <p>The output of this command should resemble:</p> <pre><code>INFO:     Will watch for changes in these directories: ['/Users/ziggy/temporal-ai-agent']\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\nINFO:     Started reloader process [31826] using StatReload\nINFO:     Started server process [31828]\nINFO:     Waiting for application startup.\nAddress: localhost:7233, Namespace default\n(If unset, then will try to connect to local server)\nINFO:     Application startup complete.\n</code></pre> <p>Finally, open the last new terminal, change directories into the <code>frontend</code> directory and start the web UI:</p> <pre><code>cd frontend\nnpx vite\n</code></pre> <p>You will see output to your terminal, and then your web browser will open to <code>localhost:5173</code> with your agent running.</p> <p>Note</p> <p>When first starting the web UI, you may see a red error banner appear upon startup with a message about timeouts. This is expected, as the UI begins polling immediately before the Workflow may begin. This will go away within a few seconds once the Workflow Execution has started and the first message from the agent appears.</p> <p>Finally, open a new browser tab and navigate to <code>localhost:8233</code>. This will display the Temporal Web UI. You should see a running Workflow Execution there with the Workflow ID agent-workflow. Click on the link to open it so you can watch the Workflow progress as you run test your agent.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#testing-the-complete-system","title":"Testing the complete system","text":"<p>With all components running, you can now test the agent Workflow.</p> <p>Navigate back to <code>localhost:5173</code>. You should see a message similar to the following. Remember, the agent's responses are powered by an LLM, so the responses are non-deterministic, meaning they are likely to be slightly different every time.</p> <pre><code>Agent: Welcome! I'm here to help you plan your travel to events in North America. \nI can assist you in finding events, booking flights, and generating invoices for your trip. \nTo get started, please tell me which city and month you're interested in traveling to?\n</code></pre> <p>Test the conversation by responding with a city you'd like to travel to and the month you want to travel:</p> <pre><code>You: I'd like to see events in San Francisco in March\n</code></pre> <p>The agent will process receive your prompt and use the LLM to determine the next step:</p> <pre><code>Agent: Let's proceed with finding events in San Francisco in March.\n</code></pre> <p>It will determine that it should use the <code>FindEvents</code> tool and search for events.</p> <p>Note</p> <p>If you have the <code>SHOW_CONFIRM</code> environment variable set to <code>True</code>, the UI will prompt you to confirm execution of this tool and all future tool executions. By default this is enabled, so you will need to confirm the execution.</p> <p>Once you have confirmed the tool execution, the agent executes the tool and provides events for you to choose from:</p> <pre><code>Agent: I found a couple of events in San Francisco:\n1. Lunar New Year Festival &amp; Parade from February 8 to February 22, 2026\n2. San Francisco International Film Festival from April 17 to May 1, 2026\nWould you like to search for flights to attend any of these events? If so, please provide your departure city.\n</code></pre> <p>You can then respond with which event you'd like to attend:</p> <pre><code>You: I would like to attend the San Francisco International Film Festival\n</code></pre> <p>However, you forgot to provide the departure city here, which the agent recognized and then prompted you for again.</p> <pre><code>Agent: Great choice! The San Francisco International Film Festival is from April 17 to May 1, 2026. \nPlease provide your departure city so I can search for flights.\n</code></pre> <p>Thinking about lunch, you accidentally input your lunch order into the chatbot:</p> <pre><code>I would like to order two double cheeseburgers.\n</code></pre> <p>The agent's guardrails recognize this isn't valid for its goal, so it informs you and prompts you to enter your departure city.</p> <pre><code>Agent: Your request to order two double cheeseburgers doesn't align with our current goal. \nWe're working on organizing a trip for you to attend the San Francisco International Film Festival. \nTo proceed, please let me know your departure city so I can search for flights for your trip.\n</code></pre> <p>You then provide it with your departure city:</p> <pre><code>You: I'm sorry. I'd like to depart from Austin, TX\n</code></pre> <p>The agent now has the information it needs, and can move on to the next step. However, it may decide to confirm with you again to ensure that's what you meant.</p> <pre><code>Agent: Thanks! You're departing from Austin, TX. \nWould you like to proceed with searching for flights from Austin to San Francisco for the San Francisco International Film Festival?\n</code></pre> <p>To which you should either confirm or deny. In this instance, confirm:</p> <pre><code>You: Yes\n</code></pre> <p>This extra confirmation step may not always happen. It depends if the LLM decides to verify.</p> <p>However, it is now satisfied and is ready to execute the next tool. This is evident because after this response, you are asked to confirm execution for the <code>SearchFlights</code> tool:</p> <pre><code>Agent: Let's proceed with searching for flights from Austin, TX (AUS) to San Francisco (SFO) around the dates of April 17 to May 1, 2026.\n</code></pre> <p>After you confirm the tool usage, the agent then executes the tool, searching for flights to your destination. </p> <p>Note</p> <p>If you have supplied a RAPIDAPI key, this will make a call to a microservice to check for real flight data. If the API returns multiple times with an error or no flights, this is the external API being unreliable and returning sporadic error messages. To alleviate this, use the mocked function instead.</p> <p>Once the agent finds flight options, it will present them to you, allowing you to select a flight if there are multiple. It will prompt you if you would like to create an invoice for the flight:</p> <pre><code>Agent: \nI found the cheapest flight with Southwest Airlines for $149.75. \nWould you like to create an invoice for this flight?\n</code></pre> <p>To which you confirm:</p> <pre><code>You: Yes\n</code></pre> <p>And the agent will proceed with creating an invoice, prompting the user to allow the execution of the <code>CreateInvoice</code> tool:</p> <pre><code>Agent: Let's proceed with creating an invoice for the Southwest Airlines flight.\n</code></pre> <p>The agent then creates the invoice, the goal is complete, and the chat is over.</p> <pre><code>Agent: Invoice generated successfully! \nYou can view and pay your invoice at: https://pay.example.com/invoice/12345. \nYour reference number is INV-12345. If you need further assistance, feel free to ask.\n</code></pre> <p>Note</p> <p>If you set a <code>STRIPE_API_KEY</code> environment variable in your <code>.env</code> file, the tool will use the Stripe API to create an invoice in your Stripe environment. Otherwise, it will create a pseudo link.</p> <p>Now that the chat is over, the Workflow Execution is over. You can start another chat session by clicking the Start New Chat button in the web UI, which will start a new Workflow Execution.</p> <p>Next, you'll examine the Event History of your most recent chat session.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#tracing-the-workflow-execution-in-the-web-ui","title":"Tracing the Workflow Execution in the Web UI","text":"<p>One of the features of Temporal is the observability that you gain via the Temporal Web UI. This is made possible since every event is stored, along with the inputs and output of Workflows, Activities, and other Temporal operations. </p> <p>Open the Temporal Web UI at <code>http://localhost:8233</code> and navigate to your most recent run.</p> <p>Your UI may not look exactly like the screenshots below due to differing UI versions, varying output from LLMs, and different user inputs. This is fine; the core concepts are still applicable.</p> <p>Navigate to the Workflows page to see your past agent Workflow Executions.  This is also the default landing page.</p> <p></p> <p>You will see all of your completed and currently running chat sessions here.  Click on the Workflow ID link agent-workflow of the most recently completed execution to see the details about that specific execution.</p> <p>At the top, you'll see the summary for the Workflow Execution. This contains information such as the duration of the execution, when it started, when it ended, what Task Queue it used, the size of the history, and the Workflow Type. All of this information an also be pieced together throughout the Event History, the Summary section provides an easier way to find it.</p> <p></p> <p>Next is the Input and Result section. Here you can see the initial input to the Workflow, and the final result that the agent returned in JSON format.</p> <p></p> <p>Below that is the Event History timeline. This is a time-based representation of every event that occurred during the execution of the Workflow.</p> <p></p> <p>Each individual event in this timeline is expandable. You can click on it and view the details for the event. For example, if you click on a purple Signal icon, you can see the Signal name, the identity of the Worker that processed it, and the input. </p> <p></p> <p>Other events will contain other information. Activities will contain information regarding the timeouts, retry policies, and input and results.</p> <p>Finally, you have the list version of the Event History. Everything that is recorded above is derived from this history.  You can click into each individual event and see all the information about a single event. Certain events, such as Activities, that typically come in a group, will be automatically paired for concise viewing as shown below.</p> <p></p> <p>You can also use this UI live. During a running Workflow Execution, you can watch live updates as you interact with your chatbot, and see the events come in to the timeline and list views. If you'd like, run another session of your chatbot and have the web UI open in a separate browser tab on another window so you can witness this.</p> <p>Next, you'll explore a few testing scenarios for demonstrating how Temporal adds durability to your agent.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#optional-witnessing-the-durability-of-the-agent","title":"(Optional) Witnessing the Durability of the Agent","text":"<p>Building your agent with Temporal adds durability to your agent. This means that your agent can withstand failures that traditional applications wouldn't be able to, such as internet outages or process crashes. Perform the following scenarios to witness the durability Temporal provides.</p> <p>The following scenario is a simulation of one engineer's very bad day at work. Follow along and see how Temporal mitigated potentially outage level issues.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#part-1-terminating-the-worker","title":"Part 1: Terminating the Worker","text":"<p>Scenario: Your agent is deployed to production. You have a chat session running, and a Worker is processing your Workflow. Suddenly, the virtual machine hosting your Worker is rebooted for updates. The Worker is forcefully terminated and progress appears lost. What happens?</p> <p>Simulating this scenario:</p> <ol> <li>Ensure your Temporal development server, Worker (be sure you only have one running), API, and web UI are running.</li> <li>Start a new chat session.</li> <li>Before typing anything in the chat, kill the Worker using <code>CTRL-C</code>.</li> <li>Type a city and month in the chat, and press Send.</li> <li>You will see the UI stall, and not make progress. You may also see an error message appear at the top saying Error fetching history.</li> <li>Return to the Worker terminal and restart the Worker.</li> <li>Return to the web UI and watch for progress. Eventually the message should send and the agent Workflow progresses like nothing happened.</li> <li>If you are prompted to confirm the tool execution, do so. Then leave the UI up for the next scenario.</li> </ol> <p>What happened?: When the Worker came back online, it registered with the Task Queue and began listening for tasks it could execute. When the original Worker timed out, not returning a response for the task it was supposed to execute, the new Worker accepted it. The new Worker then rebuilt the state of the original Workflow Execution, up to the point of failure, and continued execution as if nothing happened. This new Worker could have been on another virtual machine within the Worker fleet, or the original Worker when the virtual machine finished its upgrade. This ensured that the state was not lost and the Workflow continued to progress.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#part-2-turning-off-the-internet","title":"Part 2: Turning off the Internet","text":"<p>Scenario: After the upgrade finished, somewhere, miles away, Danny the data center intern trips over a improperly managed power cable and the network switch to the rack where your Worker is hosted goes down. While he scrambles to plug it back end, your Worker is intermittently without network access. What happens?</p> <p>Simulating this scenario:</p> <ol> <li>Either continue from the previous session, or start with a new chat window and don't send a message yet.</li> <li>Turn off your Wifi/Unplug your network adapter to simulate this failure.</li> <li>Respond to the prompt the agent posed to you. The agent will validate this using the LLM, which it won't be able to access.</li> <li>Go to your Temporal Web UI at <code>localhost:8233</code> and find the failing Activity. You will see it attempting to retry the call to the LLM. </li> <li>Turn the internet back on.</li> <li>Eventually, the LLM call will succeed, with no intervention from the developer.</li> <li>If you are prompted to confirm the tool execution, do so. Then leave the UI up for the next scenario.</li> </ol> <p>What happened?: Temporal Activities are retried automatically upon failure. Intermittent failures such as network outages are often fixed via retries. Each Activity has a default Retry Policy that retries, then backs off increasingly to a maximum duration. Once the network comes back online, at the next retry interval the LLM call will execute and succeed.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#part-3-swapping-out-llms","title":"Part 3: Swapping out LLMs","text":"<p>Scenario: Now that the switch is back online, the developer can breath a sigh of relief. Unfortunately they get paged that their OpenAI credits are depleted, there are angry customers trying to use the chatbot, and the only person with a corporate card to replenish the credits is on PTO. You have an Anthropic account with some Claude credits you can swap in quickly.</p> <p>Note</p> <p>This scenario requires an Anthropic account with a Claude API token.</p> <p>Simulating this scenario:</p> <ol> <li>Either continue from the previous session, or start with a new chat window. Send a few chats to make progress in the Workflow, but do not complete it.</li> <li>Open the <code>.env</code> file and modify the following variables:<ul> <li><code>LLM_MODEL</code>: <code>anthropic/claude-sonnet-4-20250514</code></li> <li><code>LLM_KEY</code>: Your LLM Key</li> </ul> </li> <li>Restart the Worker.</li> <li>Respond to the next prompt in the chat.</li> <li>The agent will respond as if nothing happened, continuing the conversation.</li> </ol> <p>What happened?: Since the agent is durable and preserves state, the conversation history was preserved when the Worker was terminated. The state of the Workflow was reconstructed to the point where the Worker was terminated, and the conversation history was sent to Claude as context when executing the next prompt. The agent continues executing as if nothing happened.</p> <p>These are just some of the failure scenarios the agent can survive.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#conclusion","title":"Conclusion","text":"<p>In this tutorial, you built a durable AI agent that handles multi-turn conversations, executes tools to achieve a goal, and recovers from failures. You implemented the agent using Temporal primitives, including Workflows, Activities, Signals, Queries, Workers, and Task Queues. You created a REST API to enable client integration with your agent. You tested your agent with a chatbot interface, and witnessed the agent survive various failure scenarios.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#key-architectural-patterns","title":"Key architectural patterns","text":"<p>Your implementation demonstrates several important patterns for building AI agent systems:</p> <p>Durability through orchestration: Temporal Workflows provide automatic state persistence, ensuring conversations survive process crashes, network failures, and infrastructure issues. This durability is essential for AI agents that manage long-running, stateful interactions.</p> <p>Separation of concerns: The architecture cleanly separates orchestration logic (Workflows), external interactions (Activities), tool implementations (Python functions), and user interface (API), making the system maintainable and extensible.</p> <p>Observability by design: Every execution step is recorded in the Event History, providing visibility into the agent's execution without the need for extra tools.</p> <p>Extensibility: The tool and goal registry pattern enables adding defining new tools and goals without modifying the core Workflow logic.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#resources-for-continued-learning","title":"Resources for continued learning","text":"<p>To continue your learning on Temporal and its use for AI, check out the following resources</p> <ul> <li>Download and run a more feature-rich version of this agent, which is what inspired this tutorial.</li> <li>Learn more about Temporal AI Use Cases</li> <li>Explore the Temporal documentation for more Temporal features and best practices.</li> <li>Take a Temporal Course and dive deeper into Temporal topics.</li> <li>Ask a question in the Temporal community in the #topic-ai channel.</li> </ul>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#final-thoughts","title":"Final thoughts","text":"<p>The foundation you built in this tutorial enables you to build agents to solve nearly any goal. If you're up to it, try writing your own goal and tools and have the agent execute them. Temporal's Durable Execution brings reliability and observability to long-running, distributed systems, which is exactly what AI agents are.</p> <p>Check back later for the next installment in this tutorial series, where you will continue to add functionality to your agent.</p>"},{"location":"tutorials/how-to-build-a-durable-ai-agent-with-temporal-and-python/#license-acknowledgements","title":"License Acknowledgements","text":"<p>I wrote this piece while employed at Temporal. In order to preserve it in my portfolio, I am cross posting it here. You can find the MIT License for the Temporal Learning site for the content below, in accordance with the licensing terms.</p> <p>Link to original license</p> <p>Inclusion</p> <p>Temporal documentation</p> <p>MIT License</p> <p>Copyright \u00a9 2022 Temporal Technologies Inc. All rights reserved.</p> <p>Copyright \u00a9 2017 Uber Technologies, Inc.</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"uses/","title":"Uses","text":"<p>This is my uses page, a list of hardware, software, and tools I use on a regular.  I'm indecisive and change what I use often, so this may also change frequently.</p>"},{"location":"uses/#general-hardware","title":"General Hardware","text":"<ul> <li>Apple Magic Keyboard with NumPad - Work keyboard, I've found Mac hardware plays nicest with Macs. Not my favorite, but not terrible. Numpad is a must have. </li> <li> <p>Apple Trackpad - Thought I'd try this instead of a mouse when I joined Temporal. I like it better in some regards, less in others. Right click is harder. Long drags across multiple large monitors is harder. The gestures are easier and nice(1).</p> <ol> <li>AND I CAN USE IT WHILE CHARGING!!!</li> </ol> </li> <li> <p>3 Monitors - 2 Dells and an LG. I don't know the specs. They're all 27 inches or larger. I didn't buy them. I collect monitors as I traverse remote jobs. No one ever wants them back. They're my little trophies. But 3 is a must for full productivity. One for the IDE, one for my terminal to test, one for a browser for research(1). </p> <ol> <li>And for those of you who don't full screen your apps on a Mac, you terrify me. </li> <li>Das Keyboard Model 4 Ultimate - Keyboard on my desktop. Clicky blue switches all the way! And yes, the keycaps are blank.</li> </ol> </li> </ul>"},{"location":"uses/#development-tools","title":"Development Tools","text":"<p>I write code daily in many languages, usually Python and Java, but also Go, TypeScript, lately Ruby, and the occasional C#.  These are the tools I use on the daily. </p> <ul> <li>VSCode - Tried and true. Only IDE I use. </li> <li> <p>Claude Code - Over the past month, I have gone from casual user to power user(1). The more I ask my friends how they are using it, the more I've realized I'm the power user in the group.</p> <ol> <li>I put this shit on everything.</li> </ol> </li> <li> <p>iTerm2 and Windows Terminal- Different terminals for different OSes. Trying Ghostty is on my list of things to do.</p> </li> <li>tmux - Terminal multiplexer. Vital for running multiple Claude Code sessions at once.</li> </ul>"},{"location":"uses/#productivity","title":"Productivity","text":"<ul> <li> <p>Obsidian - Knowledge base and note-taking application, daily journal(1).</p> <ol> <li>When I remember to journal.... </li> </ol> </li> <li> <p>Todoist - Keeping track of all my tasks across work, community, and home.</p> </li> <li>6ft Undated Reusable Whiteboard Calendar - This thing has been a game changer. I've had it for 3 years now, and I love it. I often tell people on meetings about it. \"I'm not looking away, I'm checking my year calendar.\" For someone who travels for work a lot, a year at a glance has saved me so many potential double bookings. I also enjoy taking a picture of it at the end of every year and saving it. I can see all the work I did before I wipe it clean and start again.</li> <li>Desktop Whiteboard Computer Buddy - Another amazing tool. Great for quick notes in a meeting, doubles as a phone stand and little drawer. I get this as Christmas presents for people now.</li> <li> <p>A REAL Whiteboard - Can you tell I like whiteboards? I've had cheap ones you can get online or from local stores, but I finally decided to get a good one(1). Totally worth it.</p> <ol> <li>Translation: I had home office budget to use.</li> </ol> </li> </ul>"},{"location":"uses/#content-creation","title":"Content Creation","text":""},{"location":"uses/#writing","title":"Writing","text":"<p>I spend the majority of my time writing. Over the years, I've tried many tools and continue to try more. These are what I'm currently using, but check back often as this list may change.</p> <ul> <li>VSCode - I write exclusively in Markdown. When I have to write in another format, I write Markdown and convert it later. VSCode has such a rich plugin ecosystem I can switch between coding and writing seamlessly.</li> <li><code>vale</code> - A command-line tool that allows you to define a style guide and lint your content against it.</li> <li> <p><code>lychee</code> A command-line tool that checks for broken links. This is part of my CI and keeps my various sites up to date, makes sure I don't forget to add links(1), and finds link rot.</p> <ol> <li>When writing, I will often add Markdown syntax for a link like so <code>\"[link](#)</code> when I want to add a link but come back and add them later. <code>lychee</code> helps me catch that. </li> </ol> </li> <li> <p>Claude Code - Oh no!  He uses AI tools to write? Burn him! (1) Claude is a great editor. I don't use Claude to write content(2), but paired with <code>vale</code>, I have one hell of an editor.</p> <ol> <li>This is a whole blog post in itself.</li> <li>Yet, again, that is a whole fucking blog post.</li> </ol> </li> </ul>"},{"location":"uses/#video","title":"Video","text":"<p>I don't create professional video content as often anymore, but I do have a setup for when I need to.</p> <ul> <li>Microphone here - Large-diaphragm condenser microphone.</li> <li>Focusrite Scarlett 2i2 Audio Interface - USB interface for XLR microphones</li> <li>Sony ZV-E10 Camera - Mirror-less camera for vlogging. </li> <li>ScreenFlow - Video editing and screen recording software. Mac only</li> <li>Elgato Cam Link 4k - Capture device for camera to record directly to my computer.</li> <li>Elgato Key Light - I have two of these to avoid casting a shadow. They can be a little finicky but overall they've been reliable.</li> <li>Elgato Green Screen - Solid product. Just a great green screen, although I've been told I need a blue screen because of my hair color.</li> <li>Glide Gear TMP100 Teleprompter - Teleprompter for highly scripted videos.</li> </ul>"},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/archive/2022/","title":"2022","text":""},{"location":"blog/archive/2021/","title":"2021","text":""},{"location":"blog/archive/2020/","title":"2020","text":""},{"location":"blog/archive/2019/","title":"2019","text":""},{"location":"blog/category/career/","title":"Career","text":""},{"location":"blog/category/goals/","title":"Goals","text":""},{"location":"blog/category/recap/","title":"Recap","text":""},{"location":"blog/category/resumes/","title":"Resumes","text":""},{"location":"blog/category/rant/","title":"Rant","text":""},{"location":"blog/category/programming/","title":"Programming","text":""},{"location":"blog/page/2/","title":"Blog","text":""},{"location":"tutorials/archive/2025/","title":"2025","text":""},{"location":"tutorials/archive/2022/","title":"2022","text":""},{"location":"tutorials/archive/2021/","title":"2021","text":""},{"location":"tutorials/category/python/","title":"Python","text":""},{"location":"tutorials/category/temporal/","title":"Temporal","text":""},{"location":"tutorials/category/ai/","title":"AI","text":""},{"location":"tutorials/category/gaming/","title":"Gaming","text":""},{"location":"tutorials/category/web/","title":"Web","text":""},{"location":"tutorials/category/microservices/","title":"Microservices","text":""},{"location":"speaking/archive/2024/","title":"2024","text":""},{"location":"speaking/archive/2023/","title":"2023","text":""},{"location":"speaking/archive/2022/","title":"2022","text":""},{"location":"speaking/archive/2021/","title":"2021","text":""},{"location":"speaking/archive/2020/","title":"2020","text":""},{"location":"speaking/archive/2016/","title":"2016","text":""},{"location":"speaking/category/workshop/","title":"Workshop","text":""},{"location":"speaking/category/conference-talk/","title":"Conference Talk","text":""},{"location":"speaking/category/podcast/","title":"Podcast","text":""},{"location":"speaking/category/webinar/","title":"Webinar","text":""},{"location":"speaking/page/2/","title":"Speaking","text":""}]}